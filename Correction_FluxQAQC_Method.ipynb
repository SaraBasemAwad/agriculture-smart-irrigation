{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"2e8bbbb8-46dc-4859-85cd-65ea495d33bd\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id !== undefined) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var element_id = msg.content.text.trim();\n",
       "            Bokeh.index[element_id].model.document.clear();\n",
       "            delete Bokeh.index[element_id];\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(`.${CLASS_NAME.split(' ')[0]}`);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[0].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[0].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[0]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"2e8bbbb8-46dc-4859-85cd-65ea495d33bd\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n",
       "    }\n",
       "    finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.info(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(js_urls, callback) {\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = js_urls.length;\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var s = document.createElement('script');\n",
       "      s.src = url;\n",
       "      s.async = false;\n",
       "      s.onreadystatechange = s.onload = function() {\n",
       "        root._bokeh_is_loading--;\n",
       "        if (root._bokeh_is_loading === 0) {\n",
       "          console.log(\"Bokeh: all BokehJS libraries loaded\");\n",
       "          run_callbacks()\n",
       "        }\n",
       "      };\n",
       "      s.onerror = function() {\n",
       "        console.warn(\"failed to load library \" + url);\n",
       "      };\n",
       "      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "    }\n",
       "  };var element = document.getElementById(\"2e8bbbb8-46dc-4859-85cd-65ea495d33bd\");\n",
       "  if (element == null) {\n",
       "    console.log(\"Bokeh: ERROR: autoload.js configured with elementid '2e8bbbb8-46dc-4859-85cd-65ea495d33bd' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.10.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.10.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.10.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-0.12.10.min.js\"];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "    },\n",
       "    function(Bokeh) {\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.12.10.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.10.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.10.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.10.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.10.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.10.min.css\");\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i].call(root, root.Bokeh);\n",
       "      }if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"2e8bbbb8-46dc-4859-85cd-65ea495d33bd\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(js_urls, function() {\n",
       "      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"2e8bbbb8-46dc-4859-85cd-65ea495d33bd\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n    }\n    finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.info(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(js_urls, callback) {\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = js_urls.length;\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var s = document.createElement('script');\n      s.src = url;\n      s.async = false;\n      s.onreadystatechange = s.onload = function() {\n        root._bokeh_is_loading--;\n        if (root._bokeh_is_loading === 0) {\n          console.log(\"Bokeh: all BokehJS libraries loaded\");\n          run_callbacks()\n        }\n      };\n      s.onerror = function() {\n        console.warn(\"failed to load library \" + url);\n      };\n      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.getElementsByTagName(\"head\")[0].appendChild(s);\n    }\n  };var element = document.getElementById(\"2e8bbbb8-46dc-4859-85cd-65ea495d33bd\");\n  if (element == null) {\n    console.log(\"Bokeh: ERROR: autoload.js configured with elementid '2e8bbbb8-46dc-4859-85cd-65ea495d33bd' but no matching script tag was found. \")\n    return false;\n  }\n\n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.10.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.10.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.10.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-0.12.10.min.js\"];\n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    \n    function(Bokeh) {\n      \n    },\n    function(Bokeh) {\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.12.10.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.10.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.10.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.10.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.10.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.10.min.css\");\n    }\n  ];\n\n  function run_inline_js() {\n    \n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"2e8bbbb8-46dc-4859-85cd-65ea495d33bd\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(js_urls, function() {\n      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "from fluxdataqaqc import Data, QaQc, Plot\n",
    "from bokeh.plotting import figure, show, ColumnDataSource\n",
    "from bokeh.plotting import output_notebook\n",
    "from bokeh.models.formatters import DatetimeTickFormatter\n",
    "from bokeh.models import LinearAxis, Range1d\n",
    "from bokeh.models import HoverTool\n",
    "from bokeh.io import output_notebook\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_path = \"/Users/saraawad/Desktop/Datasets/Google/\"\n",
    "hourly_classified_path = os.path.join(base_path + \"Ameriflux/\", \"Ameriflux Hourly Classified/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Helpers:\n",
    "    def __init__(self):\n",
    "        print(\"Helper\")\n",
    "        \n",
    "    def convert_missing_values_nan(df):\n",
    "        '''This function will convert -9999 to NaN'''\n",
    "        df = df.replace(-9999.000000, np.NaN)\n",
    "        return df\n",
    "\n",
    "    def drop_nan_columns(df):\n",
    "        '''Drops the columns having all theirs rows as Nans'''\n",
    "        columns_to_exclude = [\"Date\", \"Day\", \"Year\", \"Month\", \"Timestamp start\"\n",
    "                              , \"Time\", \"TIMESTAMP\", \"Tier\", \"TIMESTAMP_START\", \"TIMESTAMP_END\", \"Day Status\"]\n",
    "        columns = df.columns\n",
    "        for i in range(len(columns)):\n",
    "            col = columns[i]\n",
    "            if col in columns_to_exclude:\n",
    "                continue\n",
    "            nan_sum_col = df[col].isnull().sum()\n",
    "            if nan_sum_col == len(df):\n",
    "                df.drop(col, axis=1, inplace=True)\n",
    "        return df\n",
    "    \n",
    "    def drop_nans_rows(df):\n",
    "        '''This function will drop the rows having NaNs'''\n",
    "        print(\"Before removing missing values:\")\n",
    "        print(\"number of rows:\", df.shape[0], \"\\nnumber of columns:\", df.shape[1])\n",
    "        df = df.dropna(how='any')\n",
    "        print(\"After removing missing values:\")\n",
    "        print(\"number of rows:\", df.shape[0], \"\\nnumber of columns:\", df.shape[1])\n",
    "        return df\n",
    "        \n",
    "    def get_all_matching_columns(df, keyword):\n",
    "        return df.filter(like=keyword).columns\n",
    "\n",
    "    def generate_lags(df, column, lags_count): \n",
    "        for i in range(lags_count):\n",
    "            lag_name = column + \"-\" + str(i + 1)\n",
    "            df[lag_name] = df[column].shift(i + 1)\n",
    "#             for j in range(i):\n",
    "#                 df.loc[str(j+1), lag_name] = np.nan\n",
    "#         df = df.dropna(how='any')\n",
    "        return df\n",
    "\n",
    "    def add_LE_conversion_rate(df, col):\n",
    "        conversion_rate = 28.94\n",
    "        new_col = col + \"(mm)\"\n",
    "        df[new_col] = df[col] / conversion_rate\n",
    "        return df\n",
    "\n",
    "    def read_sites_data():\n",
    "        file_path = os.path.join(base_path, \"filtered_sites_all.xlsx\")\n",
    "        df = pd.read_excel(file_path)\n",
    "        df.head()\n",
    "        return df\n",
    "\n",
    "    def export_data(df, file_path):\n",
    "        export_path = os.path.join(base_path, file_path + \".csv\")\n",
    "        export_csv = df.to_csv(export_path, index=None, header=True)\n",
    "\n",
    "    def load_data(file_path):\n",
    "        df = pd.read_csv(file_path + \".csv\", delimiter=',')\n",
    "        return df\n",
    "    \n",
    "    def list_to_df(list_to_convert):\n",
    "        '''This function will convert the provided list into a dataframe'''\n",
    "        df = pd.concat(list_to_convert, sort=True)\n",
    "        return df\n",
    "    \n",
    "    def get_files_directory(dirName):\n",
    "    # create a list of file and sub directories \n",
    "    # names in the given directory \n",
    "        listOfFile = os.listdir(dirName)\n",
    "        allFiles = list()\n",
    "        # Iterate over all the entries\n",
    "        for entry in listOfFile:\n",
    "            # Create full path\n",
    "            if entry.endswith(\".xlsx\") or entry.endswith(\".icloud\") or entry.endswith(\".DS_Store\"):\n",
    "                continue\n",
    "            fullPath = os.path.join(dirName, entry)\n",
    "            # If entry is a directory then get the list of files in this directory \n",
    "            if os.path.isdir(fullPath):\n",
    "                allFiles = allFiles + Helpers.get_files_directory(fullPath)\n",
    "            else:\n",
    "                allFiles.append(fullPath)\n",
    "\n",
    "        return allFiles\n",
    "\n",
    "    def concat_dataframe_from_files(files, skipRowsNum, split_num):\n",
    "        values = []\n",
    "        for i in range(len(files)):\n",
    "            file_path = files[i]\n",
    "            head, file_name = os.path.split(file_path)\n",
    "            #Get only the sheets having the variables\n",
    "            if file_name.endswith(\".csv\"):\n",
    "#                 print(\"file name\", file_name)\n",
    "                df = pd.read_csv(file_path, delimiter=',', skiprows=skipRowsNum)\n",
    "                site_id = file_name.split(\"_\")[split_num]\n",
    "#                 print(\"site id in file:\", site_id)\n",
    "                df[\"Site Id\"] = site_id\n",
    "                values.append(df)\n",
    "        return Helpers.list_to_df(values)   \n",
    "    \n",
    "    def generate_dataframe_from_files(dirName, skipRowsNum = 0, split_num = 0):\n",
    "        files = Helpers.get_files_directory(dirName)\n",
    "        df = Helpers.concat_dataframe_from_files(files, skipRowsNum, split_num)\n",
    "        return df\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Ameriflux:\n",
    "\n",
    "    def __init__(self, folder_path, skipRowsNum, split_num, lags_count, is_hourly, is_joint, output_name):\n",
    "        print(\"Initializer\")\n",
    "        self.folder_path = folder_path\n",
    "        self.skipRowsNum = skipRowsNum\n",
    "        self.split_num = split_num\n",
    "        self.lags_count = lags_count\n",
    "        self.is_hourly = is_hourly\n",
    "        self.is_joint = is_joint\n",
    "        self.output_name = output_name\n",
    "        \n",
    "    \n",
    "    def impute_temperature(self, df):\n",
    "        '''This function imputes the temperature by the mean when TA is negative otherwise set it to 0 \n",
    "        if the mean is negative'''\n",
    "        columns_list = [\"TA\"]\n",
    "\n",
    "        #Get the mean air temperature, if less than zero\n",
    "        #fall back to zero and then delete the mean column\n",
    "        for i in range(len(columns_list)):\n",
    "            col = columns_list[i]\n",
    "            new_col = col + \"-avg\"\n",
    "            df[new_col] = df[col].mean()\n",
    "            df[new_col] = np.where(df[new_col] < 0, 0, df[new_col])\n",
    "            df[col] = np.where(df[col] < 0, df[new_col], df[col])\n",
    "            \n",
    "        #Drop the new mean columns that are generated temporarly\n",
    "        new_columns_lists = []\n",
    "        for i in range(len(columns_list)):\n",
    "            col = columns_list[i]\n",
    "            new_col = col + \"-avg\" \n",
    "            new_columns_lists.append(new_col)\n",
    "        df.drop(new_columns_lists, axis=1, inplace=True)\n",
    "        \n",
    "        return df\n",
    "        \n",
    "    def transform_input_variants(self, df):\n",
    "        '''This function gets all the input column variants'''\n",
    "        ws_list = list(Helpers.get_all_matching_columns(df, \"WS_\"))\n",
    "        rh_list = list(Helpers.get_all_matching_columns(df, \"RH_\"))\n",
    "        ta_list = list(Helpers.get_all_matching_columns(df, \"TA_\"))\n",
    "        g_list = list(Helpers.get_all_matching_columns(df, \"G_\"))\n",
    "        h_list = [col for col in df if col.startswith('H_')]\n",
    "        netrad_list = list(Helpers.get_all_matching_columns(df, \"NETRAD_\"))\n",
    "        \n",
    "        print(\"ws_list\", ws_list)\n",
    "        print(\"rh_list\", rh_list)\n",
    "        print(\"ta_list\", ta_list)\n",
    "        print(\"g_list\", g_list)\n",
    "        print(\"h_list\", h_list)\n",
    "        print(\"netrad_list\", netrad_list)\n",
    "        \n",
    "        df = self.group_input_variants(df, ws_list, \"WS\")\n",
    "        df = self.group_input_variants(df, rh_list, \"RH\")\n",
    "        df = self.group_input_variants(df, ta_list, \"TA\")\n",
    "        df = self.group_input_variants(df, g_list, \"G\")\n",
    "        df = self.group_input_variants(df, h_list, \"H\")\n",
    "        df = self.group_input_variants(df, netrad_list, \"NETRAD\")\n",
    "        df = self.impute_temperature(df)\n",
    "        print(\"After grouping\", df.columns)\n",
    "        return df\n",
    "        \n",
    "    def group_input_variants(self, df, variant_list, mean_column):\n",
    "        '''This function imputes all the input columnn variants with the mean of them and drop the variants'''\n",
    "        if len(variant_list) > 1:\n",
    "            df[mean_column] = \"\"\n",
    "            df[mean_column] = df[variant_list].mean(axis=1)\n",
    "        elif len(variant_list) > 0:\n",
    "             df[mean_column] = df[variant_list[0]]\n",
    "        \n",
    "        df = df.drop(variant_list, axis=1)\n",
    "        return df\n",
    "    \n",
    "    def add_LE_converstion(self, df):\n",
    "        '''This function adds the conversion for LE incase LE exists and generate lags \n",
    "        for it after adding the conversion'''\n",
    "        columns_to_drop = (list(df.filter(like='LE_').columns))\n",
    "        df.drop(columns_to_drop, axis=1, inplace=True)\n",
    "        if \"LE\" in df.columns:\n",
    "            df = Helpers.add_LE_conversion_rate(df, \"LE\")   \n",
    "        return df\n",
    "        \n",
    "    def remove_unneeded_columns_hourly(self, df):\n",
    "        #Remove rows having NaNs\n",
    "        df = Helpers.drop_nans_rows(df)\n",
    "        df = self.add_LE_converstion(df)\n",
    "        return df\n",
    "    \n",
    "    def drop_invalid_columns(self, df):\n",
    "        '''This function will remove un-needed columns that have different unit of measure than the\n",
    "        other variants so they should be dropped before grouping variants'''\n",
    "        ssitc_list = list(Helpers.get_all_matching_columns(df, \"_SSITC_TEST\"))\n",
    "        max_list = list(Helpers.get_all_matching_columns(df, \"WS_MAX\"))\n",
    "        columnsToDrop = []\n",
    "        columnsToDrop.extend(ssitc_list)\n",
    "        columnsToDrop.extend(max_list)\n",
    "        print(\"columns to drop\", columnsToDrop)\n",
    "        df = df.drop(columnsToDrop, axis=1)\n",
    "        return df\n",
    "        \n",
    "    def generate_hourly_data(self, df):\n",
    "        '''This function will process the half-hourly data'''\n",
    "        print(\"df shape:\", df.shape)\n",
    "        df = Helpers.convert_missing_values_nan(df)\n",
    "        #Remove rows having NaNs\n",
    "        df = self.drop_invalid_columns(df)\n",
    "        df = Helpers.drop_nans_rows(df)\n",
    "        df = self.transform_input_variants(df)\n",
    "#         df = self.remove_unneeded_columns_hourly(df)\n",
    "        return df\n",
    "        \n",
    "    def generate_site_data(self, sites_df):\n",
    "        files = Helpers.get_files_directory(self.folder_path)\n",
    "        for i in range(len(files)):\n",
    "            file_path = files[i]\n",
    "            head, file_name = os.path.split(file_path)\n",
    "            #Get only the sheets having the variables\n",
    "            if file_name.endswith(\".csv\"):\n",
    "                df_filt = pd.read_csv(file_path, delimiter=',', skiprows=self.skipRowsNum)\n",
    "                site_id = file_name.split(\"_\")[self.split_num]\n",
    "                df_filt[\"Site Id\"] = site_id\n",
    "                df_filt = self.generate_hourly_data(df_filt)\n",
    "                #Concat all hours updated to a list\n",
    "                if (len(df_filt) > 0) and (\"LE\" in df_filt.columns) :\n",
    "                    print(\"Site:\", site_id)\n",
    "                    file_name = os.path.join(self.output_name, site_id + \"_Hourly\")\n",
    "                    Helpers.export_data(df_filt, file_name) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializer\n",
      "df shape: (144768, 52)\n",
      "columns to drop ['FC_SSITC_TEST', 'FCH4_SSITC_TEST', 'H_SSITC_TEST', 'LE_SSITC_TEST', 'TAU_SSITC_TEST_PI_F']\n",
      "Before removing missing values:\n",
      "number of rows: 144768 \n",
      "number of columns: 47\n",
      "After removing missing values:\n",
      "number of rows: 50155 \n",
      "number of columns: 47\n",
      "ws_list []\n",
      "rh_list ['RH_PI_F']\n",
      "ta_list []\n",
      "g_list []\n",
      "h_list ['H_PI_F']\n",
      "netrad_list []\n",
      "After grouping Index(['TIMESTAMP_END', 'CO2', 'H2O', 'CH4', 'FC', 'FCH4', 'G', 'H', 'LE',\n",
      "       'WD', 'WS', 'USTAR', 'ZL', 'TAU', 'MO_LENGTH', 'V_SIGMA', 'W_SIGMA',\n",
      "       'PA', 'TA', 'VPD_PI', 'T_SONIC', 'T_SONIC_SIGMA', 'TS_PI_1', 'TS_PI_2',\n",
      "       'TS_PI_3', 'TS_PI_4', 'TS_PI_5', 'WTD', 'NETRAD', 'PPFD_IN', 'PPFD_OUT',\n",
      "       'SW_IN', 'P', 'FC_PI_F', 'RECO_PI_F', 'GPP_PI_F', 'FCH4_PI_F',\n",
      "       'LE_PI_F', 'Site Id', 'Category', 'Year', 'Month', 'Day', 'Date',\n",
      "       'Timestamp start', 'RH'],\n",
      "      dtype='object')\n",
      "Site: US-Twt\n",
      "df shape: (65700, 28)\n",
      "columns to drop []\n",
      "Before removing missing values:\n",
      "number of rows: 65700 \n",
      "number of columns: 28\n",
      "After removing missing values:\n",
      "number of rows: 48911 \n",
      "number of columns: 28\n",
      "ws_list []\n",
      "rh_list []\n",
      "ta_list []\n",
      "g_list []\n",
      "h_list []\n",
      "netrad_list []\n",
      "After grouping Index(['TIMESTAMP_END', 'FC', 'H', 'LE', 'TAU', 'TA', 'RH', 'NETRAD', 'SW_IN',\n",
      "       'SW_OUT', 'ALB', 'PPFD_IN', 'WS', 'WD', 'USTAR', 'ZL', 'PA', 'P', 'G',\n",
      "       'TS_1_1_1', 'SWC_1_1_1', 'Site Id', 'Category', 'Year', 'Month', 'Day',\n",
      "       'Date', 'Timestamp start'],\n",
      "      dtype='object')\n",
      "Site: US-Wlr\n",
      "df shape: (280548, 81)\n",
      "columns to drop ['TAU_SSITC_TEST_1_1_1', 'H_SSITC_TEST_1_1_1', 'LE_SSITC_TEST_1_1_1', 'FC_SSITC_TEST_1_1_1', 'WS_MAX_1_1_1']\n",
      "Before removing missing values:\n",
      "number of rows: 280548 \n",
      "number of columns: 76\n",
      "After removing missing values:\n",
      "number of rows: 0 \n",
      "number of columns: 76\n",
      "ws_list ['WS_1_1_1', 'WS_1_2_1']\n",
      "rh_list ['RH_1_1_1', 'RH_1_2_1']\n",
      "ta_list ['TA_1_1_1', 'TA_1_2_1']\n",
      "g_list ['G_1_1_1', 'G_2_1_1', 'G_3_1_1', 'G_4_1_1']\n",
      "h_list ['H_1_1_1']\n",
      "netrad_list ['NETRAD_1_1_1']\n",
      "After grouping Index(['TIMESTAMP_END', 'CO2_1_1_1', 'H2O_1_1_1', 'TAU_1_1_1', 'LE_1_1_1',\n",
      "       'FC_1_1_1', 'WD_1_1_1', 'U_SIGMA_1_1_1', 'V_SIGMA_1_1_1',\n",
      "       'W_SIGMA_1_1_1', 'USTAR_1_1_1', 'MO_LENGTH_1_1_1', 'ZL_1_1_1',\n",
      "       'VPD_PI_1_1_1', 'T_SONIC_1_1_1', 'T_SONIC_SIGMA_1_1_1', 'WD_1_2_1',\n",
      "       'PA_1_1_1', 'SW_IN_1_1_1', 'LW_IN_1_1_1', 'SW_OUT_1_1_1',\n",
      "       'LW_OUT_1_1_1', 'SW_IN_1_1_2', 'PPFD_IN_1_1_1', 'P_1_1_1', 'SWC_1_1_1',\n",
      "       'SWC_2_1_1', 'SWC_1_2_1', 'SWC_2_2_1', 'SWC_3_1_1', 'SWC_4_1_1',\n",
      "       'SWC_3_2_1', 'SWC_4_2_1', 'TS_1_1_1', 'TS_1_2_1', 'TS_1_3_1',\n",
      "       'TS_2_1_1', 'TS_2_2_1', 'TS_2_3_1', 'PPFD_OUT_1_1_1', 'SWC_1_3_1',\n",
      "       'SWC_1_4_1', 'TS_1_4_1', 'SWC_1_5_1', 'TS_1_5_1', 'SWC_1_6_1',\n",
      "       'TS_1_6_1', 'SWC_2_3_1', 'SWC_2_3_2', 'TS_2_3_2', 'SWC_2_2_2',\n",
      "       'TS_2_2_2', 'SWC_2_1_2', 'TS_2_1_2', 'SW_DIR_1_1_1', 'SW_DIF_1_1_1',\n",
      "       'T_CANOPY_1_1_1', 'Site Id', 'Category', 'Year', 'Month', 'Day', 'Date',\n",
      "       'Timestamp start', 'WS', 'RH', 'TA', 'G', 'H', 'NETRAD'],\n",
      "      dtype='object')\n",
      "df shape: (175296, 28)\n",
      "columns to drop []\n",
      "Before removing missing values:\n",
      "number of rows: 175296 \n",
      "number of columns: 28\n",
      "After removing missing values:\n",
      "number of rows: 57031 \n",
      "number of columns: 28\n",
      "ws_list []\n",
      "rh_list []\n",
      "ta_list []\n",
      "g_list []\n",
      "h_list []\n",
      "netrad_list []\n",
      "After grouping Index(['TIMESTAMP_END', 'USTAR', 'TA', 'WD', 'WS', 'NEE_PI', 'FC', 'SC', 'H',\n",
      "       'LE', 'G', 'TS_1', 'P', 'RH', 'PA', 'CO2_1', 'CO2_2', 'VPD_PI',\n",
      "       'NETRAD', 'PPFD_IN', 'SW_IN', 'Site Id', 'Category', 'Year', 'Month',\n",
      "       'Day', 'Date', 'Timestamp start'],\n",
      "      dtype='object')\n",
      "Site: US-Ced\n",
      "df shape: (149328, 54)\n",
      "columns to drop ['FC_SSITC_TEST', 'FCH4_SSITC_TEST', 'H_SSITC_TEST', 'LE_SSITC_TEST', 'TAU_SSITC_TEST_PI_F']\n",
      "Before removing missing values:\n",
      "number of rows: 149328 \n",
      "number of columns: 49\n",
      "After removing missing values:\n",
      "number of rows: 0 \n",
      "number of columns: 49\n",
      "ws_list []\n",
      "rh_list []\n",
      "ta_list []\n",
      "g_list []\n",
      "h_list ['H_PI_F']\n",
      "netrad_list []\n",
      "After grouping Index(['TIMESTAMP_END', 'CO2', 'H2O', 'CH4', 'FC', 'FCH4', 'H', 'LE', 'WD',\n",
      "       'WS', 'USTAR', 'ZL', 'MO_LENGTH', 'V_SIGMA', 'W_SIGMA', 'PA', 'RH',\n",
      "       'TA', 'VPD_PI', 'T_SONIC', 'T_SONIC_SIGMA', 'TS_PI_1', 'TS_PI_2',\n",
      "       'TS_PI_3', 'TS_PI_4', 'TS_PI_5', 'TS_PI_6', 'NETRAD', 'PPFD_IN',\n",
      "       'PPFD_OUT', 'SW_IN', 'SW_OUT', 'LW_IN', 'LW_OUT', 'FC_PI_F',\n",
      "       'RECO_PI_F', 'GPP_PI_F', 'FCH4_PI_F', 'LE_PI_F', 'TAU', 'WTD',\n",
      "       'Site Id', 'Category', 'Year', 'Month', 'Day', 'Date',\n",
      "       'Timestamp start'],\n",
      "      dtype='object')\n",
      "df shape: (122736, 33)\n",
      "columns to drop []\n",
      "Before removing missing values:\n",
      "number of rows: 122736 \n",
      "number of columns: 33\n",
      "After removing missing values:\n",
      "number of rows: 44817 \n",
      "number of columns: 33\n",
      "ws_list []\n",
      "rh_list []\n",
      "ta_list []\n",
      "g_list []\n",
      "h_list []\n",
      "netrad_list []\n",
      "After grouping Index(['TIMESTAMP_END', 'USTAR', 'TA', 'WD', 'WS', 'NEE_PI', 'FC', 'SC', 'H',\n",
      "       'LE', 'G', 'TS_1', 'TS_2', 'P', 'RH', 'PA', 'CO2_1', 'CO2_2', 'VPD_PI',\n",
      "       'SWC_1', 'NETRAD', 'PPFD_IN', 'SW_IN', 'SW_OUT', 'H2O', 'RECO_PI',\n",
      "       'Site Id', 'Category', 'Year', 'Month', 'Day', 'Date',\n",
      "       'Timestamp start'],\n",
      "      dtype='object')\n",
      "Site: US-Kon\n",
      "df shape: (177528, 82)\n",
      "columns to drop []\n",
      "Before removing missing values:\n",
      "number of rows: 177528 \n",
      "number of columns: 82\n",
      "After removing missing values:\n",
      "number of rows: 0 \n",
      "number of columns: 82\n",
      "ws_list ['WS_1_1_1', 'WS_1_1_2', 'WS_1_2_1', 'WS_2_1_1']\n",
      "rh_list ['RH_1_1_1', 'RH_1_2_1', 'RH_1_3_1', 'RH_1_1_2']\n",
      "ta_list ['TA_1_1_1', 'TA_1_2_1', 'TA_1_3_1', 'TA_1_1_2', 'TA_2_1_1']\n",
      "g_list ['G_2_1_1', 'G_2_1_2']\n",
      "h_list ['H_1_1_1']\n",
      "netrad_list ['NETRAD_1_1_1']\n",
      "After grouping Index(['TIMESTAMP_END', 'USTAR_1_1_1', 'WD_1_1_1', 'FC_1_1_1', 'LE_1_1_1',\n",
      "       'TS_2_1_1', 'P_1_1_1', 'PA_1_1_1', 'CO2_1_1_1', 'VPD_PI_1_1_1',\n",
      "       'SWC_PI_1', 'PPFD_IN_1_1_1', 'SW_IN_1_1_1', 'SW_OUT_1_1_1',\n",
      "       'LW_IN_1_1_1', 'LW_OUT_1_1_1', 'H2O_1_1_1', 'RECO_PI_1_1_1',\n",
      "       'PPFD_DIF_1_1_1', 'T_SONIC_1_2_1', 'CO2_1_2_1', 'H2O_1_2_1',\n",
      "       'SW_IN_1_2_1', 'SW_OUT_1_2_1', 'LW_IN_1_2_1', 'LW_OUT_1_2_1',\n",
      "       'U_SIGMA_1_2_1', 'V_SIGMA_1_2_1', 'W_SIGMA_1_2_1',\n",
      "       'T_SONIC_SIGMA_1_2_1', 'T_SONIC_1_1_1', 'T_SONIC_SIGMA_1_1_1',\n",
      "       'PPFD_IN_1_1_2', 'WD_1_1_2', 'U_SIGMA_1_1_1', 'V_SIGMA_1_1_1',\n",
      "       'W_SIGMA_1_1_1', 'T_SONIC_2_1_1', 'CO2_2_1_1', 'H2O_2_1_1',\n",
      "       'SW_BC_IN_1_1_1', 'SW_BC_OUT_1_1_1', 'LW_BC_IN_1_1_1',\n",
      "       'LW_BC_OUT_1_1_1', 'PPFD_BC_IN_1_1_1', 'P_2_1_1', 'U_SIGMA_2_1_1',\n",
      "       'V_SIGMA_2_1_1', 'W_SIGMA_2_1_1', 'T_SONIC_SIGMA_2_1_1', 'WD_1_2_1',\n",
      "       'WD_2_1_1', 'SWC_1_1_1', 'SWC_2_1_1', 'SWC_3_1_1', 'SWC_4_1_1',\n",
      "       'SWC_5_1_1', 'SWC_6_1_1', 'Site Id', 'Category', 'Year', 'Month', 'Day',\n",
      "       'Date', 'Timestamp start', 'WS', 'RH', 'TA', 'G', 'H', 'NETRAD'],\n",
      "      dtype='object')\n",
      "df shape: (140256, 35)\n",
      "columns to drop []\n",
      "Before removing missing values:\n",
      "number of rows: 140256 \n",
      "number of columns: 35\n",
      "After removing missing values:\n",
      "number of rows: 44511 \n",
      "number of columns: 35\n",
      "ws_list []\n",
      "rh_list []\n",
      "ta_list []\n",
      "g_list []\n",
      "h_list []\n",
      "netrad_list []\n",
      "After grouping Index(['TIMESTAMP_END', 'USTAR', 'TA', 'WD', 'WS', 'NEE_PI', 'FC', 'SC', 'H',\n",
      "       'LE', 'G', 'TS_1', 'TS_2', 'P', 'RH', 'PA', 'CO2_1', 'CO2_2', 'VPD_PI',\n",
      "       'SWC_1', 'SWC_2', 'NETRAD', 'PPFD_IN', 'SW_IN', 'PPFD_OUT', 'H2O',\n",
      "       'PPFD_DIF', 'ZL', 'Site Id', 'Category', 'Year', 'Month', 'Day', 'Date',\n",
      "       'Timestamp start'],\n",
      "      dtype='object')\n",
      "Site: US-Snd\n",
      "df shape: (70128, 33)\n",
      "columns to drop []\n",
      "Before removing missing values:\n",
      "number of rows: 70128 \n",
      "number of columns: 33\n",
      "After removing missing values:\n",
      "number of rows: 50164 \n",
      "number of columns: 33\n",
      "ws_list []\n",
      "rh_list ['RH_1_1_1']\n",
      "ta_list ['TA_1_1_1']\n",
      "g_list []\n",
      "h_list []\n",
      "netrad_list []\n",
      "After grouping Index(['TIMESTAMP_END', 'USTAR', 'WD', 'WS', 'FC', 'H', 'LE', 'G', 'TS_1_1_1',\n",
      "       'TS_1_2_1', 'P', 'PA_1_1_1', 'CO2', 'VPD_PI_1_1_1', 'SWC_1_1_1',\n",
      "       'SWC_1_2_1', 'NETRAD', 'PPFD_IN', 'SW_IN', 'PPFD_OUT', 'SW_OUT',\n",
      "       'LW_IN', 'LW_OUT', 'H2O', 'Site Id', 'Category', 'Year', 'Month', 'Day',\n",
      "       'Date', 'Timestamp start', 'RH', 'TA'],\n",
      "      dtype='object')\n",
      "Site: US-AR1\n",
      "df shape: (168768, 50)\n",
      "columns to drop ['FC_SSITC_TEST', 'FCH4_SSITC_TEST', 'H_SSITC_TEST', 'LE_SSITC_TEST', 'TAU_SSITC_TEST']\n",
      "Before removing missing values:\n",
      "number of rows: 168768 \n",
      "number of columns: 45\n",
      "After removing missing values:\n",
      "number of rows: 18316 \n",
      "number of columns: 45\n",
      "ws_list []\n",
      "rh_list []\n",
      "ta_list []\n",
      "g_list []\n",
      "h_list ['H_PI_F']\n",
      "netrad_list []\n",
      "After grouping Index(['TIMESTAMP_END', 'CO2', 'H2O', 'CH4', 'FC', 'FCH4', 'H', 'LE', 'WD',\n",
      "       'WS', 'USTAR', 'ZL', 'TAU', 'MO_LENGTH', 'V_SIGMA', 'W_SIGMA', 'PA',\n",
      "       'RH', 'TA', 'VPD_PI', 'T_SONIC', 'T_SONIC_SIGMA', 'TS_PI_1', 'TS_PI_2',\n",
      "       'TS_PI_3', 'TS_PI_4', 'TS_PI_5', 'NETRAD', 'PPFD_IN', 'PPFD_OUT', 'P',\n",
      "       'WTD', 'FC_PI_F', 'RECO_PI_F', 'GPP_PI_F', 'FCH4_PI_F', 'LE_PI_F',\n",
      "       'Site Id', 'Category', 'Year', 'Month', 'Day', 'Date',\n",
      "       'Timestamp start'],\n",
      "      dtype='object')\n",
      "Site: US-Myb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df shape: (52608, 57)\n",
      "columns to drop []\n",
      "Before removing missing values:\n",
      "number of rows: 52608 \n",
      "number of columns: 57\n",
      "After removing missing values:\n",
      "number of rows: 7589 \n",
      "number of columns: 57\n",
      "ws_list []\n",
      "rh_list []\n",
      "ta_list []\n",
      "g_list ['G_1_1_1', 'G_1_1_2', 'G_1_1_3', 'G_1_1_4', 'G_PI_1_1_A']\n",
      "h_list []\n",
      "netrad_list []\n",
      "After grouping Index(['TIMESTAMP_END', 'WS', 'U_SIGMA', 'V_SIGMA', 'W_SIGMA', 'WD', 'TA',\n",
      "       'T_CANOPY', 'RH', 'PA', 'T_SONIC', 'T_SONIC_SIGMA', 'P_RAIN', 'CO2',\n",
      "       'H2O', 'FC', 'NEE_PI', 'H', 'LE', 'USTAR', 'ZL', 'SW_IN', 'SW_OUT',\n",
      "       'LW_IN', 'LW_OUT', 'SW_DIF', 'SW_DIR', 'PPFD_IN', 'PPFD_OUT', 'NETRAD',\n",
      "       'NDVI', 'PRI', 'ALB', 'TS_1_1_1', 'TS_1_1_2', 'TS_PI_1_1_A', 'TS_1_2_1',\n",
      "       'TS_1_2_2', 'TS_PI_1_2_A', 'SWC_1_1_1', 'SWC_1_1_2', 'SWC_PI_1_1_A',\n",
      "       'SWC_1_2_1', 'SWC_1_2_2', 'SWC_PI_1_2_A', 'Site Id', 'Category', 'Year',\n",
      "       'Month', 'Day', 'Date', 'Timestamp start', 'G'],\n",
      "      dtype='object')\n",
      "Site: US-A32\n",
      "df shape: (290784, 79)\n",
      "columns to drop []\n",
      "Before removing missing values:\n",
      "number of rows: 290784 \n",
      "number of columns: 79\n",
      "After removing missing values:\n",
      "number of rows: 0 \n",
      "number of columns: 79\n",
      "ws_list []\n",
      "rh_list []\n",
      "ta_list ['TA_1_1_1', 'TA_1_1_2', 'TA_1_1_3']\n",
      "g_list ['G_1_1_1', 'G_2_1_1', 'G_3_1_1', 'G_4_1_1', 'G_5_1_1', 'G_6_1_1', 'G_7_1_1', 'G_8_1_1']\n",
      "h_list []\n",
      "netrad_list []\n",
      "After grouping Index(['TIMESTAMP_END', 'FC', 'LE', 'H', 'CO2', 'H2O', 'PA', 'T_SONIC',\n",
      "       'T_SONIC_SIGMA', 'RH', 'P', 'PPFD_IN', 'PPFD_DIF', 'PPFD_DIR', 'SW_IN',\n",
      "       'SW_OUT', 'LW_IN', 'LW_OUT', 'NETRAD', 'ALB', 'SWC_1_1_1', 'SWC_1_2_1',\n",
      "       'SWC_1_3_1', 'SWC_1_4_1', 'SWC_1_5_1', 'SWC_1_6_1', 'SWC_1_7_1',\n",
      "       'SWC_1_8_1', 'SWC_2_1_1', 'SWC_2_2_1', 'SWC_2_3_1', 'SWC_2_4_1',\n",
      "       'SWC_2_5_1', 'SWC_2_6_1', 'SWC_2_7_1', 'SWC_2_8_1', 'SWC_3_1_1',\n",
      "       'SWC_3_2_1', 'SWC_3_3_1', 'SWC_3_4_1', 'SWC_3_5_1', 'SWC_3_6_1',\n",
      "       'SWC_3_7_1', 'SWC_3_8_1', 'SWC_4_1_1', 'TS_1_1_1', 'TS_1_2_1',\n",
      "       'TS_1_3_1', 'TS_1_4_1', 'TS_1_5_1', 'TS_1_6_1', 'D_SNOW', 'USTAR',\n",
      "       'U_SIGMA', 'V_SIGMA', 'W_SIGMA', 'WS', 'WD', 'NEE_PI', 'RECO_PI',\n",
      "       'GPP_PI', 'Site Id', 'Category', 'Year', 'Month', 'Day', 'Date',\n",
      "       'Timestamp start', 'TA', 'G'],\n",
      "      dtype='object')\n",
      "df shape: (87648, 27)\n",
      "columns to drop []\n",
      "Before removing missing values:\n",
      "number of rows: 87648 \n",
      "number of columns: 27\n",
      "After removing missing values:\n",
      "number of rows: 29299 \n",
      "number of columns: 27\n",
      "ws_list []\n",
      "rh_list []\n",
      "ta_list []\n",
      "g_list []\n",
      "h_list []\n",
      "netrad_list []\n",
      "After grouping Index(['TIMESTAMP_END', 'USTAR', 'TA', 'WD', 'WS', 'FC', 'H', 'LE', 'G', 'P',\n",
      "       'RH', 'PA', 'VPD_PI', 'NETRAD', 'PPFD_IN', 'SW_IN', 'PPFD_OUT',\n",
      "       'SW_OUT', 'LW_IN', 'LW_OUT', 'Site Id', 'Category', 'Year', 'Month',\n",
      "       'Day', 'Date', 'Timestamp start'],\n",
      "      dtype='object')\n",
      "Site: US-Goo\n",
      "df shape: (140256, 34)\n",
      "columns to drop []\n",
      "Before removing missing values:\n",
      "number of rows: 140256 \n",
      "number of columns: 34\n",
      "After removing missing values:\n",
      "number of rows: 12724 \n",
      "number of columns: 34\n",
      "ws_list []\n",
      "rh_list []\n",
      "ta_list []\n",
      "g_list []\n",
      "h_list []\n",
      "netrad_list []\n",
      "After grouping Index(['TIMESTAMP_END', 'USTAR', 'TA', 'WD', 'WS', 'NEE_PI', 'FC', 'SC', 'H',\n",
      "       'LE', 'G', 'TS_1', 'TS_2', 'P', 'RH', 'PA', 'CO2_1', 'CO2_2', 'VPD_PI',\n",
      "       'NETRAD', 'PPFD_IN', 'SW_IN', 'PPFD_OUT', 'SW_OUT', 'LW_IN', 'LW_OUT',\n",
      "       'H2O', 'Site Id', 'Category', 'Year', 'Month', 'Day', 'Date',\n",
      "       'Timestamp start'],\n",
      "      dtype='object')\n",
      "Site: US-Skr\n",
      "df shape: (342528, 67)\n",
      "columns to drop []\n",
      "Before removing missing values:\n",
      "number of rows: 342528 \n",
      "number of columns: 67\n",
      "After removing missing values:\n",
      "number of rows: 50215 \n",
      "number of columns: 67\n",
      "ws_list []\n",
      "rh_list ['RH_PI_F']\n",
      "ta_list ['TA_PI_F']\n",
      "g_list ['G_PI_1_1_A']\n",
      "h_list ['H_PI_F']\n",
      "netrad_list []\n",
      "After grouping Index(['TIMESTAMP_END', 'FC', 'CO2', 'CO2_SIGMA', 'LE', 'H2O', 'H2O_SIGMA',\n",
      "       'H', 'T_SONIC', 'T_SONIC_SIGMA', 'WD', 'WS', 'USTAR', 'W_SIGMA',\n",
      "       'U_SIGMA', 'V_SIGMA', 'TA', 'VPD_PI', 'RH', 'PA', 'TS_PI_1_1_A',\n",
      "       'TS_PI_1_2_A', 'TS_PI_1_3_A', 'TS_PI_1_4_A', 'TS_PI_1_5_A',\n",
      "       'SWC_PI_1_1_A', 'SWC_PI_1_2_A', 'SWC_PI_1_3_A', 'P', 'ZL', 'NETRAD',\n",
      "       'SW_IN_1_1_1', 'PPFD_IN', 'PPFD_OUT', 'SW_IN_1_1_2', 'SW_OUT', 'LW_IN',\n",
      "       'LW_OUT', 'PPFD_DIR', 'PPFD_DIF', 'NEE_PI_F', 'GPP_PI_F', 'RECO_PI_F',\n",
      "       'FC_PI_F', 'LE_PI_F', 'VPD_PI_F', 'PA_PI_F', 'TS_PI_F_1_1_A',\n",
      "       'TS_PI_F_1_2_A', 'TS_PI_F_1_3_A', 'TS_PI_F_1_4_A', 'TS_PI_F_1_5_A',\n",
      "       'SWC_PI_F_1_1_A', 'SWC_PI_F_1_2_A', 'SWC_PI_F_1_3_A', 'P_PI_F',\n",
      "       'Site Id', 'Category', 'Year', 'Month', 'Day', 'Date',\n",
      "       'Timestamp start', 'G'],\n",
      "      dtype='object')\n",
      "Site: US-Var\n",
      "df shape: (52608, 57)\n",
      "columns to drop []\n",
      "Before removing missing values:\n",
      "number of rows: 52608 \n",
      "number of columns: 57\n",
      "After removing missing values:\n",
      "number of rows: 3019 \n",
      "number of columns: 57\n",
      "ws_list []\n",
      "rh_list []\n",
      "ta_list []\n",
      "g_list ['G_1_1_1', 'G_1_1_2', 'G_1_1_3', 'G_1_1_4', 'G_PI_1_1_A']\n",
      "h_list []\n",
      "netrad_list []\n",
      "After grouping Index(['TIMESTAMP_END', 'WS', 'U_SIGMA', 'V_SIGMA', 'W_SIGMA', 'WD', 'TA',\n",
      "       'T_CANOPY', 'RH', 'PA', 'T_SONIC', 'T_SONIC_SIGMA', 'P_RAIN', 'CO2',\n",
      "       'H2O', 'FC', 'NEE_PI', 'H', 'LE', 'USTAR', 'ZL', 'SW_IN', 'SW_OUT',\n",
      "       'LW_IN', 'LW_OUT', 'SW_DIF', 'SW_DIR', 'PPFD_IN', 'PPFD_OUT', 'NETRAD',\n",
      "       'NDVI', 'PRI', 'ALB', 'TS_1_1_1', 'TS_1_1_2', 'TS_PI_1_1_A', 'TS_1_2_1',\n",
      "       'TS_1_2_2', 'TS_PI_1_2_A', 'SWC_1_1_1', 'SWC_1_1_2', 'SWC_PI_1_1_A',\n",
      "       'SWC_1_2_1', 'SWC_1_2_2', 'SWC_PI_1_2_A', 'Site Id', 'Category', 'Year',\n",
      "       'Month', 'Day', 'Date', 'Timestamp start', 'G'],\n",
      "      dtype='object')\n",
      "Site: US-A74\n",
      "df shape: (175296, 30)\n",
      "columns to drop []\n",
      "Before removing missing values:\n",
      "number of rows: 175296 \n",
      "number of columns: 30\n",
      "After removing missing values:\n",
      "number of rows: 7918 \n",
      "number of columns: 30\n",
      "ws_list []\n",
      "rh_list []\n",
      "ta_list []\n",
      "g_list []\n",
      "h_list []\n",
      "netrad_list []\n",
      "After grouping Index(['TIMESTAMP_END', 'USTAR', 'TA', 'WD', 'WS', 'FC', 'H', 'LE', 'G',\n",
      "       'TS_1', 'TS_2', 'P', 'RH', 'PA', 'CO2_1', 'CO2_2', 'VPD_PI', 'SWC_1',\n",
      "       'SWC_2', 'NETRAD', 'PPFD_IN', 'SW_IN', 'H2O', 'Site Id', 'Category',\n",
      "       'Year', 'Month', 'Day', 'Date', 'Timestamp start'],\n",
      "      dtype='object')\n",
      "Site: US-SO2\n",
      "df shape: (17520, 33)\n",
      "columns to drop []\n",
      "Before removing missing values:\n",
      "number of rows: 17520 \n",
      "number of columns: 33\n",
      "After removing missing values:\n",
      "number of rows: 2786 \n",
      "number of columns: 33\n",
      "ws_list []\n",
      "rh_list []\n",
      "ta_list []\n",
      "g_list []\n",
      "h_list []\n",
      "netrad_list []\n",
      "After grouping Index(['TIMESTAMP_END', 'FC', 'LE', 'H', 'CO2', 'H2O', 'USTAR', 'U_SIGMA',\n",
      "       'V_SIGMA', 'W_SIGMA', 'TA', 'WS', 'WD', 'PPFD_IN', 'PPFD_DIR',\n",
      "       'PPFD_DIF', 'SW_IN', 'SW_OUT', 'LW_IN', 'LW_OUT', 'NETRAD', 'ALB', 'PA',\n",
      "       'NEE_PI_F', 'GPP_PI_F', 'RECO_PI_F', 'Site Id', 'Category', 'Year',\n",
      "       'Month', 'Day', 'Date', 'Timestamp start'],\n",
      "      dtype='object')\n",
      "Site: US-Wgr\n",
      "df shape: (227904, 36)\n",
      "columns to drop []\n",
      "Before removing missing values:\n",
      "number of rows: 227904 \n",
      "number of columns: 36\n",
      "After removing missing values:\n",
      "number of rows: 0 \n",
      "number of columns: 36\n",
      "ws_list []\n",
      "rh_list []\n",
      "ta_list []\n",
      "g_list []\n",
      "h_list []\n",
      "netrad_list []\n",
      "After grouping Index(['TIMESTAMP_END', 'USTAR', 'TA', 'WD', 'WS', 'NEE_PI', 'FC', 'SC', 'H',\n",
      "       'LE', 'G', 'TS_1', 'TS_2', 'P', 'RH', 'PA', 'CO2_1', 'CO2_2', 'VPD_PI',\n",
      "       'SWC_1', 'SWC_2', 'NETRAD', 'PPFD_IN', 'SW_IN', 'PPFD_OUT', 'SW_OUT',\n",
      "       'LW_IN', 'LW_OUT', 'PPFD_DIF', 'Site Id', 'Category', 'Year', 'Month',\n",
      "       'Day', 'Date', 'Timestamp start'],\n",
      "      dtype='object')\n",
      "df shape: (192863, 70)\n",
      "columns to drop []\n",
      "Before removing missing values:\n",
      "number of rows: 192863 \n",
      "number of columns: 70\n",
      "After removing missing values:\n",
      "number of rows: 0 \n",
      "number of columns: 70\n",
      "ws_list ['WS_1_1_1', 'WS_PI_F_1_1_1']\n",
      "rh_list ['RH_1_1_1', 'RH_PI_F_1_1_1']\n",
      "ta_list ['TA_1_1_1', 'TA_PI_F_1_1_1']\n",
      "g_list ['G_2_1_1', 'G_2_3_1', 'G_2_2_1', 'G_PI_F_2_1_1']\n",
      "h_list ['H_1_1_1', 'H_PI_F_1_1_1']\n",
      "netrad_list ['NETRAD_1_1_1', 'NETRAD_PI_F_1_1_1']\n",
      "After grouping Index(['TIMESTAMP_END', 'WD_1_1_1', 'USTAR_1_1_1', 'NEE_PI_1_1_1',\n",
      "       'NEE_PI_F_1_1_1', 'SC_1_1_1', 'SH_1_1_1', 'LE_1_1_1', 'SLE_1_1_1',\n",
      "       'TS_2_1_1', 'TS_2_2_1', 'P_1_1_1', 'PA_1_1_1', 'CO2_1_1_1',\n",
      "       'VPD_PI_1_1_1', 'SWC_2_1_1', 'PPFD_IN_1_1_1', 'SW_IN_1_1_1',\n",
      "       'SW_OUT_1_1_1', 'LW_IN_1_1_1', 'LW_OUT_1_1_1', 'H2O_1_1_1',\n",
      "       'RECO_PI_F_1_1_1', 'ZL_1_1_1', 'FC_1_1_1', 'FC_PI_F_1_1_1',\n",
      "       'LE_PI_F_1_1_1', 'SW_IN_PI_F_1_1_1', 'GPP_PI_F_1_1_1', 'SWC_1_1_1',\n",
      "       'PPFD_OUT_1_1_1', 'PBLH_3_1_1', 'GPP_PI_1_1_1', 'WD_PI_F_1_1_1',\n",
      "       'SC_PI_F_1_1_1', 'SH_PI_F_1_1_1', 'SLE_PI_F_1_1_1', 'PA_PI_F_1_1_1',\n",
      "       'CO2_PI_F_1_1_1', 'VPD_PI_F_1_1_1', 'TS_PI_F_2_1_1', 'TS_PI_F_2_2_1',\n",
      "       'PPFD_OUT_PI_F_1_1_1', 'SW_OUT_PI_F_1_1_1', 'LW_IN_PI_F_1_1_1',\n",
      "       'LW_OUT_PI_F_1_1_1', 'H2O_PI_F_1_1_1', 'PBLH_1_1_1', 'RECO_PI_1_1_1',\n",
      "       'Site Id', 'Category', 'Year', 'Month', 'Day', 'Date',\n",
      "       'Timestamp start', 'WS', 'RH', 'TA', 'G', 'H', 'NETRAD'],\n",
      "      dtype='object')\n",
      "df shape: (154847, 72)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "columns to drop []\n",
      "Before removing missing values:\n",
      "number of rows: 154847 \n",
      "number of columns: 72\n",
      "After removing missing values:\n",
      "number of rows: 0 \n",
      "number of columns: 72\n",
      "ws_list []\n",
      "rh_list []\n",
      "ta_list ['TA_1_1_2', 'TA_1_1_3', 'TA_1_1_1']\n",
      "g_list ['G_1_1_1', 'G_1_1_2', 'G_1_1_3']\n",
      "h_list []\n",
      "netrad_list []\n",
      "After grouping Index(['TIMESTAMP_END', 'FC', 'LE', 'H', 'CO2', 'H2O', 'PA', 'T_SONIC',\n",
      "       'T_SONIC_SIGMA', 'RH', 'P', 'PPFD_IN', 'SW_IN', 'SW_OUT', 'LW_IN',\n",
      "       'LW_OUT', 'NETRAD', 'ALB', 'SWC_1_1_1', 'SWC_1_2_1', 'SWC_1_3_1',\n",
      "       'SWC_1_4_1', 'SWC_1_5_1', 'SWC_2_1_2', 'SWC_2_2_2', 'SWC_2_3_2',\n",
      "       'SWC_3_4_2', 'SWC_2_5_2', 'SWC_3_1_3', 'SWC_3_2_3', 'SWC_3_3_3',\n",
      "       'SWC_3_4_3', 'SWC_3_5_3', 'SWC_4_1_1', 'SWC_5_1_1', 'SWC_6_1_1',\n",
      "       'TS_1_1_1', 'TS_1_2_1', 'TS_1_3_1', 'TS_1_4_1', 'TS_1_5_1', 'TS_1_6_1',\n",
      "       'D_SNOW', 'USTAR', 'U_SIGMA', 'V_SIGMA', 'W_SIGMA', 'WS', 'WD',\n",
      "       'SWC_1_1_2', 'SWC_1_2_2', 'SWC_1_3_2', 'SWC_1_4_2', 'SWC_1_5_2',\n",
      "       'SWC_1_1_3', 'SWC_1_2_3', 'SWC_1_3_3', 'SWC_1_4_3', 'SWC_1_5_3',\n",
      "       'Site Id', 'Category', 'Year', 'Month', 'Day', 'Date',\n",
      "       'Timestamp start', 'TA', 'G'],\n",
      "      dtype='object')\n",
      "df shape: (35040, 57)\n",
      "columns to drop ['FC_SSITC_TEST', 'FCH4_SSITC_TEST', 'H_SSITC_TEST', 'LE_SSITC_TEST', 'TAU_SSITC_TEST_PI_F']\n",
      "Before removing missing values:\n",
      "number of rows: 35040 \n",
      "number of columns: 52\n",
      "After removing missing values:\n",
      "number of rows: 13392 \n",
      "number of columns: 52\n",
      "ws_list []\n",
      "rh_list []\n",
      "ta_list []\n",
      "g_list []\n",
      "h_list ['H_PI_F']\n",
      "netrad_list []\n",
      "After grouping Index(['TIMESTAMP_END', 'CO2', 'H2O', 'CH4', 'FC', 'FCH4', 'G', 'H', 'LE',\n",
      "       'WD', 'WS', 'USTAR', 'ZL', 'TAU', 'MO_LENGTH', 'V_SIGMA', 'W_SIGMA',\n",
      "       'PA', 'RH', 'TA', 'VPD_PI', 'T_SONIC', 'T_SONIC_SIGMA', 'TS_PI_1',\n",
      "       'TS_PI_2', 'TS_PI_3', 'TS_PI_4', 'TS_PI_5', 'SWC_PI_1', 'SWC_PI_2',\n",
      "       'NETRAD', 'PPFD_IN', 'PPFD_OUT', 'SW_IN', 'SW_OUT', 'LW_IN', 'LW_OUT',\n",
      "       'P', 'SW_DIF', 'FC_PI_F', 'RECO_PI_F', 'GPP_PI_F', 'FCH4_PI_F',\n",
      "       'LE_PI_F', 'Site Id', 'Category', 'Year', 'Month', 'Day', 'Date',\n",
      "       'Timestamp start'],\n",
      "      dtype='object')\n",
      "Site: US-Bi2\n",
      "df shape: (35088, 34)\n",
      "columns to drop []\n",
      "Before removing missing values:\n",
      "number of rows: 35088 \n",
      "number of columns: 34\n",
      "After removing missing values:\n",
      "number of rows: 9037 \n",
      "number of columns: 34\n",
      "ws_list []\n",
      "rh_list []\n",
      "ta_list []\n",
      "g_list []\n",
      "h_list []\n",
      "netrad_list []\n",
      "After grouping Index(['TIMESTAMP_END', 'USTAR', 'TA', 'WD', 'WS', 'NEE_PI', 'FC', 'H', 'LE',\n",
      "       'G', 'TS_1_1_1', 'TS_1_2_1', 'RH', 'PA', 'CO2', 'VPD_PI', 'SWC_1_1_1',\n",
      "       'SWC_1_2_1', 'NETRAD', 'PPFD_IN', 'SW_IN', 'PPFD_OUT', 'SW_OUT',\n",
      "       'LW_IN', 'LW_OUT', 'H2O', 'ZL', 'Site Id', 'Category', 'Year', 'Month',\n",
      "       'Day', 'Date', 'Timestamp start'],\n",
      "      dtype='object')\n",
      "Site: US-Tw2\n",
      "df shape: (70128, 32)\n",
      "columns to drop []\n",
      "Before removing missing values:\n",
      "number of rows: 70128 \n",
      "number of columns: 32\n",
      "After removing missing values:\n",
      "number of rows: 0 \n",
      "number of columns: 32\n",
      "ws_list []\n",
      "rh_list []\n",
      "ta_list []\n",
      "g_list []\n",
      "h_list []\n",
      "netrad_list []\n",
      "After grouping Index(['TIMESTAMP_END', 'USTAR', 'TA', 'WD', 'WS', 'FC', 'H', 'LE', 'G',\n",
      "       'TS_1', 'P', 'RH', 'PA', 'CO2_1', 'CO2_2', 'VPD_PI', 'SWC_1', 'NETRAD',\n",
      "       'PPFD_IN', 'SW_IN', 'SW_OUT', 'LW_IN', 'LW_OUT', 'H2O', 'RECO_PI',\n",
      "       'Site Id', 'Category', 'Year', 'Month', 'Day', 'Date',\n",
      "       'Timestamp start'],\n",
      "      dtype='object')\n",
      "df shape: (175344, 25)\n",
      "columns to drop []\n",
      "Before removing missing values:\n",
      "number of rows: 175344 \n",
      "number of columns: 25\n",
      "After removing missing values:\n",
      "number of rows: 15382 \n",
      "number of columns: 25\n",
      "ws_list []\n",
      "rh_list []\n",
      "ta_list []\n",
      "g_list []\n",
      "h_list []\n",
      "netrad_list []\n",
      "After grouping Index(['TIMESTAMP_END', 'USTAR', 'TA', 'WD', 'WS', 'NEE_PI', 'FC', 'SC', 'H',\n",
      "       'LE', 'G', 'TS_1', 'P', 'RH', 'VPD_PI', 'NETRAD', 'PPFD_IN', 'SW_IN',\n",
      "       'Site Id', 'Category', 'Year', 'Month', 'Day', 'Date',\n",
      "       'Timestamp start'],\n",
      "      dtype='object')\n",
      "Site: US-SP2\n",
      "df shape: (95088, 56)\n",
      "columns to drop ['FC_SSITC_TEST', 'FCH4_SSITC_TEST', 'H_SSITC_TEST', 'LE_SSITC_TEST', 'TAU_SSITC_TEST']\n",
      "Before removing missing values:\n",
      "number of rows: 95088 \n",
      "number of columns: 51\n",
      "After removing missing values:\n",
      "number of rows: 0 \n",
      "number of columns: 51\n",
      "ws_list []\n",
      "rh_list []\n",
      "ta_list []\n",
      "g_list []\n",
      "h_list ['H_PI_F']\n",
      "netrad_list []\n",
      "After grouping Index(['TIMESTAMP_END', 'CO2', 'H2O', 'CH4', 'FC', 'FCH4', 'G', 'H', 'LE',\n",
      "       'WD', 'WS', 'USTAR', 'ZL', 'TAU', 'MO_LENGTH', 'V_SIGMA', 'W_SIGMA',\n",
      "       'PA', 'RH', 'TA', 'VPD_PI', 'T_SONIC', 'T_SONIC_SIGMA', 'SWC_1_1_1',\n",
      "       'SWC_1_2_1', 'TS_1_1_1', 'TS_1_2_1', 'TS_1_3_1', 'TS_1_4_1', 'TS_1_5_1',\n",
      "       'NETRAD', 'PPFD_DIF', 'PPFD_IN', 'PPFD_OUT', 'SW_IN', 'SW_OUT', 'LW_IN',\n",
      "       'LW_OUT', 'P', 'FC_PI_F', 'RECO_PI_F', 'GPP_PI_F', 'LE_PI_F', 'Site Id',\n",
      "       'Category', 'Year', 'Month', 'Day', 'Date', 'Timestamp start'],\n",
      "      dtype='object')\n",
      "df shape: (70128, 33)\n",
      "columns to drop []\n",
      "Before removing missing values:\n",
      "number of rows: 70128 \n",
      "number of columns: 33\n",
      "After removing missing values:\n",
      "number of rows: 41783 \n",
      "number of columns: 33\n",
      "ws_list []\n",
      "rh_list ['RH_1_1_1']\n",
      "ta_list ['TA_1_1_1']\n",
      "g_list []\n",
      "h_list []\n",
      "netrad_list []\n",
      "After grouping Index(['TIMESTAMP_END', 'USTAR', 'WD', 'WS', 'FC', 'H', 'LE', 'G', 'TS_1_1_1',\n",
      "       'TS_1_2_1', 'P', 'PA_1_1_1', 'CO2', 'VPD_PI_1_1_1', 'SWC_1_1_1',\n",
      "       'SWC_1_2_1', 'NETRAD', 'PPFD_IN', 'SW_IN', 'PPFD_OUT', 'SW_OUT',\n",
      "       'LW_IN', 'LW_OUT', 'H2O', 'Site Id', 'Category', 'Year', 'Month', 'Day',\n",
      "       'Date', 'Timestamp start', 'RH', 'TA'],\n",
      "      dtype='object')\n",
      "Site: US-AR2\n",
      "df shape: (70128, 32)\n",
      "columns to drop []\n",
      "Before removing missing values:\n",
      "number of rows: 70128 \n",
      "number of columns: 32\n",
      "After removing missing values:\n",
      "number of rows: 65 \n",
      "number of columns: 32\n",
      "ws_list []\n",
      "rh_list []\n",
      "ta_list []\n",
      "g_list []\n",
      "h_list []\n",
      "netrad_list []\n",
      "After grouping Index(['TIMESTAMP_END', 'USTAR', 'TA', 'WD', 'WS', 'FC', 'SC', 'H', 'LE', 'G',\n",
      "       'TS_1', 'TS_2', 'P', 'RH', 'PA', 'CO2_1', 'CO2_2', 'VPD_PI', 'SWC_1',\n",
      "       'SWC_2', 'NETRAD', 'PPFD_IN', 'SW_IN', 'PPFD_OUT', 'SW_OUT', 'Site Id',\n",
      "       'Category', 'Year', 'Month', 'Day', 'Date', 'Timestamp start'],\n",
      "      dtype='object')\n",
      "Site: US-Pon\n",
      "df shape: (70128, 32)\n",
      "columns to drop []\n",
      "Before removing missing values:\n",
      "number of rows: 70128 \n",
      "number of columns: 32\n",
      "After removing missing values:\n",
      "number of rows: 216 \n",
      "number of columns: 32\n",
      "ws_list []\n",
      "rh_list []\n",
      "ta_list []\n",
      "g_list []\n",
      "h_list []\n",
      "netrad_list []\n",
      "After grouping Index(['TIMESTAMP_END', 'USTAR', 'TA', 'WD', 'WS', 'FC', 'SC', 'H', 'LE', 'G',\n",
      "       'TS_1', 'TS_2', 'P', 'RH', 'PA', 'CO2_1', 'CO2_2', 'VPD_PI', 'SWC_1',\n",
      "       'SWC_2', 'NETRAD', 'PPFD_IN', 'SW_IN', 'PPFD_OUT', 'SW_OUT', 'Site Id',\n",
      "       'Category', 'Year', 'Month', 'Day', 'Date', 'Timestamp start'],\n",
      "      dtype='object')\n",
      "Site: US-Shd\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    is_hourly = True #Boolean to indicate if the data is hourly or daily\n",
    "    skipRowsNum = 0 #Defaults to zero, incase excel has meaningless rows to skip\n",
    "    split_num = 0 #The index to read the name of the site, defaults to 0\n",
    "    lags_count = 5 #The number of lags to generate the data for \n",
    "    output_name = os.path.join(\"/Users/saraawad/Desktop/flux-data-qaqc/sites/\", \"data/\")\n",
    "    am = Ameriflux(hourly_classified_path, skipRowsNum, split_num, lags_count, is_hourly, False, output_name)\n",
    "    sites_df = Helpers.read_sites_data()\n",
    "    am.generate_site_data(sites_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class GenerateConfig:\n",
    "\n",
    "    def __init__(self, folder_path, output_name):\n",
    "        print(\"Initializer\")\n",
    "        self.folder_path = folder_path\n",
    "        self.output_name = output_name\n",
    "        \n",
    "    def are_all_main_vars_exists(self, df):\n",
    "        columnsToAdd = [\"NETRAD\", \"H\", \"LE\", \"G\", \"RH\", \"WS\", \"TA\"]\n",
    "#         ,\n",
    "#                         \"SW_IN\", \"SW_OUT\", \"LW_IN\", \"LW_OUT\", \"VPD_PI\"]\n",
    "        if all([item in df.columns for item in columnsToAdd]):\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def group_input_variants(self, df, variant_list, mean_column):\n",
    "        '''This function imputes all the input columnn variants with the mean of them and drop the variants'''\n",
    "        if len(variant_list) > 1:\n",
    "            df[mean_column] = \"\"\n",
    "            df[mean_column] = df[variant_list].mean(axis=1)\n",
    "        elif len(variant_list) > 0:\n",
    "             df[mean_column] = df[variant_list[0]]\n",
    "        \n",
    "        df = df.drop(variant_list, axis=1)\n",
    "        return df\n",
    "    \n",
    "    def generate_config(self, site_main_df, site_var_df):\n",
    "        site_id = site_main_df[\"Site Id\"].unique()[0]\n",
    "        latitude = site_main_df[\"Latitude\"].unique()[0]\n",
    "        longitude = site_main_df[\"Longitude\"].unique()[0]\n",
    "        elevation = site_main_df[\"Elevation(m)\"].unique()[0]\n",
    "\n",
    "        site_path = os.path.join(\"sites/config\", site_id + \".ini\")\n",
    "        f = open(site_path, \"w\")\n",
    "        f.write(\"[METADATA]\\n\")\n",
    "        f.write(\"climate_file_path = /Users/saraawad/Desktop/flux-data-qaqc/sites/data/\" + site_id +\"_Hourly.csv\\n\")\n",
    "        f.write(\"station_latitude = \" + str(latitude) + \"\\n\")\n",
    "        f.write(\"station_longitude = \" + str(longitude) + \"\\n\")\n",
    "        f.write(\"station_elevation = \" + str(elevation) + \"\\n\")\n",
    "        f.write(\"missing_data_value = -9999\\n\")\n",
    "        f.write(\"skiprows = 0\\n\")\n",
    "        f.write(\"date_parser = %Y%m%d%H%M\\n\")\n",
    "        f.write(\"site_id = \" + site_id + \"\\n\")\n",
    "        f.write(\"gridmet_file_path = /Users/saraawad/Desktop/flux-data-qaqc/sites/config/gridMET_data/\"\n",
    "                + site_id + \".csv\")\n",
    "\n",
    "        f.write(\"\\n\")\n",
    "        f.write(\"[DATA]\\n\")\n",
    "        f.write(\"datestring_col = Timestamp start\\n\")\n",
    "        f.write(\"net_radiation_col = NETRAD\\n\")\n",
    "        f.write(\"net_radiation_units = w/m2\\n\")\n",
    "        f.write(\"sensible_heat_flux_col = H\\n\")\n",
    "        f.write(\"sensible_heat_flux_units = w/m2\\n\")\n",
    "        f.write(\"latent_heat_flux_col = LE\\n\")\n",
    "        f.write(\"latent_heat_flux_units = w/m2\\n\")\n",
    "        f.write(\"ground_flux_col = G\\n\")\n",
    "        f.write(\"ground_flux_units = w/m2\\n\")\n",
    "        \n",
    "        sw_list = list(Helpers.get_all_matching_columns(site_var_df, \"SW_IN\"))\n",
    "        site_var_df = self.group_input_variants(site_var_df, sw_list, \"SW_IN\")\n",
    "        if len(sw_list) > 0:\n",
    "            f.write(\"shortwave_in_col = SW_IN\\n\")\n",
    "            f.write(\"shortwave_in_units = w/m2\\n\")\n",
    "            \n",
    "        sw_out_list = list(Helpers.get_all_matching_columns(site_var_df, \"SW_OUT\"))\n",
    "        site_var_df = self.group_input_variants(site_var_df, sw_out_list, \"SW_OUT\")\n",
    "        if len(sw_out_list) > 0:\n",
    "            f.write(\"shortwave_out_col = SW_OUT\\n\")\n",
    "            f.write(\"shortwave_out_units = w/m2\\n\")\n",
    "            \n",
    "          \n",
    "        ln_in_list = list(Helpers.get_all_matching_columns(site_var_df, \"LW_IN\"))\n",
    "        site_var_df = self.group_input_variants(site_var_df, ln_in_list, \"LW_IN\")\n",
    "        if len(ln_in_list) > 0:\n",
    "            f.write(\"longwave_in_col = LW_IN\\n\")\n",
    "            f.write(\"longwave_in_units = w/m2\\n\")\n",
    "        \n",
    "        ln_out_list = list(Helpers.get_all_matching_columns(site_var_df, \"LW_OUT\"))\n",
    "        site_var_df = self.group_input_variants(site_var_df, ln_out_list, \"LW_OUT\")\n",
    "        if len(ln_out_list) > 0:\n",
    "            f.write(\"longwave_out_col = LW_OUT\\n\")\n",
    "            f.write(\"longwave_out_units = w/m2\\n\")\n",
    "        \n",
    "        vdp_list = list(Helpers.get_all_matching_columns(site_var_df, \"VPD_PI\"))\n",
    "        site_var_df = self.group_input_variants(site_var_df, vdp_list, \"VPD_PI\")\n",
    "        if len(vdp_list) > 0:\n",
    "            f.write(\"vap_press_def_col = VPD_PI\\n\")\n",
    "            f.write(\"vap_press_def_units = hPa\\n\")\n",
    "            \n",
    "        f.write(\"avg_temp_col = T_SONIC\\n\")\n",
    "        f.write(\"avg_temp_units = C\\n\")\n",
    "        \n",
    "        ta_list = list(Helpers.get_all_matching_columns(site_var_df, \"TA\"))\n",
    "        site_var_df = self.group_input_variants(site_var_df, ta_list, \"TA\")\n",
    "        if len(ta_list) > 0:\n",
    "            f.write(\"temp_col = TA\\n\")\n",
    "            f.write(\"temp_units = C\\n\")\n",
    "       \n",
    "        f.write(\"rel_humidity_col = RH\\n\")\n",
    "        f.write(\"rel_humidity_units = (%): Relative humidity, range 0-100\\n\")\n",
    "        f.write(\"wind_spd_col = WS\\n\")\n",
    "        f.write(\"wind_spd_units = m/s\\n\")\n",
    "        f.close() \n",
    "        \n",
    "        \n",
    "    def generate_site_data(self):\n",
    "        files = Helpers.get_files_directory(self.folder_path)\n",
    "        sites_df = Helpers.read_sites_data()\n",
    "        for i in range(len(files)):\n",
    "            file_path = files[i]\n",
    "            head, file_name = os.path.split(file_path)\n",
    "            #Get only the sheets having the variables\n",
    "            if file_name.endswith(\".csv\"):\n",
    "                df_filt = pd.read_csv(file_path, delimiter=',')\n",
    "                site_id = file_name.split(\"_\")[0]\n",
    "                df_filt[\"Site Id\"] = site_id\n",
    "                print(\"Site:\", site_id)\n",
    "                site_df = sites_df[sites_df[\"Site Id\"] == site_id]\n",
    "                if self.are_all_main_vars_exists(df_filt):\n",
    "                    self.generate_config(site_df, df_filt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializer\n",
      "Site: US-Ced\n",
      "Site: US-Shd\n",
      "Site: US-Myb\n",
      "Site: US-Bi2\n",
      "Site: US-A32\n",
      "Site: US-Tw2\n",
      "Site: US-Pon\n",
      "Site: US-Skr\n",
      "Site: US-Snd\n",
      "Site: US-AR2\n",
      "Site: US-Goo\n",
      "Site: US-Wlr\n",
      "Site: US-A74\n",
      "Site: US-AR1\n",
      "Site: US-Kon\n",
      "Site: US-Wgr\n",
      "Site: US-SO2\n",
      "Site: US-SP2\n",
      "Site: US-Var\n",
      "Site: US-Twt\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    input_name =  os.path.join(\"/Users/saraawad/Desktop/flux-data-qaqc/sites/\", \"data/\")\n",
    "    output_name = os.path.join(\"/Users/saraawad/Desktop/flux-data-qaqc/sites/\", \"output/\")\n",
    "    gc = GenerateConfig(input_name, output_name)\n",
    "    gc.generate_site_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FluxQaQcCorrection:\n",
    "\n",
    "    def __init__(self, folder_path, output_name, correction_method=1):\n",
    "        print(\"Initializer\")\n",
    "        self.folder_path = folder_path\n",
    "        self.output_name = output_name\n",
    "        self.correction_method = correction_method\n",
    "        \n",
    "    def load_config(self, site_id, path):\n",
    "        d = Data(path)\n",
    "        print(d)\n",
    "        return d\n",
    "        \n",
    "    def ebr_correct_data(self, d):\n",
    "        q = QaQc(d, drop_gaps=True)\n",
    "#         q.correct_data(meth='ebr', etr_gap_fill=False)\n",
    "#         ebr_notgapfilled = q.df\n",
    "#         q.write()\n",
    "        \n",
    "        q.correct_data(meth='ebr', etr_gap_fill=True)\n",
    "        ebr_gapfilled = q.df\n",
    "        q.write()\n",
    "        \n",
    "    def bowen_correct_data(self, d):\n",
    "        q = QaQc(d, drop_gaps=True)\n",
    "        \n",
    "#         q.correct_data(meth='br', etr_gap_fill=False)\n",
    "#         br_notgapfilled = q.df\n",
    "#         q.write()\n",
    "        \n",
    "        q.correct_data(meth='br', etr_gap_fill=True)\n",
    "        br_gapfilled = q.df\n",
    "        q.write()\n",
    "        \n",
    "        \n",
    "#         print(\"Out dir:\", q.out_dir)\n",
    "#         print(q.df.columns)\n",
    "        \n",
    "    def generate_correction(self):\n",
    "        files = Helpers.get_files_directory(self.folder_path)\n",
    "        group_sites_list = []\n",
    "        for i in range(len(files)):\n",
    "            file_path = files[i]\n",
    "            head, file_name = os.path.split(file_path)\n",
    "            site_id = file_name.split(\".\")[0]\n",
    "            print(\"site id:\", site_id)\n",
    "            try:\n",
    "                d = self.load_config(site_id, file_path)\n",
    "                if self.correction_method == 1:\n",
    "                    self.ebr_correct_data(d)\n",
    "                else:\n",
    "                    self.bowen_correct_data(d)\n",
    "            except Exception as ex:\n",
    "                print(\"Exception:\", str(ex))\n",
    "                pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> EBR Correction </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializer\n",
      "site id: US-Tw2\n",
      "<fluxdataqaqc.data.Data object at 0x124b60588>\n",
      "WARNING: the following config variables are missing in the input climate file:\n",
      "T_SONIC\n",
      "They will be filled with NaN values\n",
      "WARNING: renaming column G to input_G\n",
      "WARNING: renaming column LE to input_LE\n",
      "WARNING: renaming column H to input_H\n",
      "WARNING: t_avg variable in column T_SONIC is missing all data it will be removed\n",
      "Converting vpd from hpa to kpa\n",
      "\n",
      "The input data temporal frequency was not detected.\n",
      "WARNING: it looks like the input temporal frequency is greater than daily, downsampling, proceed with caution!\n",
      "\n",
      "Data is being resampled to daily temporal frequency.\n",
      "Linearly interpolating gaps in energy balance components up to 4 hours when Rn < 0 and up to 2 hours when Rn >= 0.\n",
      "gridMET reference ET already downloaded for station at:\n",
      "/Users/saraawad/Desktop/flux-data-qaqc/sites/config/gridMET_data/US-Tw2_38.1083N_-121.6417W.csv\n",
      "not redownloading.\n",
      "Gap filling ET_corr with filtered ETrF x ETr (gridMET)\n",
      "site id: US-SP2\n",
      "<fluxdataqaqc.data.Data object at 0x1245834e0>\n",
      "WARNING: the following config variables are missing in the input climate file:\n",
      "T_SONIC\n",
      "They will be filled with NaN values\n",
      "WARNING: renaming column G to input_G\n",
      "WARNING: renaming column LE to input_LE\n",
      "WARNING: renaming column H to input_H\n",
      "WARNING: t_avg variable in column T_SONIC is missing all data it will be removed\n",
      "Converting vpd from hpa to kpa\n",
      "\n",
      "The input data temporal frequency was not detected.\n",
      "WARNING: it looks like the input temporal frequency is greater than daily, downsampling, proceed with caution!\n",
      "\n",
      "Data is being resampled to daily temporal frequency.\n",
      "Linearly interpolating gaps in energy balance components up to 4 hours when Rn < 0 and up to 2 hours when Rn >= 0.\n",
      "gridMET reference ET already downloaded for station at:\n",
      "/Users/saraawad/Desktop/flux-data-qaqc/sites/config/gridMET_data/US-SP2_29.7750N_-82.2250W.csv\n",
      "not redownloading.\n",
      "Gap filling ET_corr with filtered ETrF x ETr (gridMET)\n",
      "site id: US-A74\n",
      "<fluxdataqaqc.data.Data object at 0x123b5a9e8>\n",
      "WARNING: renaming column G to input_G\n",
      "WARNING: renaming column LE to input_LE\n",
      "WARNING: renaming column H to input_H\n",
      "Temporal frequency of data > hourly cannot calculate VP/VPD\n",
      "\n",
      "The input data temporal frequency was not detected.\n",
      "WARNING: it looks like the input temporal frequency is greater than daily, downsampling, proceed with caution!\n",
      "\n",
      "Data is being resampled to daily temporal frequency.\n",
      "Linearly interpolating gaps in energy balance components up to 4 hours when Rn < 0 and up to 2 hours when Rn >= 0.\n",
      "gridMET reference ET already downloaded for station at:\n",
      "/Users/saraawad/Desktop/flux-data-qaqc/sites/config/gridMET_data/US-A74_36.8167N_-97.5583W.csv\n",
      "not redownloading.\n",
      "Gap filling ET_corr with filtered ETrF x ETr (gridMET)\n",
      "site id: US-Twt\n",
      "<fluxdataqaqc.data.Data object at 0x123b5a710>\n",
      "WARNING: renaming column G to input_G\n",
      "WARNING: renaming column LE to input_LE\n",
      "WARNING: renaming column H to input_H\n",
      "Converting vpd from hpa to kpa\n",
      "Calculating vapor pressure from vapor pressure deficit and air temperature\n",
      "\n",
      "The input data temporal frequency was not detected.\n",
      "Data is being resampled to daily temporal frequency.\n",
      "Linearly interpolating gaps in energy balance components up to 4 hours when Rn < 0 and up to 2 hours when Rn >= 0.\n",
      "Filtering days with less then 100.0% or 45/45 sub-daily measurements\n",
      "gridMET reference ET already downloaded for station at:\n",
      "/Users/saraawad/Desktop/flux-data-qaqc/sites/config/gridMET_data/US-Twt_38.1083N_-121.6417W.csv\n",
      "not redownloading.\n",
      "Gap filling ET_corr with filtered ETrF x ETr (gridMET)\n",
      "site id: US-AR2_36\n",
      "Exception: File contains no section headers.\n",
      "file: PosixPath('/Users/saraawad/Desktop/flux-data-qaqc/sites/config/gridMET_data/US-AR2_36.6500N_-99.6000W.csv'), line: 1\n",
      "'date,gridMET_ETr,gridMET_prcp\\n'\n",
      "site id: US-Shd_36\n",
      "Exception: File contains no section headers.\n",
      "file: PosixPath('/Users/saraawad/Desktop/flux-data-qaqc/sites/config/gridMET_data/US-Shd_36.9417N_-96.6833W.csv'), line: 1\n",
      "'date,gridMET_ETr,gridMET_prcp\\n'\n",
      "site id: US-AR1_36\n",
      "Exception: File contains no section headers.\n",
      "file: PosixPath('/Users/saraawad/Desktop/flux-data-qaqc/sites/config/gridMET_data/US-AR1_36.4417N_-99.4333W.csv'), line: 1\n",
      "'date,gridMET_ETr,gridMET_prcp\\n'\n",
      "site id: US-SP2_29\n",
      "Exception: File contains no section headers.\n",
      "file: PosixPath('/Users/saraawad/Desktop/flux-data-qaqc/sites/config/gridMET_data/US-SP2_29.7750N_-82.2250W.csv'), line: 1\n",
      "'date,gridMET_ETr,gridMET_prcp\\n'\n",
      "site id: US-Goo_34\n",
      "Exception: File contains no section headers.\n",
      "file: PosixPath('/Users/saraawad/Desktop/flux-data-qaqc/sites/config/gridMET_data/US-Goo_34.2750N_-89.8917W.csv'), line: 1\n",
      "'date,gridMET_ETr,gridMET_prcp\\n'\n",
      "site id: US-Snd_38\n",
      "Exception: File contains no section headers.\n",
      "file: PosixPath('/Users/saraawad/Desktop/flux-data-qaqc/sites/config/gridMET_data/US-Snd_38.0250N_-121.7667W.csv'), line: 1\n",
      "'date,gridMET_ETr,gridMET_prcp\\n'\n",
      "site id: US-Twt_38\n",
      "Exception: File contains no section headers.\n",
      "file: PosixPath('/Users/saraawad/Desktop/flux-data-qaqc/sites/config/gridMET_data/US-Twt_38.1083N_-121.6417W.csv'), line: 1\n",
      "'date,gridMET_ETr,gridMET_prcp\\n'\n",
      "site id: US-Tw2_38\n",
      "Exception: File contains no section headers.\n",
      "file: PosixPath('/Users/saraawad/Desktop/flux-data-qaqc/sites/config/gridMET_data/US-Tw2_38.1083N_-121.6417W.csv'), line: 1\n",
      "'date,gridMET_ETr,gridMET_prcp\\n'\n",
      "site id: US-SO2_33\n",
      "Exception: File contains no section headers.\n",
      "file: PosixPath('/Users/saraawad/Desktop/flux-data-qaqc/sites/config/gridMET_data/US-SO2_33.3583N_-116.6417W.csv'), line: 1\n",
      "'date,gridMET_ETr,gridMET_prcp\\n'\n",
      "site id: US-Ced_39\n",
      "Exception: File contains no section headers.\n",
      "file: PosixPath('/Users/saraawad/Desktop/flux-data-qaqc/sites/config/gridMET_data/US-Ced_39.8583N_-74.3917W.csv'), line: 1\n",
      "'date,gridMET_ETr,gridMET_prcp\\n'\n",
      "site id: US-A74_36\n",
      "Exception: File contains no section headers.\n",
      "file: PosixPath('/Users/saraawad/Desktop/flux-data-qaqc/sites/config/gridMET_data/US-A74_36.8167N_-97.5583W.csv'), line: 1\n",
      "'date,gridMET_ETr,gridMET_prcp\\n'\n",
      "site id: US-Goo\n",
      "<fluxdataqaqc.data.Data object at 0x125768208>\n",
      "WARNING: the following config variables are missing in the input climate file:\n",
      "T_SONIC\n",
      "They will be filled with NaN values\n",
      "WARNING: renaming column G to input_G\n",
      "WARNING: renaming column LE to input_LE\n",
      "WARNING: renaming column H to input_H\n",
      "WARNING: t_avg variable in column T_SONIC is missing all data it will be removed\n",
      "Converting vpd from hpa to kpa\n",
      "\n",
      "The input data temporal frequency was not detected.\n",
      "WARNING: it looks like the input temporal frequency is greater than daily, downsampling, proceed with caution!\n",
      "\n",
      "Data is being resampled to daily temporal frequency.\n",
      "Linearly interpolating gaps in energy balance components up to 4 hours when Rn < 0 and up to 2 hours when Rn >= 0.\n",
      "gridMET reference ET already downloaded for station at:\n",
      "/Users/saraawad/Desktop/flux-data-qaqc/sites/config/gridMET_data/US-Goo_34.2750N_-89.8917W.csv\n",
      "not redownloading.\n",
      "Gap filling ET_corr with filtered ETrF x ETr (gridMET)\n",
      "site id: US-Shd\n",
      "<fluxdataqaqc.data.Data object at 0x124599a90>\n",
      "WARNING: the following config variables are missing in the input climate file:\n",
      "T_SONIC\n",
      "They will be filled with NaN values\n",
      "WARNING: renaming column G to input_G\n",
      "WARNING: renaming column LE to input_LE\n",
      "WARNING: renaming column H to input_H\n",
      "WARNING: t_avg variable in column T_SONIC is missing all data it will be removed\n",
      "Temporal frequency of data > hourly cannot calculate VP/VPD\n",
      "\n",
      "The input data temporal frequency was not detected.\n",
      "WARNING: it looks like the input temporal frequency is greater than daily, downsampling, proceed with caution!\n",
      "\n",
      "Data is being resampled to daily temporal frequency.\n",
      "Linearly interpolating gaps in energy balance components up to 4 hours when Rn < 0 and up to 2 hours when Rn >= 0.\n",
      "Converting vpd from hpa to kpa\n",
      "gridMET reference ET already downloaded for station at:\n",
      "/Users/saraawad/Desktop/flux-data-qaqc/sites/config/gridMET_data/US-Shd_36.9417N_-96.6833W.csv\n",
      "not redownloading.\n",
      "Gap filling ET_corr with filtered ETrF x ETr (gridMET)\n",
      "site id: US-AR2\n",
      "<fluxdataqaqc.data.Data object at 0x1235b7748>\n",
      "WARNING: the following config variables are missing in the input climate file:\n",
      "VPD_PI T_SONIC\n",
      "They will be filled with NaN values\n",
      "WARNING: renaming column G to input_G\n",
      "WARNING: renaming column LE to input_LE\n",
      "WARNING: renaming column H to input_H\n",
      "WARNING: vpd variable in column VPD_PI is missing all data it will be removed\n",
      "WARNING: t_avg variable in column T_SONIC is missing all data it will be removed\n",
      "\n",
      "The input data temporal frequency was not detected.\n",
      "Data is being resampled to daily temporal frequency.\n",
      "Linearly interpolating gaps in energy balance components up to 4 hours when Rn < 0 and up to 2 hours when Rn >= 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering days with less then 100.0% or 48/48 sub-daily measurements\n",
      "gridMET reference ET already downloaded for station at:\n",
      "/Users/saraawad/Desktop/flux-data-qaqc/sites/config/gridMET_data/US-AR2_36.6500N_-99.6000W.csv\n",
      "not redownloading.\n",
      "Gap filling ET_corr with filtered ETrF x ETr (gridMET)\n",
      "site id: US-AR1\n",
      "<fluxdataqaqc.data.Data object at 0x123b5a518>\n",
      "WARNING: the following config variables are missing in the input climate file:\n",
      "VPD_PI T_SONIC\n",
      "They will be filled with NaN values\n",
      "WARNING: renaming column G to input_G\n",
      "WARNING: renaming column LE to input_LE\n",
      "WARNING: renaming column H to input_H\n",
      "WARNING: vpd variable in column VPD_PI is missing all data it will be removed\n",
      "WARNING: t_avg variable in column T_SONIC is missing all data it will be removed\n",
      "\n",
      "The input data temporal frequency was not detected.\n",
      "Data is being resampled to daily temporal frequency.\n",
      "Linearly interpolating gaps in energy balance components up to 4 hours when Rn < 0 and up to 2 hours when Rn >= 0.\n",
      "Filtering days with less then 100.0% or 46/46 sub-daily measurements\n",
      "gridMET reference ET already downloaded for station at:\n",
      "/Users/saraawad/Desktop/flux-data-qaqc/sites/config/gridMET_data/US-AR1_36.4417N_-99.4333W.csv\n",
      "not redownloading.\n",
      "Gap filling ET_corr with filtered ETrF x ETr (gridMET)\n",
      "site id: US-SO2\n",
      "<fluxdataqaqc.data.Data object at 0x123b3dcc0>\n",
      "WARNING: the following config variables are missing in the input climate file:\n",
      "T_SONIC\n",
      "They will be filled with NaN values\n",
      "WARNING: renaming column G to input_G\n",
      "WARNING: renaming column LE to input_LE\n",
      "WARNING: renaming column H to input_H\n",
      "WARNING: t_avg variable in column T_SONIC is missing all data it will be removed\n",
      "Temporal frequency of data > hourly cannot calculate VP/VPD\n",
      "\n",
      "The input data temporal frequency was not detected.\n",
      "WARNING: it looks like the input temporal frequency is greater than daily, downsampling, proceed with caution!\n",
      "\n",
      "Data is being resampled to daily temporal frequency.\n",
      "Linearly interpolating gaps in energy balance components up to 4 hours when Rn < 0 and up to 2 hours when Rn >= 0.\n",
      "Converting vpd from hpa to kpa\n",
      "gridMET reference ET already downloaded for station at:\n",
      "/Users/saraawad/Desktop/flux-data-qaqc/sites/config/gridMET_data/US-SO2_33.3583N_-116.6417W.csv\n",
      "not redownloading.\n",
      "Gap filling ET_corr with filtered ETrF x ETr (gridMET)\n",
      "site id: US-Snd\n",
      "<fluxdataqaqc.data.Data object at 0x123599240>\n",
      "WARNING: the following config variables are missing in the input climate file:\n",
      "T_SONIC\n",
      "They will be filled with NaN values\n",
      "WARNING: renaming column G to input_G\n",
      "WARNING: renaming column LE to input_LE\n",
      "WARNING: renaming column H to input_H\n",
      "WARNING: t_avg variable in column T_SONIC is missing all data it will be removed\n",
      "Temporal frequency of data > hourly cannot calculate VP/VPD\n",
      "\n",
      "The input data temporal frequency was not detected.\n",
      "Data is being resampled to daily temporal frequency.\n",
      "Linearly interpolating gaps in energy balance components up to 4 hours when Rn < 0 and up to 2 hours when Rn >= 0.\n",
      "Filtering days with less then 100.0% or 17/17 sub-daily measurements\n",
      "Converting vpd from hpa to kpa\n",
      "gridMET reference ET already downloaded for station at:\n",
      "/Users/saraawad/Desktop/flux-data-qaqc/sites/config/gridMET_data/US-Snd_38.0250N_-121.7667W.csv\n",
      "not redownloading.\n",
      "Gap filling ET_corr with filtered ETrF x ETr (gridMET)\n",
      "site id: US-Ced\n",
      "<fluxdataqaqc.data.Data object at 0x123b5a668>\n",
      "WARNING: the following config variables are missing in the input climate file:\n",
      "T_SONIC\n",
      "They will be filled with NaN values\n",
      "WARNING: renaming column G to input_G\n",
      "WARNING: renaming column LE to input_LE\n",
      "WARNING: renaming column H to input_H\n",
      "WARNING: t_avg variable in column T_SONIC is missing all data it will be removed\n",
      "Converting vpd from hpa to kpa\n",
      "\n",
      "The input data temporal frequency was not detected.\n",
      "Data is being resampled to daily temporal frequency.\n",
      "Linearly interpolating gaps in energy balance components up to 4 hours when Rn < 0 and up to 2 hours when Rn >= 0.\n",
      "Filtering days with less then 100.0% or 45/45 sub-daily measurements\n",
      "gridMET reference ET already downloaded for station at:\n",
      "/Users/saraawad/Desktop/flux-data-qaqc/sites/config/gridMET_data/US-Ced_39.8583N_-74.3917W.csv\n",
      "not redownloading.\n",
      "Gap filling ET_corr with filtered ETrF x ETr (gridMET)\n",
      "site id: US-Wlr\n",
      "<fluxdataqaqc.data.Data object at 0x1111d8160>\n",
      "WARNING: the following config variables are missing in the input climate file:\n",
      "T_SONIC\n",
      "They will be filled with NaN values\n",
      "WARNING: renaming column G to input_G\n",
      "WARNING: renaming column LE to input_LE\n",
      "WARNING: renaming column H to input_H\n",
      "WARNING: t_avg variable in column T_SONIC is missing all data it will be removed\n",
      "\n",
      "The input data temporal frequency was not detected.\n",
      "Data is being resampled to daily temporal frequency.\n",
      "Linearly interpolating gaps in energy balance components up to 4 hours when Rn < 0 and up to 2 hours when Rn >= 0.\n",
      "Filtering days with less then 100.0% or 48/48 sub-daily measurements\n",
      "WARNING: unable to find/read gridMET file\n",
      " /Users/saraawad/Desktop/flux-data-qaqc/sites/config/gridMET_data/US-Wlr.csv\n",
      "Downloading gridMET var: daily_mean_reference_evapotranspiration_alfalfa\n",
      "\n",
      "Downloading gridMET var: precipitation_amount\n",
      "\n",
      "Gap filling ET_corr with filtered ETrF x ETr (gridMET)\n",
      "site id: US-A32\n",
      "<fluxdataqaqc.data.Data object at 0x124f6cf98>\n",
      "WARNING: renaming column G to input_G\n",
      "WARNING: renaming column LE to input_LE\n",
      "WARNING: renaming column H to input_H\n",
      "Temporal frequency of data > hourly cannot calculate VP/VPD\n",
      "\n",
      "The input data temporal frequency was not detected.\n",
      "WARNING: it looks like the input temporal frequency is greater than daily, downsampling, proceed with caution!\n",
      "\n",
      "Data is being resampled to daily temporal frequency.\n",
      "Linearly interpolating gaps in energy balance components up to 4 hours when Rn < 0 and up to 2 hours when Rn >= 0.\n",
      "WARNING: unable to find/read gridMET file\n",
      " /Users/saraawad/Desktop/flux-data-qaqc/sites/config/gridMET_data/US-A32.csv\n",
      "Downloading gridMET var: daily_mean_reference_evapotranspiration_alfalfa\n",
      "\n",
      "Downloading gridMET var: precipitation_amount\n",
      "\n",
      "Gap filling ET_corr with filtered ETrF x ETr (gridMET)\n",
      "site id: US-Pon\n",
      "<fluxdataqaqc.data.Data object at 0x124f6ceb8>\n",
      "WARNING: the following config variables are missing in the input climate file:\n",
      "T_SONIC\n",
      "They will be filled with NaN values\n",
      "WARNING: renaming column G to input_G\n",
      "WARNING: renaming column LE to input_LE\n",
      "WARNING: renaming column H to input_H\n",
      "WARNING: t_avg variable in column T_SONIC is missing all data it will be removed\n",
      "Temporal frequency of data > hourly cannot calculate VP/VPD\n",
      "\n",
      "The input data temporal frequency was not detected.\n",
      "WARNING: it looks like the input temporal frequency is greater than daily, downsampling, proceed with caution!\n",
      "\n",
      "Data is being resampled to daily temporal frequency.\n",
      "Linearly interpolating gaps in energy balance components up to 4 hours when Rn < 0 and up to 2 hours when Rn >= 0.\n",
      "Converting vpd from hpa to kpa\n",
      "WARNING: unable to find/read gridMET file\n",
      " /Users/saraawad/Desktop/flux-data-qaqc/sites/config/gridMET_data/US-Pon.csv\n",
      "Downloading gridMET var: daily_mean_reference_evapotranspiration_alfalfa\n",
      "\n",
      "Downloading gridMET var: precipitation_amount\n",
      "\n",
      "Gap filling ET_corr with filtered ETrF x ETr (gridMET)\n",
      "site id: US-Kon\n",
      "<fluxdataqaqc.data.Data object at 0x123599128>\n",
      "WARNING: the following config variables are missing in the input climate file:\n",
      "T_SONIC\n",
      "They will be filled with NaN values\n",
      "WARNING: renaming column G to input_G\n",
      "WARNING: renaming column LE to input_LE\n",
      "WARNING: renaming column H to input_H\n",
      "WARNING: t_avg variable in column T_SONIC is missing all data it will be removed\n",
      "Converting vpd from hpa to kpa\n",
      "\n",
      "The input data temporal frequency was not detected.\n",
      "WARNING: it looks like the input temporal frequency is greater than daily, downsampling, proceed with caution!\n",
      "\n",
      "Data is being resampled to daily temporal frequency.\n",
      "Linearly interpolating gaps in energy balance components up to 4 hours when Rn < 0 and up to 2 hours when Rn >= 0.\n",
      "WARNING: unable to find/read gridMET file\n",
      " /Users/saraawad/Desktop/flux-data-qaqc/sites/config/gridMET_data/US-Kon.csv\n",
      "Downloading gridMET var: daily_mean_reference_evapotranspiration_alfalfa\n",
      "\n",
      "Downloading gridMET var: precipitation_amount\n",
      "\n",
      "Gap filling ET_corr with filtered ETrF x ETr (gridMET)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "site id: US-Skr\n",
      "<fluxdataqaqc.data.Data object at 0x124b7b2e8>\n",
      "WARNING: the following config variables are missing in the input climate file:\n",
      "T_SONIC\n",
      "They will be filled with NaN values\n",
      "WARNING: renaming column G to input_G\n",
      "WARNING: renaming column LE to input_LE\n",
      "WARNING: renaming column H to input_H\n",
      "WARNING: t_avg variable in column T_SONIC is missing all data it will be removed\n",
      "Temporal frequency of data > hourly cannot calculate VP/VPD\n",
      "\n",
      "The input data temporal frequency was not detected.\n",
      "WARNING: it looks like the input temporal frequency is greater than daily, downsampling, proceed with caution!\n",
      "\n",
      "Data is being resampled to daily temporal frequency.\n",
      "Linearly interpolating gaps in energy balance components up to 4 hours when Rn < 0 and up to 2 hours when Rn >= 0.\n",
      "Converting vpd from hpa to kpa\n",
      "WARNING: unable to find/read gridMET file\n",
      " /Users/saraawad/Desktop/flux-data-qaqc/sites/config/gridMET_data/US-Skr.csv\n",
      "Downloading gridMET var: daily_mean_reference_evapotranspiration_alfalfa\n",
      "\n",
      "Downloading gridMET var: precipitation_amount\n",
      "\n",
      "Gap filling ET_corr with filtered ETrF x ETr (gridMET)\n",
      "site id: US-Bi2\n",
      "<fluxdataqaqc.data.Data object at 0x123603b38>\n",
      "WARNING: renaming column G to input_G\n",
      "WARNING: renaming column LE to input_LE\n",
      "WARNING: renaming column H to input_H\n",
      "Converting vpd from hpa to kpa\n",
      "Calculating vapor pressure from vapor pressure deficit and air temperature\n",
      "\n",
      "The input data temporal frequency was not detected.\n",
      "Data is being resampled to daily temporal frequency.\n",
      "Linearly interpolating gaps in energy balance components up to 4 hours when Rn < 0 and up to 2 hours when Rn >= 0.\n",
      "Filtering days with less then 100.0% or 33/33 sub-daily measurements\n",
      "WARNING: unable to find/read gridMET file\n",
      " /Users/saraawad/Desktop/flux-data-qaqc/sites/config/gridMET_data/US-Bi2.csv\n",
      "Downloading gridMET var: daily_mean_reference_evapotranspiration_alfalfa\n",
      "\n",
      "Downloading gridMET var: precipitation_amount\n",
      "\n",
      "Gap filling ET_corr with filtered ETrF x ETr (gridMET)\n",
      "site id: US-Var\n",
      "<fluxdataqaqc.data.Data object at 0x11a1c1160>\n",
      "WARNING: the following config variables are missing in the input climate file:\n",
      "SW_IN\n",
      "They will be filled with NaN values\n",
      "WARNING: renaming column G to input_G\n",
      "WARNING: renaming column LE to input_LE\n",
      "WARNING: renaming column H to input_H\n",
      "WARNING: sw_in variable in column SW_IN is missing all data it will be removed\n",
      "Temporal frequency of data > hourly cannot calculate VP/VPD\n",
      "\n",
      "The input data temporal frequency was not detected.\n",
      "WARNING: it looks like the input temporal frequency is greater than daily, downsampling, proceed with caution!\n",
      "\n",
      "Data is being resampled to daily temporal frequency.\n",
      "Linearly interpolating gaps in energy balance components up to 4 hours when Rn < 0 and up to 2 hours when Rn >= 0.\n",
      "Converting vpd from hpa to kpa\n",
      "WARNING: unable to find/read gridMET file\n",
      " /Users/saraawad/Desktop/flux-data-qaqc/sites/config/gridMET_data/US-Var.csv\n",
      "Downloading gridMET var: daily_mean_reference_evapotranspiration_alfalfa\n",
      "\n",
      "Downloading gridMET var: precipitation_amount\n",
      "\n",
      "Gap filling ET_corr with filtered ETrF x ETr (gridMET)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    input_name = os.path.join(\"/Users/saraawad/Desktop/flux-data-qaqc/sites/\", \"config/\")\n",
    "    output_name = os.path.join(\"/Users/saraawad/Desktop/flux-data-qaqc/sites/\", \"data/\")\n",
    "    correction_method = 1\n",
    "    gc = FluxQaQcCorrection(input_name, output_name, correction_method)\n",
    "    gc.generate_correction()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Bowen Ratio </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializer\n",
      "site id: US-Tw2\n",
      "<fluxdataqaqc.data.Data object at 0x123b42b38>\n",
      "WARNING: the following config variables are missing in the input climate file:\n",
      "T_SONIC\n",
      "They will be filled with NaN values\n",
      "WARNING: renaming column G to input_G\n",
      "WARNING: renaming column LE to input_LE\n",
      "WARNING: renaming column H to input_H\n",
      "WARNING: t_avg variable in column T_SONIC is missing all data it will be removed\n",
      "Converting vpd from hpa to kpa\n",
      "\n",
      "The input data temporal frequency was not detected.\n",
      "WARNING: it looks like the input temporal frequency is greater than daily, downsampling, proceed with caution!\n",
      "\n",
      "Data is being resampled to daily temporal frequency.\n",
      "Linearly interpolating gaps in energy balance components up to 4 hours when Rn < 0 and up to 2 hours when Rn >= 0.\n",
      "gridMET reference ET already downloaded for station at:\n",
      "/Users/saraawad/Desktop/flux-data-qaqc/sites/config/gridMET_data/US-Tw2_38.1083N_-121.6417W.csv\n",
      "not redownloading.\n",
      "Gap filling ET_corr with filtered ETrF x ETr (gridMET)\n",
      "site id: US-SP2\n",
      "<fluxdataqaqc.data.Data object at 0x12398acc0>\n",
      "WARNING: the following config variables are missing in the input climate file:\n",
      "T_SONIC\n",
      "They will be filled with NaN values\n",
      "WARNING: renaming column G to input_G\n",
      "WARNING: renaming column LE to input_LE\n",
      "WARNING: renaming column H to input_H\n",
      "WARNING: t_avg variable in column T_SONIC is missing all data it will be removed\n",
      "Converting vpd from hpa to kpa\n",
      "\n",
      "The input data temporal frequency was not detected.\n",
      "WARNING: it looks like the input temporal frequency is greater than daily, downsampling, proceed with caution!\n",
      "\n",
      "Data is being resampled to daily temporal frequency.\n",
      "Linearly interpolating gaps in energy balance components up to 4 hours when Rn < 0 and up to 2 hours when Rn >= 0.\n",
      "gridMET reference ET already downloaded for station at:\n",
      "/Users/saraawad/Desktop/flux-data-qaqc/sites/config/gridMET_data/US-SP2_29.7750N_-82.2250W.csv\n",
      "not redownloading.\n",
      "Gap filling ET_corr with filtered ETrF x ETr (gridMET)\n",
      "site id: US-A74\n",
      "<fluxdataqaqc.data.Data object at 0x123b5acf8>\n",
      "WARNING: renaming column G to input_G\n",
      "WARNING: renaming column LE to input_LE\n",
      "WARNING: renaming column H to input_H\n",
      "Temporal frequency of data > hourly cannot calculate VP/VPD\n",
      "\n",
      "The input data temporal frequency was not detected.\n",
      "WARNING: it looks like the input temporal frequency is greater than daily, downsampling, proceed with caution!\n",
      "\n",
      "Data is being resampled to daily temporal frequency.\n",
      "Linearly interpolating gaps in energy balance components up to 4 hours when Rn < 0 and up to 2 hours when Rn >= 0.\n",
      "gridMET reference ET already downloaded for station at:\n",
      "/Users/saraawad/Desktop/flux-data-qaqc/sites/config/gridMET_data/US-A74_36.8167N_-97.5583W.csv\n",
      "not redownloading.\n",
      "Gap filling ET_corr with filtered ETrF x ETr (gridMET)\n",
      "site id: US-Twt\n",
      "<fluxdataqaqc.data.Data object at 0x123599278>\n",
      "WARNING: renaming column G to input_G\n",
      "WARNING: renaming column LE to input_LE\n",
      "WARNING: renaming column H to input_H\n",
      "Converting vpd from hpa to kpa\n",
      "Calculating vapor pressure from vapor pressure deficit and air temperature\n",
      "\n",
      "The input data temporal frequency was not detected.\n",
      "Data is being resampled to daily temporal frequency.\n",
      "Linearly interpolating gaps in energy balance components up to 4 hours when Rn < 0 and up to 2 hours when Rn >= 0.\n",
      "Filtering days with less then 100.0% or 45/45 sub-daily measurements\n",
      "gridMET reference ET already downloaded for station at:\n",
      "/Users/saraawad/Desktop/flux-data-qaqc/sites/config/gridMET_data/US-Twt_38.1083N_-121.6417W.csv\n",
      "not redownloading.\n",
      "Gap filling ET_corr with filtered ETrF x ETr (gridMET)\n",
      "site id: US-Kon_39\n",
      "Exception: File contains no section headers.\n",
      "file: PosixPath('/Users/saraawad/Desktop/flux-data-qaqc/sites/config/gridMET_data/US-Kon_39.0667N_-96.5583W.csv'), line: 1\n",
      "'date,gridMET_ETr,gridMET_prcp\\n'\n",
      "site id: US-AR2_36\n",
      "Exception: File contains no section headers.\n",
      "file: PosixPath('/Users/saraawad/Desktop/flux-data-qaqc/sites/config/gridMET_data/US-AR2_36.6500N_-99.6000W.csv'), line: 1\n",
      "'date,gridMET_ETr,gridMET_prcp\\n'\n",
      "site id: US-Shd_36\n",
      "Exception: File contains no section headers.\n",
      "file: PosixPath('/Users/saraawad/Desktop/flux-data-qaqc/sites/config/gridMET_data/US-Shd_36.9417N_-96.6833W.csv'), line: 1\n",
      "'date,gridMET_ETr,gridMET_prcp\\n'\n",
      "site id: US-AR1_36\n",
      "Exception: File contains no section headers.\n",
      "file: PosixPath('/Users/saraawad/Desktop/flux-data-qaqc/sites/config/gridMET_data/US-AR1_36.4417N_-99.4333W.csv'), line: 1\n",
      "'date,gridMET_ETr,gridMET_prcp\\n'\n",
      "site id: US-Bi2_38\n",
      "Exception: File contains no section headers.\n",
      "file: PosixPath('/Users/saraawad/Desktop/flux-data-qaqc/sites/config/gridMET_data/US-Bi2_38.1083N_-121.5167W.csv'), line: 1\n",
      "'date,gridMET_ETr,gridMET_prcp\\n'\n",
      "site id: US-SP2_29\n",
      "Exception: File contains no section headers.\n",
      "file: PosixPath('/Users/saraawad/Desktop/flux-data-qaqc/sites/config/gridMET_data/US-SP2_29.7750N_-82.2250W.csv'), line: 1\n",
      "'date,gridMET_ETr,gridMET_prcp\\n'\n",
      "site id: US-Goo_34\n",
      "Exception: File contains no section headers.\n",
      "file: PosixPath('/Users/saraawad/Desktop/flux-data-qaqc/sites/config/gridMET_data/US-Goo_34.2750N_-89.8917W.csv'), line: 1\n",
      "'date,gridMET_ETr,gridMET_prcp\\n'\n",
      "site id: US-Snd_38\n",
      "Exception: File contains no section headers.\n",
      "file: PosixPath('/Users/saraawad/Desktop/flux-data-qaqc/sites/config/gridMET_data/US-Snd_38.0250N_-121.7667W.csv'), line: 1\n",
      "'date,gridMET_ETr,gridMET_prcp\\n'\n",
      "site id: US-Twt_38\n",
      "Exception: File contains no section headers.\n",
      "file: PosixPath('/Users/saraawad/Desktop/flux-data-qaqc/sites/config/gridMET_data/US-Twt_38.1083N_-121.6417W.csv'), line: 1\n",
      "'date,gridMET_ETr,gridMET_prcp\\n'\n",
      "site id: US-Pon_36\n",
      "Exception: File contains no section headers.\n",
      "file: PosixPath('/Users/saraawad/Desktop/flux-data-qaqc/sites/config/gridMET_data/US-Pon_36.7750N_-97.1417W.csv'), line: 1\n",
      "'date,gridMET_ETr,gridMET_prcp\\n'\n",
      "site id: US-Tw2_38\n",
      "Exception: File contains no section headers.\n",
      "file: PosixPath('/Users/saraawad/Desktop/flux-data-qaqc/sites/config/gridMET_data/US-Tw2_38.1083N_-121.6417W.csv'), line: 1\n",
      "'date,gridMET_ETr,gridMET_prcp\\n'\n",
      "site id: US-Skr_25\n",
      "Exception: File contains no section headers.\n",
      "file: PosixPath('/Users/saraawad/Desktop/flux-data-qaqc/sites/config/gridMET_data/US-Skr_25.3583N_-81.0583W.csv'), line: 1\n",
      "'date,gridMET_ETr,gridMET_prcp\\n'\n",
      "site id: US-SO2_33\n",
      "Exception: File contains no section headers.\n",
      "file: PosixPath('/Users/saraawad/Desktop/flux-data-qaqc/sites/config/gridMET_data/US-SO2_33.3583N_-116.6417W.csv'), line: 1\n",
      "'date,gridMET_ETr,gridMET_prcp\\n'\n",
      "site id: US-Ced_39\n",
      "Exception: File contains no section headers.\n",
      "file: PosixPath('/Users/saraawad/Desktop/flux-data-qaqc/sites/config/gridMET_data/US-Ced_39.8583N_-74.3917W.csv'), line: 1\n",
      "'date,gridMET_ETr,gridMET_prcp\\n'\n",
      "site id: US-Var_38\n",
      "Exception: File contains no section headers.\n",
      "file: PosixPath('/Users/saraawad/Desktop/flux-data-qaqc/sites/config/gridMET_data/US-Var_38.4000N_-120.9333W.csv'), line: 1\n",
      "'date,gridMET_ETr,gridMET_prcp\\n'\n",
      "site id: US-Wlr_37\n",
      "Exception: File contains no section headers.\n",
      "file: PosixPath('/Users/saraawad/Desktop/flux-data-qaqc/sites/config/gridMET_data/US-Wlr_37.5250N_-96.8500W.csv'), line: 1\n",
      "'date,gridMET_ETr,gridMET_prcp\\n'\n",
      "site id: US-A74_36\n",
      "Exception: File contains no section headers.\n",
      "file: PosixPath('/Users/saraawad/Desktop/flux-data-qaqc/sites/config/gridMET_data/US-A74_36.8167N_-97.5583W.csv'), line: 1\n",
      "'date,gridMET_ETr,gridMET_prcp\\n'\n",
      "site id: US-A32_36\n",
      "Exception: File contains no section headers.\n",
      "file: PosixPath('/Users/saraawad/Desktop/flux-data-qaqc/sites/config/gridMET_data/US-A32_36.8167N_-97.8083W.csv'), line: 1\n",
      "'date,gridMET_ETr,gridMET_prcp\\n'\n",
      "site id: US-Goo\n",
      "<fluxdataqaqc.data.Data object at 0x124599e10>\n",
      "WARNING: the following config variables are missing in the input climate file:\n",
      "T_SONIC\n",
      "They will be filled with NaN values\n",
      "WARNING: renaming column G to input_G\n",
      "WARNING: renaming column LE to input_LE\n",
      "WARNING: renaming column H to input_H\n",
      "WARNING: t_avg variable in column T_SONIC is missing all data it will be removed\n",
      "Converting vpd from hpa to kpa\n",
      "\n",
      "The input data temporal frequency was not detected.\n",
      "WARNING: it looks like the input temporal frequency is greater than daily, downsampling, proceed with caution!\n",
      "\n",
      "Data is being resampled to daily temporal frequency.\n",
      "Linearly interpolating gaps in energy balance components up to 4 hours when Rn < 0 and up to 2 hours when Rn >= 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gridMET reference ET already downloaded for station at:\n",
      "/Users/saraawad/Desktop/flux-data-qaqc/sites/config/gridMET_data/US-Goo_34.2750N_-89.8917W.csv\n",
      "not redownloading.\n",
      "Gap filling ET_corr with filtered ETrF x ETr (gridMET)\n",
      "site id: US-Shd\n",
      "<fluxdataqaqc.data.Data object at 0x124aeaef0>\n",
      "WARNING: the following config variables are missing in the input climate file:\n",
      "T_SONIC\n",
      "They will be filled with NaN values\n",
      "WARNING: renaming column G to input_G\n",
      "WARNING: renaming column LE to input_LE\n",
      "WARNING: renaming column H to input_H\n",
      "WARNING: t_avg variable in column T_SONIC is missing all data it will be removed\n",
      "Temporal frequency of data > hourly cannot calculate VP/VPD\n",
      "\n",
      "The input data temporal frequency was not detected.\n",
      "WARNING: it looks like the input temporal frequency is greater than daily, downsampling, proceed with caution!\n",
      "\n",
      "Data is being resampled to daily temporal frequency.\n",
      "Linearly interpolating gaps in energy balance components up to 4 hours when Rn < 0 and up to 2 hours when Rn >= 0.\n",
      "Converting vpd from hpa to kpa\n",
      "gridMET reference ET already downloaded for station at:\n",
      "/Users/saraawad/Desktop/flux-data-qaqc/sites/config/gridMET_data/US-Shd_36.9417N_-96.6833W.csv\n",
      "not redownloading.\n",
      "Gap filling ET_corr with filtered ETrF x ETr (gridMET)\n",
      "site id: US-AR2\n",
      "<fluxdataqaqc.data.Data object at 0x1235992b0>\n",
      "WARNING: the following config variables are missing in the input climate file:\n",
      "VPD_PI T_SONIC\n",
      "They will be filled with NaN values\n",
      "WARNING: renaming column G to input_G\n",
      "WARNING: renaming column LE to input_LE\n",
      "WARNING: renaming column H to input_H\n",
      "WARNING: vpd variable in column VPD_PI is missing all data it will be removed\n",
      "WARNING: t_avg variable in column T_SONIC is missing all data it will be removed\n",
      "\n",
      "The input data temporal frequency was not detected.\n",
      "Data is being resampled to daily temporal frequency.\n",
      "Linearly interpolating gaps in energy balance components up to 4 hours when Rn < 0 and up to 2 hours when Rn >= 0.\n",
      "Filtering days with less then 100.0% or 48/48 sub-daily measurements\n",
      "gridMET reference ET already downloaded for station at:\n",
      "/Users/saraawad/Desktop/flux-data-qaqc/sites/config/gridMET_data/US-AR2_36.6500N_-99.6000W.csv\n",
      "not redownloading.\n",
      "Gap filling ET_corr with filtered ETrF x ETr (gridMET)\n",
      "site id: US-AR1\n",
      "<fluxdataqaqc.data.Data object at 0x123969a58>\n",
      "WARNING: the following config variables are missing in the input climate file:\n",
      "VPD_PI T_SONIC\n",
      "They will be filled with NaN values\n",
      "WARNING: renaming column G to input_G\n",
      "WARNING: renaming column LE to input_LE\n",
      "WARNING: renaming column H to input_H\n",
      "WARNING: vpd variable in column VPD_PI is missing all data it will be removed\n",
      "WARNING: t_avg variable in column T_SONIC is missing all data it will be removed\n",
      "\n",
      "The input data temporal frequency was not detected.\n",
      "Data is being resampled to daily temporal frequency.\n",
      "Linearly interpolating gaps in energy balance components up to 4 hours when Rn < 0 and up to 2 hours when Rn >= 0.\n",
      "Filtering days with less then 100.0% or 46/46 sub-daily measurements\n",
      "gridMET reference ET already downloaded for station at:\n",
      "/Users/saraawad/Desktop/flux-data-qaqc/sites/config/gridMET_data/US-AR1_36.4417N_-99.4333W.csv\n",
      "not redownloading.\n",
      "Gap filling ET_corr with filtered ETrF x ETr (gridMET)\n",
      "site id: US-SO2\n",
      "<fluxdataqaqc.data.Data object at 0x123964e48>\n",
      "WARNING: the following config variables are missing in the input climate file:\n",
      "T_SONIC\n",
      "They will be filled with NaN values\n",
      "WARNING: renaming column G to input_G\n",
      "WARNING: renaming column LE to input_LE\n",
      "WARNING: renaming column H to input_H\n",
      "WARNING: t_avg variable in column T_SONIC is missing all data it will be removed\n",
      "Temporal frequency of data > hourly cannot calculate VP/VPD\n",
      "\n",
      "The input data temporal frequency was not detected.\n",
      "WARNING: it looks like the input temporal frequency is greater than daily, downsampling, proceed with caution!\n",
      "\n",
      "Data is being resampled to daily temporal frequency.\n",
      "Linearly interpolating gaps in energy balance components up to 4 hours when Rn < 0 and up to 2 hours when Rn >= 0.\n",
      "Converting vpd from hpa to kpa\n",
      "gridMET reference ET already downloaded for station at:\n",
      "/Users/saraawad/Desktop/flux-data-qaqc/sites/config/gridMET_data/US-SO2_33.3583N_-116.6417W.csv\n",
      "not redownloading.\n",
      "Gap filling ET_corr with filtered ETrF x ETr (gridMET)\n",
      "site id: US-A32_monthly_data\n",
      "Exception: File contains no section headers.\n",
      "file: PosixPath('/Users/saraawad/Desktop/flux-data-qaqc/sites/config/output/EBR/US-A32_monthly_data.csv'), line: 1\n",
      "'date,SW_IN,NETRAD,ebr_5day_clim,input_LE,ebr,RH,rso,LW_OUT,flux_corr,flux,WS,SW_OUT,ebr_corr,ETrF_filtered,T_SONIC,input_G,ebc_cf,ETrF,LW_IN,energy,H_corr,input_H,LE_corr,gridMET_prcp,ET_fill_val,ET_gap,Rn_subday_gaps,H_subday_gaps,LE_subday_gaps,ET_corr,ET_fill,G_subday_gaps,ET,gridMET_ETr\\n'\n",
      "site id: US-Ced_daily_data\n",
      "Exception: File contains no section headers.\n",
      "file: PosixPath('/Users/saraawad/Desktop/flux-data-qaqc/sites/config/output/EBR/US-Ced_daily_data.csv'), line: 1\n",
      "'date,SW_IN,NETRAD,VPD_PI,input_G,input_LE,RH,input_H,WS,Rn_subday_gaps,G_subday_gaps,H_subday_gaps,LE_subday_gaps,rso,flux,energy,ebr_5day_clim,ebc_cf,H_corr,ebr,ebr_corr,flux_corr,LE_corr,ET,ET_corr,gridMET_ETr,gridMET_prcp,ETrF,ETrF_filtered,ET_fill,ET_gap,ET_fill_val\\n'\n",
      "site id: US-Var_monthly_data\n",
      "Exception: File contains no section headers.\n",
      "file: PosixPath('/Users/saraawad/Desktop/flux-data-qaqc/sites/config/output/EBR/US-Var_monthly_data.csv'), line: 1\n",
      "'date,NETRAD,ebr_5day_clim,input_LE,ebr,RH,rso,LW_OUT,flux_corr,flux,WS,SW_OUT,ebr_corr,ETrF_filtered,T_SONIC,VPD_PI,input_G,ebc_cf,ETrF,LW_IN,energy,H_corr,input_H,LE_corr,gridMET_prcp,ET_fill_val,ET_gap,Rn_subday_gaps,H_subday_gaps,LE_subday_gaps,ET_corr,ET_fill,G_subday_gaps,ET,gridMET_ETr\\n'\n",
      "site id: US-Pon_monthly_data\n",
      "Exception: File contains no section headers.\n",
      "file: PosixPath('/Users/saraawad/Desktop/flux-data-qaqc/sites/config/output/EBR/US-Pon_monthly_data.csv'), line: 1\n",
      "'date,SW_IN,NETRAD,ebr_5day_clim,input_LE,ebr,RH,rso,flux_corr,flux,WS,SW_OUT,ebr_corr,ETrF_filtered,VPD_PI,input_G,ebc_cf,ETrF,H_corr,energy,input_H,LE_corr,gridMET_prcp,ET_fill_val,ET_gap,Rn_subday_gaps,H_subday_gaps,LE_subday_gaps,ET_corr,ET_fill,G_subday_gaps,ET,gridMET_ETr\\n'\n",
      "site id: US-Wlr_monthly_data\n",
      "Exception: File contains no section headers.\n",
      "file: PosixPath('/Users/saraawad/Desktop/flux-data-qaqc/sites/config/output/EBR/US-Wlr_monthly_data.csv'), line: 1\n",
      "'date,SW_IN,NETRAD,ebr_5day_clim,SW_OUT,input_G,ebc_cf,ETrF,rso,input_LE,H_corr,energy,ebr,LE_corr,ebr_corr,flux_corr,flux,input_H,ETrF_filtered,RH,WS,gridMET_prcp,ET_fill_val,ET_gap,Rn_subday_gaps,H_subday_gaps,LE_subday_gaps,ET_corr,ET_fill,G_subday_gaps,ET,gridMET_ETr\\n'\n",
      "site id: US-Shd_monthly_data\n",
      "Exception: File contains no section headers.\n",
      "file: PosixPath('/Users/saraawad/Desktop/flux-data-qaqc/sites/config/output/EBR/US-Shd_monthly_data.csv'), line: 1\n",
      "'date,SW_IN,NETRAD,ebr_5day_clim,input_LE,ebr,RH,rso,flux_corr,flux,WS,SW_OUT,ebr_corr,ETrF_filtered,VPD_PI,input_G,ebc_cf,ETrF,H_corr,energy,input_H,LE_corr,gridMET_prcp,ET_fill_val,ET_gap,Rn_subday_gaps,H_subday_gaps,LE_subday_gaps,ET_corr,ET_fill,G_subday_gaps,ET,gridMET_ETr\\n'\n",
      "site id: US-A74_daily_data\n",
      "Exception: File contains no section headers.\n",
      "file: PosixPath('/Users/saraawad/Desktop/flux-data-qaqc/sites/config/output/EBR/US-A74_daily_data.csv'), line: 1\n",
      "'date,T_SONIC,SW_IN,NETRAD,SW_OUT,input_G,input_LE,LW_IN,LW_OUT,input_H,RH,WS,Rn_subday_gaps,G_subday_gaps,H_subday_gaps,LE_subday_gaps,rso,flux,energy,ebr_5day_clim,ebc_cf,H_corr,ebr,ebr_corr,flux_corr,LE_corr,ET,ET_corr,gridMET_ETr,gridMET_prcp,ETrF,ETrF_filtered,ET_fill,ET_gap,ET_fill_val\\n'\n",
      "site id: US-Twt_daily_data\n",
      "Exception: File contains no section headers.\n",
      "file: PosixPath('/Users/saraawad/Desktop/flux-data-qaqc/sites/config/output/EBR/US-Twt_daily_data.csv'), line: 1\n",
      "'date,T_SONIC,NETRAD,SW_IN,VPD_PI,input_G,input_LE,vp,input_H,RH,WS,Rn_subday_gaps,G_subday_gaps,H_subday_gaps,LE_subday_gaps,rso,flux,energy,ebr_5day_clim,ebc_cf,H_corr,ebr,ebr_corr,flux_corr,LE_corr,ET,ET_corr,gridMET_ETr,gridMET_prcp,ETrF,ETrF_filtered,ET_fill,ET_gap,ET_fill_val\\n'\n",
      "site id: US-Goo_monthly_data\n",
      "Exception: File contains no section headers.\n",
      "file: PosixPath('/Users/saraawad/Desktop/flux-data-qaqc/sites/config/output/EBR/US-Goo_monthly_data.csv'), line: 1\n",
      "'date,SW_IN,NETRAD,ebr_5day_clim,input_LE,ebr,RH,rso,LW_OUT,flux_corr,flux,WS,SW_OUT,ebr_corr,ETrF_filtered,VPD_PI,input_G,ebc_cf,ETrF,LW_IN,energy,H_corr,input_H,LE_corr,gridMET_prcp,ET_fill_val,ET_gap,Rn_subday_gaps,H_subday_gaps,LE_subday_gaps,ET_corr,ET_fill,G_subday_gaps,ET,gridMET_ETr\\n'\n",
      "site id: US-Var_daily_data\n",
      "Exception: File contains no section headers.\n",
      "file: PosixPath('/Users/saraawad/Desktop/flux-data-qaqc/sites/config/output/EBR/US-Var_daily_data.csv'), line: 1\n",
      "'date,T_SONIC,NETRAD,SW_OUT,VPD_PI,input_G,input_LE,LW_IN,LW_OUT,RH,input_H,WS,Rn_subday_gaps,G_subday_gaps,H_subday_gaps,LE_subday_gaps,rso,flux,energy,ebr_5day_clim,ebc_cf,H_corr,ebr,ebr_corr,flux_corr,LE_corr,ET,ET_corr,gridMET_ETr,gridMET_prcp,ETrF,ETrF_filtered,ET_fill,ET_gap,ET_fill_val\\n'\n",
      "site id: US-SO2_daily_data\n",
      "Exception: File contains no section headers.\n",
      "file: PosixPath('/Users/saraawad/Desktop/flux-data-qaqc/sites/config/output/EBR/US-SO2_daily_data.csv'), line: 1\n",
      "'date,SW_IN,NETRAD,VPD_PI,input_G,input_LE,RH,input_H,WS,Rn_subday_gaps,G_subday_gaps,H_subday_gaps,LE_subday_gaps,rso,flux,energy,ebr_5day_clim,ebc_cf,H_corr,ebr,ebr_corr,flux_corr,LE_corr,ET,ET_corr,gridMET_ETr,gridMET_prcp,ETrF,ETrF_filtered,ET_fill,ET_gap,ET_fill_val\\n'\n",
      "site id: US-SP2_monthly_data\n",
      "Exception: File contains no section headers.\n",
      "file: PosixPath('/Users/saraawad/Desktop/flux-data-qaqc/sites/config/output/EBR/US-SP2_monthly_data.csv'), line: 1\n",
      "'date,SW_IN,NETRAD,ebr_5day_clim,VPD_PI,input_G,ebc_cf,ETrF,rso,input_LE,H_corr,energy,ebr,LE_corr,ebr_corr,flux_corr,flux,input_H,ETrF_filtered,RH,WS,gridMET_prcp,ET_fill_val,ET_gap,Rn_subday_gaps,H_subday_gaps,LE_subday_gaps,ET_corr,ET_fill,G_subday_gaps,ET,gridMET_ETr\\n'\n",
      "site id: US-Kon_daily_data\n",
      "Exception: File contains no section headers.\n",
      "file: PosixPath('/Users/saraawad/Desktop/flux-data-qaqc/sites/config/output/EBR/US-Kon_daily_data.csv'), line: 1\n",
      "'date,SW_IN,NETRAD,SW_OUT,VPD_PI,input_G,input_LE,RH,input_H,WS,Rn_subday_gaps,G_subday_gaps,H_subday_gaps,LE_subday_gaps,rso,flux,energy,ebr_5day_clim,ebc_cf,H_corr,ebr,ebr_corr,flux_corr,LE_corr,ET,ET_corr,gridMET_ETr,gridMET_prcp,ETrF,ETrF_filtered,ET_fill,ET_gap,ET_fill_val\\n'\n",
      "site id: US-Snd_monthly_data\n",
      "Exception: File contains no section headers.\n",
      "file: PosixPath('/Users/saraawad/Desktop/flux-data-qaqc/sites/config/output/EBR/US-Snd_monthly_data.csv'), line: 1\n",
      "'date,SW_IN,NETRAD,ebr_5day_clim,VPD_PI,input_G,ebc_cf,ETrF,rso,input_LE,H_corr,energy,ebr,LE_corr,ebr_corr,flux_corr,flux,input_H,ETrF_filtered,RH,WS,gridMET_prcp,ET_fill_val,ET_gap,Rn_subday_gaps,H_subday_gaps,LE_subday_gaps,ET_corr,ET_fill,G_subday_gaps,ET,gridMET_ETr\\n'\n",
      "site id: US-AR2_monthly_data\n",
      "Exception: File contains no section headers.\n",
      "file: PosixPath('/Users/saraawad/Desktop/flux-data-qaqc/sites/config/output/EBR/US-AR2_monthly_data.csv'), line: 1\n",
      "'date,SW_IN,NETRAD,ebr_5day_clim,input_LE,ebr,RH,rso,LW_OUT,flux_corr,flux,WS,SW_OUT,ebr_corr,ETrF_filtered,input_G,ebc_cf,ETrF,LW_IN,energy,H_corr,input_H,LE_corr,gridMET_prcp,ET_fill_val,ET_gap,Rn_subday_gaps,H_subday_gaps,LE_subday_gaps,ET_corr,ET_fill,G_subday_gaps,ET,gridMET_ETr\\n'\n",
      "site id: US-Tw2_daily_data\n",
      "Exception: File contains no section headers.\n",
      "file: PosixPath('/Users/saraawad/Desktop/flux-data-qaqc/sites/config/output/EBR/US-Tw2_daily_data.csv'), line: 1\n",
      "'date,SW_IN,NETRAD,SW_OUT,VPD_PI,input_G,input_LE,LW_IN,LW_OUT,RH,input_H,WS,Rn_subday_gaps,G_subday_gaps,H_subday_gaps,LE_subday_gaps,rso,flux,energy,ebr_5day_clim,ebc_cf,H_corr,ebr,ebr_corr,flux_corr,LE_corr,ET,ET_corr,gridMET_ETr,gridMET_prcp,ETrF,ETrF_filtered,ET_fill,ET_gap,ET_fill_val\\n'\n",
      "site id: US-Pon_daily_data\n",
      "Exception: File contains no section headers.\n",
      "file: PosixPath('/Users/saraawad/Desktop/flux-data-qaqc/sites/config/output/EBR/US-Pon_daily_data.csv'), line: 1\n",
      "'date,SW_IN,NETRAD,SW_OUT,VPD_PI,input_G,input_LE,RH,input_H,WS,Rn_subday_gaps,G_subday_gaps,H_subday_gaps,LE_subday_gaps,rso,flux,energy,ebr_5day_clim,ebc_cf,H_corr,ebr,ebr_corr,flux_corr,LE_corr,ET,ET_corr,gridMET_ETr,gridMET_prcp,ETrF,ETrF_filtered,ET_fill,ET_gap,ET_fill_val\\n'\n",
      "site id: US-Ced_monthly_data\n",
      "Exception: File contains no section headers.\n",
      "file: PosixPath('/Users/saraawad/Desktop/flux-data-qaqc/sites/config/output/EBR/US-Ced_monthly_data.csv'), line: 1\n",
      "'date,SW_IN,NETRAD,ebr_5day_clim,VPD_PI,input_G,ebc_cf,ETrF,rso,input_LE,H_corr,energy,ebr,LE_corr,ebr_corr,flux_corr,flux,input_H,ETrF_filtered,RH,WS,gridMET_prcp,ET_fill_val,ET_gap,Rn_subday_gaps,H_subday_gaps,LE_subday_gaps,ET_corr,ET_fill,G_subday_gaps,ET,gridMET_ETr\\n'\n",
      "site id: US-SO2_monthly_data\n",
      "Exception: File contains no section headers.\n",
      "file: PosixPath('/Users/saraawad/Desktop/flux-data-qaqc/sites/config/output/EBR/US-SO2_monthly_data.csv'), line: 1\n",
      "'date,SW_IN,NETRAD,ebr_5day_clim,VPD_PI,input_G,ebc_cf,ETrF,rso,input_LE,H_corr,energy,ebr,LE_corr,ebr_corr,flux_corr,flux,input_H,ETrF_filtered,RH,WS,gridMET_prcp,ET_fill_val,ET_gap,Rn_subday_gaps,H_subday_gaps,LE_subday_gaps,ET_corr,ET_fill,G_subday_gaps,ET,gridMET_ETr\\n'\n",
      "site id: US-Bi2_monthly_data\n",
      "Exception: File contains no section headers.\n",
      "file: PosixPath('/Users/saraawad/Desktop/flux-data-qaqc/sites/config/output/EBR/US-Bi2_monthly_data.csv'), line: 1\n",
      "'date,SW_IN,NETRAD,ebr_5day_clim,input_LE,ebr,RH,rso,LW_OUT,flux_corr,flux,WS,SW_OUT,vp,ebr_corr,ETrF_filtered,T_SONIC,VPD_PI,input_G,ebc_cf,ETrF,LW_IN,energy,H_corr,input_H,LE_corr,gridMET_prcp,ET_fill_val,ET_gap,Rn_subday_gaps,H_subday_gaps,LE_subday_gaps,ET_corr,ET_fill,G_subday_gaps,ET,gridMET_ETr\\n'\n",
      "site id: US-Bi2_daily_data\n",
      "Exception: File contains no section headers.\n",
      "file: PosixPath('/Users/saraawad/Desktop/flux-data-qaqc/sites/config/output/EBR/US-Bi2_daily_data.csv'), line: 1\n",
      "'date,T_SONIC,NETRAD,SW_IN,SW_OUT,VPD_PI,input_G,input_LE,LW_IN,LW_OUT,vp,input_H,RH,WS,Rn_subday_gaps,G_subday_gaps,H_subday_gaps,LE_subday_gaps,rso,flux,energy,ebr_5day_clim,ebc_cf,H_corr,ebr,ebr_corr,flux_corr,LE_corr,ET,ET_corr,gridMET_ETr,gridMET_prcp,ETrF,ETrF_filtered,ET_fill,ET_gap,ET_fill_val\\n'\n",
      "site id: US-A32_daily_data\n",
      "Exception: File contains no section headers.\n",
      "file: PosixPath('/Users/saraawad/Desktop/flux-data-qaqc/sites/config/output/EBR/US-A32_daily_data.csv'), line: 1\n",
      "'date,T_SONIC,SW_IN,NETRAD,SW_OUT,input_G,input_LE,LW_IN,LW_OUT,input_H,RH,WS,Rn_subday_gaps,G_subday_gaps,H_subday_gaps,LE_subday_gaps,rso,flux,energy,ebr_5day_clim,ebc_cf,H_corr,ebr,ebr_corr,flux_corr,LE_corr,ET,ET_corr,gridMET_ETr,gridMET_prcp,ETrF,ETrF_filtered,ET_fill,ET_gap,ET_fill_val\\n'\n",
      "site id: US-AR1_monthly_data\n",
      "Exception: File contains no section headers.\n",
      "file: PosixPath('/Users/saraawad/Desktop/flux-data-qaqc/sites/config/output/EBR/US-AR1_monthly_data.csv'), line: 1\n",
      "'date,SW_IN,NETRAD,ebr_5day_clim,input_LE,ebr,RH,rso,LW_OUT,flux_corr,flux,WS,SW_OUT,ebr_corr,ETrF_filtered,input_G,ebc_cf,ETrF,LW_IN,energy,H_corr,input_H,LE_corr,gridMET_prcp,ET_fill_val,ET_gap,Rn_subday_gaps,H_subday_gaps,LE_subday_gaps,ET_corr,ET_fill,G_subday_gaps,ET,gridMET_ETr\\n'\n",
      "site id: US-AR1_daily_data\n",
      "Exception: File contains no section headers.\n",
      "file: PosixPath('/Users/saraawad/Desktop/flux-data-qaqc/sites/config/output/EBR/US-AR1_daily_data.csv'), line: 1\n",
      "'date,SW_IN,NETRAD,SW_OUT,input_G,input_LE,LW_IN,LW_OUT,RH,input_H,WS,Rn_subday_gaps,G_subday_gaps,H_subday_gaps,LE_subday_gaps,rso,flux,energy,ebr_5day_clim,ebc_cf,H_corr,ebr,ebr_corr,flux_corr,LE_corr,ET,ET_corr,gridMET_ETr,gridMET_prcp,ETrF,ETrF_filtered,ET_fill,ET_gap,ET_fill_val\\n'\n",
      "site id: US-A74_monthly_data\n",
      "Exception: File contains no section headers.\n",
      "file: PosixPath('/Users/saraawad/Desktop/flux-data-qaqc/sites/config/output/EBR/US-A74_monthly_data.csv'), line: 1\n",
      "'date,SW_IN,NETRAD,ebr_5day_clim,input_LE,ebr,RH,rso,LW_OUT,flux_corr,flux,WS,SW_OUT,ebr_corr,ETrF_filtered,T_SONIC,input_G,ebc_cf,ETrF,LW_IN,energy,H_corr,input_H,LE_corr,gridMET_prcp,ET_fill_val,ET_gap,Rn_subday_gaps,H_subday_gaps,LE_subday_gaps,ET_corr,ET_fill,G_subday_gaps,ET,gridMET_ETr\\n'\n",
      "site id: US-Tw2_monthly_data\n",
      "Exception: File contains no section headers.\n",
      "file: PosixPath('/Users/saraawad/Desktop/flux-data-qaqc/sites/config/output/EBR/US-Tw2_monthly_data.csv'), line: 1\n",
      "'date,SW_IN,NETRAD,ebr_5day_clim,input_LE,ebr,RH,rso,LW_OUT,flux_corr,flux,WS,SW_OUT,ebr_corr,ETrF_filtered,VPD_PI,input_G,ebc_cf,ETrF,LW_IN,energy,H_corr,input_H,LE_corr,gridMET_prcp,ET_fill_val,ET_gap,Rn_subday_gaps,H_subday_gaps,LE_subday_gaps,ET_corr,ET_fill,G_subday_gaps,ET,gridMET_ETr\\n'\n",
      "site id: US-Goo_daily_data\n",
      "Exception: File contains no section headers.\n",
      "file: PosixPath('/Users/saraawad/Desktop/flux-data-qaqc/sites/config/output/EBR/US-Goo_daily_data.csv'), line: 1\n",
      "'date,SW_IN,NETRAD,SW_OUT,VPD_PI,input_G,input_LE,LW_IN,LW_OUT,RH,input_H,WS,Rn_subday_gaps,G_subday_gaps,H_subday_gaps,LE_subday_gaps,rso,flux,energy,ebr_5day_clim,ebc_cf,H_corr,ebr,ebr_corr,flux_corr,LE_corr,ET,ET_corr,gridMET_ETr,gridMET_prcp,ETrF,ETrF_filtered,ET_fill,ET_gap,ET_fill_val\\n'\n",
      "site id: US-Twt_monthly_data\n",
      "Exception: File contains no section headers.\n",
      "file: PosixPath('/Users/saraawad/Desktop/flux-data-qaqc/sites/config/output/EBR/US-Twt_monthly_data.csv'), line: 1\n",
      "'date,SW_IN,NETRAD,ebr_5day_clim,input_LE,ebr,RH,rso,flux_corr,flux,WS,vp,ebr_corr,ETrF_filtered,T_SONIC,VPD_PI,input_G,ebc_cf,ETrF,H_corr,energy,input_H,LE_corr,gridMET_prcp,ET_fill_val,ET_gap,Rn_subday_gaps,H_subday_gaps,LE_subday_gaps,ET_corr,ET_fill,G_subday_gaps,ET,gridMET_ETr\\n'\n",
      "site id: US-SP2_daily_data\n",
      "Exception: File contains no section headers.\n",
      "file: PosixPath('/Users/saraawad/Desktop/flux-data-qaqc/sites/config/output/EBR/US-SP2_daily_data.csv'), line: 1\n",
      "'date,SW_IN,NETRAD,VPD_PI,input_G,input_LE,RH,input_H,WS,Rn_subday_gaps,G_subday_gaps,H_subday_gaps,LE_subday_gaps,rso,flux,energy,ebr_5day_clim,ebc_cf,H_corr,ebr,ebr_corr,flux_corr,LE_corr,ET,ET_corr,gridMET_ETr,gridMET_prcp,ETrF,ETrF_filtered,ET_fill,ET_gap,ET_fill_val\\n'\n",
      "site id: US-Snd_daily_data\n",
      "Exception: File contains no section headers.\n",
      "file: PosixPath('/Users/saraawad/Desktop/flux-data-qaqc/sites/config/output/EBR/US-Snd_daily_data.csv'), line: 1\n",
      "'date,SW_IN,NETRAD,VPD_PI,input_G,input_LE,RH,input_H,WS,Rn_subday_gaps,G_subday_gaps,H_subday_gaps,LE_subday_gaps,rso,flux,energy,ebr_5day_clim,ebc_cf,H_corr,ebr,ebr_corr,flux_corr,LE_corr,ET,ET_corr,gridMET_ETr,gridMET_prcp,ETrF,ETrF_filtered,ET_fill,ET_gap,ET_fill_val\\n'\n",
      "site id: US-Wlr_daily_data\n",
      "Exception: File contains no section headers.\n",
      "file: PosixPath('/Users/saraawad/Desktop/flux-data-qaqc/sites/config/output/EBR/US-Wlr_daily_data.csv'), line: 1\n",
      "'date,SW_IN,NETRAD,SW_OUT,input_G,input_LE,RH,input_H,WS,Rn_subday_gaps,G_subday_gaps,H_subday_gaps,LE_subday_gaps,rso,flux,energy,ebr_5day_clim,ebc_cf,H_corr,ebr,ebr_corr,flux_corr,LE_corr,ET,ET_corr,gridMET_ETr,gridMET_prcp,ETrF,ETrF_filtered,ET_fill,ET_gap,ET_fill_val\\n'\n",
      "site id: US-Skr_daily_data\n",
      "Exception: File contains no section headers.\n",
      "file: PosixPath('/Users/saraawad/Desktop/flux-data-qaqc/sites/config/output/EBR/US-Skr_daily_data.csv'), line: 1\n",
      "'date,SW_IN,NETRAD,SW_OUT,VPD_PI,input_G,input_LE,LW_IN,LW_OUT,RH,input_H,WS,Rn_subday_gaps,G_subday_gaps,H_subday_gaps,LE_subday_gaps,rso,flux,energy,ebr_5day_clim,ebc_cf,H_corr,ebr,ebr_corr,flux_corr,LE_corr,ET,ET_corr,gridMET_ETr,gridMET_prcp,ETrF,ETrF_filtered,ET_fill,ET_gap,ET_fill_val\\n'\n",
      "site id: US-Skr_monthly_data\n",
      "Exception: File contains no section headers.\n",
      "file: PosixPath('/Users/saraawad/Desktop/flux-data-qaqc/sites/config/output/EBR/US-Skr_monthly_data.csv'), line: 1\n",
      "'date,SW_IN,NETRAD,ebr_5day_clim,input_LE,ebr,RH,rso,LW_OUT,flux_corr,flux,WS,SW_OUT,ebr_corr,ETrF_filtered,VPD_PI,input_G,ebc_cf,ETrF,LW_IN,energy,H_corr,input_H,LE_corr,gridMET_prcp,ET_fill_val,ET_gap,Rn_subday_gaps,H_subday_gaps,LE_subday_gaps,ET_corr,ET_fill,G_subday_gaps,ET,gridMET_ETr\\n'\n",
      "site id: US-AR2_daily_data\n",
      "Exception: File contains no section headers.\n",
      "file: PosixPath('/Users/saraawad/Desktop/flux-data-qaqc/sites/config/output/EBR/US-AR2_daily_data.csv'), line: 1\n",
      "'date,SW_IN,NETRAD,SW_OUT,input_G,input_LE,LW_IN,LW_OUT,RH,input_H,WS,Rn_subday_gaps,G_subday_gaps,H_subday_gaps,LE_subday_gaps,rso,flux,energy,ebr_5day_clim,ebc_cf,H_corr,ebr,ebr_corr,flux_corr,LE_corr,ET,ET_corr,gridMET_ETr,gridMET_prcp,ETrF,ETrF_filtered,ET_fill,ET_gap,ET_fill_val\\n'\n",
      "site id: US-Shd_daily_data\n",
      "Exception: File contains no section headers.\n",
      "file: PosixPath('/Users/saraawad/Desktop/flux-data-qaqc/sites/config/output/EBR/US-Shd_daily_data.csv'), line: 1\n",
      "'date,SW_IN,NETRAD,SW_OUT,VPD_PI,input_G,input_LE,RH,input_H,WS,Rn_subday_gaps,G_subday_gaps,H_subday_gaps,LE_subday_gaps,rso,flux,energy,ebr_5day_clim,ebc_cf,H_corr,ebr,ebr_corr,flux_corr,LE_corr,ET,ET_corr,gridMET_ETr,gridMET_prcp,ETrF,ETrF_filtered,ET_fill,ET_gap,ET_fill_val\\n'\n",
      "site id: US-Kon_monthly_data\n",
      "Exception: File contains no section headers.\n",
      "file: PosixPath('/Users/saraawad/Desktop/flux-data-qaqc/sites/config/output/EBR/US-Kon_monthly_data.csv'), line: 1\n",
      "'date,SW_IN,NETRAD,ebr_5day_clim,input_LE,ebr,RH,rso,flux_corr,flux,WS,SW_OUT,ebr_corr,ETrF_filtered,VPD_PI,input_G,ebc_cf,ETrF,H_corr,energy,input_H,LE_corr,gridMET_prcp,ET_fill_val,ET_gap,Rn_subday_gaps,H_subday_gaps,LE_subday_gaps,ET_corr,ET_fill,G_subday_gaps,ET,gridMET_ETr\\n'\n",
      "site id: US-Snd\n",
      "<fluxdataqaqc.data.Data object at 0x124a1bd30>\n",
      "WARNING: the following config variables are missing in the input climate file:\n",
      "T_SONIC\n",
      "They will be filled with NaN values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: renaming column G to input_G\n",
      "WARNING: renaming column LE to input_LE\n",
      "WARNING: renaming column H to input_H\n",
      "WARNING: t_avg variable in column T_SONIC is missing all data it will be removed\n",
      "Temporal frequency of data > hourly cannot calculate VP/VPD\n",
      "\n",
      "The input data temporal frequency was not detected.\n",
      "Data is being resampled to daily temporal frequency.\n",
      "Linearly interpolating gaps in energy balance components up to 4 hours when Rn < 0 and up to 2 hours when Rn >= 0.\n",
      "Filtering days with less then 100.0% or 17/17 sub-daily measurements\n",
      "Converting vpd from hpa to kpa\n",
      "gridMET reference ET already downloaded for station at:\n",
      "/Users/saraawad/Desktop/flux-data-qaqc/sites/config/gridMET_data/US-Snd_38.0250N_-121.7667W.csv\n",
      "not redownloading.\n",
      "Gap filling ET_corr with filtered ETrF x ETr (gridMET)\n",
      "site id: US-Ced\n",
      "<fluxdataqaqc.data.Data object at 0x124aea588>\n",
      "WARNING: the following config variables are missing in the input climate file:\n",
      "T_SONIC\n",
      "They will be filled with NaN values\n",
      "WARNING: renaming column G to input_G\n",
      "WARNING: renaming column LE to input_LE\n",
      "WARNING: renaming column H to input_H\n",
      "WARNING: t_avg variable in column T_SONIC is missing all data it will be removed\n",
      "Converting vpd from hpa to kpa\n",
      "\n",
      "The input data temporal frequency was not detected.\n",
      "Data is being resampled to daily temporal frequency.\n",
      "Linearly interpolating gaps in energy balance components up to 4 hours when Rn < 0 and up to 2 hours when Rn >= 0.\n",
      "Filtering days with less then 100.0% or 45/45 sub-daily measurements\n",
      "gridMET reference ET already downloaded for station at:\n",
      "/Users/saraawad/Desktop/flux-data-qaqc/sites/config/gridMET_data/US-Ced_39.8583N_-74.3917W.csv\n",
      "not redownloading.\n",
      "Gap filling ET_corr with filtered ETrF x ETr (gridMET)\n",
      "site id: US-Wlr\n",
      "<fluxdataqaqc.data.Data object at 0x12481a4a8>\n",
      "WARNING: the following config variables are missing in the input climate file:\n",
      "T_SONIC\n",
      "They will be filled with NaN values\n",
      "WARNING: renaming column G to input_G\n",
      "WARNING: renaming column LE to input_LE\n",
      "WARNING: renaming column H to input_H\n",
      "WARNING: t_avg variable in column T_SONIC is missing all data it will be removed\n",
      "\n",
      "The input data temporal frequency was not detected.\n",
      "Data is being resampled to daily temporal frequency.\n",
      "Linearly interpolating gaps in energy balance components up to 4 hours when Rn < 0 and up to 2 hours when Rn >= 0.\n",
      "Filtering days with less then 100.0% or 48/48 sub-daily measurements\n",
      "gridMET reference ET already downloaded for station at:\n",
      "/Users/saraawad/Desktop/flux-data-qaqc/sites/config/gridMET_data/US-Wlr_37.5250N_-96.8500W.csv\n",
      "not redownloading.\n",
      "Gap filling ET_corr with filtered ETrF x ETr (gridMET)\n",
      "site id: US-A32\n",
      "<fluxdataqaqc.data.Data object at 0x12481a710>\n",
      "WARNING: renaming column G to input_G\n",
      "WARNING: renaming column LE to input_LE\n",
      "WARNING: renaming column H to input_H\n",
      "Temporal frequency of data > hourly cannot calculate VP/VPD\n",
      "\n",
      "The input data temporal frequency was not detected.\n",
      "WARNING: it looks like the input temporal frequency is greater than daily, downsampling, proceed with caution!\n",
      "\n",
      "Data is being resampled to daily temporal frequency.\n",
      "Linearly interpolating gaps in energy balance components up to 4 hours when Rn < 0 and up to 2 hours when Rn >= 0.\n",
      "gridMET reference ET already downloaded for station at:\n",
      "/Users/saraawad/Desktop/flux-data-qaqc/sites/config/gridMET_data/US-A32_36.8167N_-97.8083W.csv\n",
      "not redownloading.\n",
      "Gap filling ET_corr with filtered ETrF x ETr (gridMET)\n",
      "site id: US-Pon\n",
      "<fluxdataqaqc.data.Data object at 0x123b22eb8>\n",
      "WARNING: the following config variables are missing in the input climate file:\n",
      "T_SONIC\n",
      "They will be filled with NaN values\n",
      "WARNING: renaming column G to input_G\n",
      "WARNING: renaming column LE to input_LE\n",
      "WARNING: renaming column H to input_H\n",
      "WARNING: t_avg variable in column T_SONIC is missing all data it will be removed\n",
      "Temporal frequency of data > hourly cannot calculate VP/VPD\n",
      "\n",
      "The input data temporal frequency was not detected.\n",
      "WARNING: it looks like the input temporal frequency is greater than daily, downsampling, proceed with caution!\n",
      "\n",
      "Data is being resampled to daily temporal frequency.\n",
      "Linearly interpolating gaps in energy balance components up to 4 hours when Rn < 0 and up to 2 hours when Rn >= 0.\n",
      "Converting vpd from hpa to kpa\n",
      "gridMET reference ET already downloaded for station at:\n",
      "/Users/saraawad/Desktop/flux-data-qaqc/sites/config/gridMET_data/US-Pon_36.7750N_-97.1417W.csv\n",
      "not redownloading.\n",
      "Gap filling ET_corr with filtered ETrF x ETr (gridMET)\n",
      "site id: US-Kon\n",
      "<fluxdataqaqc.data.Data object at 0x12398a8d0>\n",
      "WARNING: the following config variables are missing in the input climate file:\n",
      "T_SONIC\n",
      "They will be filled with NaN values\n",
      "WARNING: renaming column G to input_G\n",
      "WARNING: renaming column LE to input_LE\n",
      "WARNING: renaming column H to input_H\n",
      "WARNING: t_avg variable in column T_SONIC is missing all data it will be removed\n",
      "Converting vpd from hpa to kpa\n",
      "\n",
      "The input data temporal frequency was not detected.\n",
      "WARNING: it looks like the input temporal frequency is greater than daily, downsampling, proceed with caution!\n",
      "\n",
      "Data is being resampled to daily temporal frequency.\n",
      "Linearly interpolating gaps in energy balance components up to 4 hours when Rn < 0 and up to 2 hours when Rn >= 0.\n",
      "gridMET reference ET already downloaded for station at:\n",
      "/Users/saraawad/Desktop/flux-data-qaqc/sites/config/gridMET_data/US-Kon_39.0667N_-96.5583W.csv\n",
      "not redownloading.\n",
      "Gap filling ET_corr with filtered ETrF x ETr (gridMET)\n",
      "site id: US-Skr\n",
      "<fluxdataqaqc.data.Data object at 0x123978a20>\n",
      "WARNING: the following config variables are missing in the input climate file:\n",
      "T_SONIC\n",
      "They will be filled with NaN values\n",
      "WARNING: renaming column G to input_G\n",
      "WARNING: renaming column LE to input_LE\n",
      "WARNING: renaming column H to input_H\n",
      "WARNING: t_avg variable in column T_SONIC is missing all data it will be removed\n",
      "Temporal frequency of data > hourly cannot calculate VP/VPD\n",
      "\n",
      "The input data temporal frequency was not detected.\n",
      "WARNING: it looks like the input temporal frequency is greater than daily, downsampling, proceed with caution!\n",
      "\n",
      "Data is being resampled to daily temporal frequency.\n",
      "Linearly interpolating gaps in energy balance components up to 4 hours when Rn < 0 and up to 2 hours when Rn >= 0.\n",
      "Converting vpd from hpa to kpa\n",
      "gridMET reference ET already downloaded for station at:\n",
      "/Users/saraawad/Desktop/flux-data-qaqc/sites/config/gridMET_data/US-Skr_25.3583N_-81.0583W.csv\n",
      "not redownloading.\n",
      "Gap filling ET_corr with filtered ETrF x ETr (gridMET)\n",
      "site id: US-Bi2\n",
      "<fluxdataqaqc.data.Data object at 0x123b5a518>\n",
      "WARNING: renaming column G to input_G\n",
      "WARNING: renaming column LE to input_LE\n",
      "WARNING: renaming column H to input_H\n",
      "Converting vpd from hpa to kpa\n",
      "Calculating vapor pressure from vapor pressure deficit and air temperature\n",
      "\n",
      "The input data temporal frequency was not detected.\n",
      "Data is being resampled to daily temporal frequency.\n",
      "Linearly interpolating gaps in energy balance components up to 4 hours when Rn < 0 and up to 2 hours when Rn >= 0.\n",
      "Filtering days with less then 100.0% or 33/33 sub-daily measurements\n",
      "gridMET reference ET already downloaded for station at:\n",
      "/Users/saraawad/Desktop/flux-data-qaqc/sites/config/gridMET_data/US-Bi2_38.1083N_-121.5167W.csv\n",
      "not redownloading.\n",
      "Gap filling ET_corr with filtered ETrF x ETr (gridMET)\n",
      "site id: US-Var\n",
      "<fluxdataqaqc.data.Data object at 0x1235b7cf8>\n",
      "WARNING: the following config variables are missing in the input climate file:\n",
      "SW_IN\n",
      "They will be filled with NaN values\n",
      "WARNING: renaming column G to input_G\n",
      "WARNING: renaming column LE to input_LE\n",
      "WARNING: renaming column H to input_H\n",
      "WARNING: sw_in variable in column SW_IN is missing all data it will be removed\n",
      "Temporal frequency of data > hourly cannot calculate VP/VPD\n",
      "\n",
      "The input data temporal frequency was not detected.\n",
      "WARNING: it looks like the input temporal frequency is greater than daily, downsampling, proceed with caution!\n",
      "\n",
      "Data is being resampled to daily temporal frequency.\n",
      "Linearly interpolating gaps in energy balance components up to 4 hours when Rn < 0 and up to 2 hours when Rn >= 0.\n",
      "Converting vpd from hpa to kpa\n",
      "gridMET reference ET already downloaded for station at:\n",
      "/Users/saraawad/Desktop/flux-data-qaqc/sites/config/gridMET_data/US-Var_38.4000N_-120.9333W.csv\n",
      "not redownloading.\n",
      "Gap filling ET_corr with filtered ETrF x ETr (gridMET)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    input_name = os.path.join(\"/Users/saraawad/Desktop/flux-data-qaqc/sites/\", \"config/\")\n",
    "    output_name = os.path.join(\"/Users/saraawad/Desktop/flux-data-qaqc/sites/\", \"data/\")\n",
    "    correction_method = 2\n",
    "    gc = FluxQaQcCorrection(input_name, output_name, correction_method)\n",
    "    gc.generate_correction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Site Id</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Elevation(m)</th>\n",
       "      <th>Climate Koeppen</th>\n",
       "      <th>Mean Annual Temp (Â°C)</th>\n",
       "      <th>Mean Annual Precip. (mm):</th>\n",
       "      <th>Flux Species Measured:</th>\n",
       "      <th>Years Data Collected:</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US-ARM</td>\n",
       "      <td>36.605800</td>\n",
       "      <td>-97.488800</td>\n",
       "      <td>314.00</td>\n",
       "      <td>Cfa (Humid Subtropical: mild with no dry seaso...</td>\n",
       "      <td>14.760000</td>\n",
       "      <td>843.00000</td>\n",
       "      <td>CO2, H2O</td>\n",
       "      <td>2002 - 2019</td>\n",
       "      <td>Central facility tower crop field (winter whea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>US-AR2</td>\n",
       "      <td>36.635800</td>\n",
       "      <td>-99.597500</td>\n",
       "      <td>646.00</td>\n",
       "      <td>Dsa (Dry Continental: hot summer)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CO2, H, H2O</td>\n",
       "      <td>2009 - 2012</td>\n",
       "      <td>The ARM USDA UNL OSU Woodward Switchgrass 2 to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US-KFS</td>\n",
       "      <td>39.056100</td>\n",
       "      <td>-95.190700</td>\n",
       "      <td>310.00</td>\n",
       "      <td>Cfa (Humid Subtropical: mild with no dry seaso...</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1014.00000</td>\n",
       "      <td>CO2, H2O</td>\n",
       "      <td>2007 - 2019</td>\n",
       "      <td>The study is an abandoned grassland at the Kan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US-Wgr</td>\n",
       "      <td>45.112865</td>\n",
       "      <td>-122.656026</td>\n",
       "      <td>52.00</td>\n",
       "      <td>Csb (Mediterranean: mild with dry, warm summer)</td>\n",
       "      <td>11.580000</td>\n",
       "      <td>1194.00000</td>\n",
       "      <td>CO2, H, H2O</td>\n",
       "      <td>2014 - 2019</td>\n",
       "      <td>he site was established in summer 2014 and is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>US-Kon</td>\n",
       "      <td>39.082400</td>\n",
       "      <td>-96.560300</td>\n",
       "      <td>417.00</td>\n",
       "      <td>Cfa (Humid Subtropical: mild with no dry seaso...</td>\n",
       "      <td>12.770000</td>\n",
       "      <td>867.00000</td>\n",
       "      <td>CO2, H2O</td>\n",
       "      <td>2006 - 2019</td>\n",
       "      <td>Burned on an annual basis. Bison reintroduced ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>US-Bi2</td>\n",
       "      <td>38.109000</td>\n",
       "      <td>-121.535000</td>\n",
       "      <td>-4.98</td>\n",
       "      <td>Csa (Mediterranean: mild with dry, hot summer)</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>338.00000</td>\n",
       "      <td>CO2, CH4, H2O</td>\n",
       "      <td>2017 - 2019</td>\n",
       "      <td>corn is growing on an island in the Sacramento...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>US-Me2</td>\n",
       "      <td>44.452300</td>\n",
       "      <td>-121.557400</td>\n",
       "      <td>1253.00</td>\n",
       "      <td>Csb (Mediterranean: mild with dry, warm summer)</td>\n",
       "      <td>6.280000</td>\n",
       "      <td>523.00000</td>\n",
       "      <td>CO2, H2O</td>\n",
       "      <td>2002 - 2019</td>\n",
       "      <td>The mean stand age is 71 years old and the sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>US-A74</td>\n",
       "      <td>36.808464</td>\n",
       "      <td>-97.548854</td>\n",
       "      <td>337.00</td>\n",
       "      <td>Cfa (Humid Subtropical: mild with no dry seaso...</td>\n",
       "      <td>33.900000</td>\n",
       "      <td>889.00000</td>\n",
       "      <td>CO2, H, H2O</td>\n",
       "      <td>2016 - 2019</td>\n",
       "      <td>This site is located near the ARM SGP Central ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>US-HRC</td>\n",
       "      <td>34.585722</td>\n",
       "      <td>-91.747528</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cfa (Humid Subtropical: mild with no dry seaso...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CO2, CH4, H2O</td>\n",
       "      <td>2017 - 2017</td>\n",
       "      <td>Conventional flood irrigation method on a rice...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>US-SO2</td>\n",
       "      <td>33.373800</td>\n",
       "      <td>-116.622800</td>\n",
       "      <td>1394.00</td>\n",
       "      <td>Csa (Mediterranean: mild with dry, hot summer)</td>\n",
       "      <td>13.630000</td>\n",
       "      <td>553.00000</td>\n",
       "      <td>CO2, H2O</td>\n",
       "      <td>1997 - 2019</td>\n",
       "      <td>The Sky Oaks Old site is located near the Sky ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>US-Ced</td>\n",
       "      <td>39.837900</td>\n",
       "      <td>-74.379100</td>\n",
       "      <td>58.00</td>\n",
       "      <td>Cfa (Humid Subtropical: mild with no dry seaso...</td>\n",
       "      <td>11.040000</td>\n",
       "      <td>1138.00000</td>\n",
       "      <td>CO2, H, H2O</td>\n",
       "      <td>2005 - 2019</td>\n",
       "      <td>Wildfires and prescribed fires are a common oc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>US-AR1</td>\n",
       "      <td>36.426700</td>\n",
       "      <td>-99.420000</td>\n",
       "      <td>611.00</td>\n",
       "      <td>Dsa (Dry Continental: hot summer)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CO2, H, H2O</td>\n",
       "      <td>2009 - 2019</td>\n",
       "      <td>The ARM USDA UNL OSU Woodward Switchgrass 1 to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>US-Skr</td>\n",
       "      <td>25.362933</td>\n",
       "      <td>-81.077582</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cwa (Humid Subtropical: dry winter, hot summer)</td>\n",
       "      <td>23.770000</td>\n",
       "      <td>1259.00000</td>\n",
       "      <td>CO2, H2O</td>\n",
       "      <td>2004 - 2019</td>\n",
       "      <td>The Florida Everglades Shark River Slough Mang...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>US-A32</td>\n",
       "      <td>36.819268</td>\n",
       "      <td>-97.819772</td>\n",
       "      <td>335.00</td>\n",
       "      <td>Cfa (Humid Subtropical: mild with no dry seaso...</td>\n",
       "      <td>33.900000</td>\n",
       "      <td>889.00000</td>\n",
       "      <td>CO2, H, H2O</td>\n",
       "      <td>2015 - 2019</td>\n",
       "      <td>This site is located at the ARM SGP Extended F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>US-HRA</td>\n",
       "      <td>34.583300</td>\n",
       "      <td>-91.747958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cfa (Humid Subtropical: mild with no dry seaso...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CO2, CH4, H, H2O</td>\n",
       "      <td>2017 - 2017</td>\n",
       "      <td>Zero grade rice field (25 ha) under continuous...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>US-MMS</td>\n",
       "      <td>39.323200</td>\n",
       "      <td>-86.413100</td>\n",
       "      <td>275.00</td>\n",
       "      <td>Cfa (Humid Subtropical: mild with no dry seaso...</td>\n",
       "      <td>10.850000</td>\n",
       "      <td>1032.00000</td>\n",
       "      <td>CO2, H, H2O</td>\n",
       "      <td>1999 - 2019</td>\n",
       "      <td>Owned by the Indiana Department of Natural Res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>US-Me6</td>\n",
       "      <td>44.323284</td>\n",
       "      <td>-121.607800</td>\n",
       "      <td>998.00</td>\n",
       "      <td>Csb (Mediterranean: mild with dry, warm summer)</td>\n",
       "      <td>7.594914</td>\n",
       "      <td>494.34069</td>\n",
       "      <td>CO2, H2O</td>\n",
       "      <td>2010 - 2019</td>\n",
       "      <td>The study site is located east of the Cascade ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>US-Pon</td>\n",
       "      <td>36.766670</td>\n",
       "      <td>-97.133330</td>\n",
       "      <td>310.00</td>\n",
       "      <td>Cfa (Humid Subtropical: mild with no dry seaso...</td>\n",
       "      <td>14.940000</td>\n",
       "      <td>866.34000</td>\n",
       "      <td>CO2</td>\n",
       "      <td>1997 - 2001</td>\n",
       "      <td>The Ponca Winter Wheat site is a 65 ha rainfed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>US-Wlr</td>\n",
       "      <td>37.520800</td>\n",
       "      <td>-96.855000</td>\n",
       "      <td>408.00</td>\n",
       "      <td>Cfa (Humid Subtropical: mild with no dry seaso...</td>\n",
       "      <td>13.520000</td>\n",
       "      <td>881.00000</td>\n",
       "      <td>CO2</td>\n",
       "      <td>2001 - 2004</td>\n",
       "      <td>The Walnut River Watershed site rests on a C3/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>US-WBW</td>\n",
       "      <td>35.958770</td>\n",
       "      <td>-84.287430</td>\n",
       "      <td>283.00</td>\n",
       "      <td>Cfa (Humid Subtropical: mild with no dry seaso...</td>\n",
       "      <td>13.710000</td>\n",
       "      <td>1372.05000</td>\n",
       "      <td>CO2</td>\n",
       "      <td>1995 - 1999</td>\n",
       "      <td>... The stand is over 50 years old, having reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>US-SP2</td>\n",
       "      <td>29.764800</td>\n",
       "      <td>-82.244820</td>\n",
       "      <td>50.00</td>\n",
       "      <td>Cfa (Humid Subtropical: mild with no dry seaso...</td>\n",
       "      <td>20.070000</td>\n",
       "      <td>1314.41000</td>\n",
       "      <td>CO2</td>\n",
       "      <td>1998 - 2008</td>\n",
       "      <td>Even aged slash pine (Pinus elliottii) plantat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>US-Tw2</td>\n",
       "      <td>38.104700</td>\n",
       "      <td>-121.643300</td>\n",
       "      <td>-5.00</td>\n",
       "      <td>Csa (Mediterranean: mild with dry, hot summer)</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>421.00000</td>\n",
       "      <td>CO2</td>\n",
       "      <td>2012 - 2013</td>\n",
       "      <td>The Twitchell Corn site is a corn field on pea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>US-FR2</td>\n",
       "      <td>29.949490</td>\n",
       "      <td>-97.996230</td>\n",
       "      <td>271.90</td>\n",
       "      <td>Cfa (Humid Subtropical: mild with no dry seaso...</td>\n",
       "      <td>19.480000</td>\n",
       "      <td>864.00000</td>\n",
       "      <td>CO2</td>\n",
       "      <td>2004 - 2019</td>\n",
       "      <td>Freeman Ranch is a 4200 ha research area owned...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>US-Ton</td>\n",
       "      <td>38.431600</td>\n",
       "      <td>-120.965980</td>\n",
       "      <td>177.00</td>\n",
       "      <td>Csa (Mediterranean: mild with dry, hot summer)</td>\n",
       "      <td>15.800000</td>\n",
       "      <td>559.00000</td>\n",
       "      <td>CO2</td>\n",
       "      <td>2001 - 2019</td>\n",
       "      <td>Located in the lower foothills of the Sierra N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>US-Shd</td>\n",
       "      <td>36.933330</td>\n",
       "      <td>-96.683330</td>\n",
       "      <td>346.00</td>\n",
       "      <td>Cfa (Humid Subtropical: mild with no dry seaso...</td>\n",
       "      <td>14.320000</td>\n",
       "      <td>897.91000</td>\n",
       "      <td>CO2</td>\n",
       "      <td>1997 - 2001</td>\n",
       "      <td>Native tall grass prairie. A prairie managemen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>US-Goo</td>\n",
       "      <td>34.254700</td>\n",
       "      <td>-89.873500</td>\n",
       "      <td>87.00</td>\n",
       "      <td>Cfa (Humid Subtropical: mild with no dry seaso...</td>\n",
       "      <td>15.890000</td>\n",
       "      <td>1425.77000</td>\n",
       "      <td>CO2</td>\n",
       "      <td>2002 - 2006</td>\n",
       "      <td>The Goodwin Creek site is located in the Bluff...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>US-Var</td>\n",
       "      <td>38.413300</td>\n",
       "      <td>-120.950700</td>\n",
       "      <td>129.00</td>\n",
       "      <td>Csa (Mediterranean: mild with dry, hot summer)</td>\n",
       "      <td>15.800000</td>\n",
       "      <td>559.00000</td>\n",
       "      <td>CO2</td>\n",
       "      <td>2000 - 2019</td>\n",
       "      <td>Located in the lower foothills of the Sierra N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>US-Tw3</td>\n",
       "      <td>38.115900</td>\n",
       "      <td>-121.646700</td>\n",
       "      <td>-9.00</td>\n",
       "      <td>Csa (Mediterranean: mild with dry, hot summer)</td>\n",
       "      <td>15.600000</td>\n",
       "      <td>421.00000</td>\n",
       "      <td>CO2, CH4</td>\n",
       "      <td>2013 - 2019</td>\n",
       "      <td>The Twitchell Alfalfa site is an alfalfa field...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>US-Myb</td>\n",
       "      <td>38.049861</td>\n",
       "      <td>-121.764980</td>\n",
       "      <td>-4.00</td>\n",
       "      <td>Csa (Mediterranean: mild with dry, hot summer)</td>\n",
       "      <td>15.900000</td>\n",
       "      <td>338.00000</td>\n",
       "      <td>CO2, CH4</td>\n",
       "      <td>2010 - 2019</td>\n",
       "      <td>The Mayberry Wetland site is a 300-acre restor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>US-Twt</td>\n",
       "      <td>38.108720</td>\n",
       "      <td>-121.653100</td>\n",
       "      <td>-7.00</td>\n",
       "      <td>Csa (Mediterranean: mild with dry, hot summer)</td>\n",
       "      <td>15.600000</td>\n",
       "      <td>421.00000</td>\n",
       "      <td>CO2, CH4</td>\n",
       "      <td>2009 - 2019</td>\n",
       "      <td>The Twitchell Island site is a rice paddy that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>US-Tw1</td>\n",
       "      <td>38.107400</td>\n",
       "      <td>-121.646900</td>\n",
       "      <td>-9.00</td>\n",
       "      <td>Csa (Mediterranean: mild with dry, hot summer)</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>421.00000</td>\n",
       "      <td>CO2, CH4</td>\n",
       "      <td>2012 - 2019</td>\n",
       "      <td>The Twitchell Wetland site is a 7.4-acre resto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>US-Snd</td>\n",
       "      <td>38.037300</td>\n",
       "      <td>-121.753700</td>\n",
       "      <td>-5.00</td>\n",
       "      <td>Csa (Mediterranean: mild with dry, hot summer)</td>\n",
       "      <td>15.600000</td>\n",
       "      <td>358.00000</td>\n",
       "      <td>CO2, CH4</td>\n",
       "      <td>2007 - 2015</td>\n",
       "      <td>The Sherman Island site is a 38-ha peatland pa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Site Id   Latitude   Longitude  Elevation(m)  \\\n",
       "0   US-ARM  36.605800  -97.488800        314.00   \n",
       "1   US-AR2  36.635800  -99.597500        646.00   \n",
       "2   US-KFS  39.056100  -95.190700        310.00   \n",
       "3   US-Wgr  45.112865 -122.656026         52.00   \n",
       "4   US-Kon  39.082400  -96.560300        417.00   \n",
       "5   US-Bi2  38.109000 -121.535000         -4.98   \n",
       "6   US-Me2  44.452300 -121.557400       1253.00   \n",
       "7   US-A74  36.808464  -97.548854        337.00   \n",
       "8   US-HRC  34.585722  -91.747528           NaN   \n",
       "9   US-SO2  33.373800 -116.622800       1394.00   \n",
       "10  US-Ced  39.837900  -74.379100         58.00   \n",
       "11  US-AR1  36.426700  -99.420000        611.00   \n",
       "12  US-Skr  25.362933  -81.077582           NaN   \n",
       "13  US-A32  36.819268  -97.819772        335.00   \n",
       "14  US-HRA  34.583300  -91.747958           NaN   \n",
       "15  US-MMS  39.323200  -86.413100        275.00   \n",
       "16  US-Me6  44.323284 -121.607800        998.00   \n",
       "17  US-Pon  36.766670  -97.133330        310.00   \n",
       "18  US-Wlr  37.520800  -96.855000        408.00   \n",
       "19  US-WBW  35.958770  -84.287430        283.00   \n",
       "20  US-SP2  29.764800  -82.244820         50.00   \n",
       "21  US-Tw2  38.104700 -121.643300         -5.00   \n",
       "22  US-FR2  29.949490  -97.996230        271.90   \n",
       "23  US-Ton  38.431600 -120.965980        177.00   \n",
       "24  US-Shd  36.933330  -96.683330        346.00   \n",
       "25  US-Goo  34.254700  -89.873500         87.00   \n",
       "26  US-Var  38.413300 -120.950700        129.00   \n",
       "27  US-Tw3  38.115900 -121.646700         -9.00   \n",
       "28  US-Myb  38.049861 -121.764980         -4.00   \n",
       "29  US-Twt  38.108720 -121.653100         -7.00   \n",
       "30  US-Tw1  38.107400 -121.646900         -9.00   \n",
       "31  US-Snd  38.037300 -121.753700         -5.00   \n",
       "\n",
       "                                      Climate Koeppen  Mean Annual Temp (Â°C)  \\\n",
       "0   Cfa (Humid Subtropical: mild with no dry seaso...               14.760000   \n",
       "1                   Dsa (Dry Continental: hot summer)                     NaN   \n",
       "2   Cfa (Humid Subtropical: mild with no dry seaso...               12.000000   \n",
       "3     Csb (Mediterranean: mild with dry, warm summer)               11.580000   \n",
       "4   Cfa (Humid Subtropical: mild with no dry seaso...               12.770000   \n",
       "5      Csa (Mediterranean: mild with dry, hot summer)               16.000000   \n",
       "6     Csb (Mediterranean: mild with dry, warm summer)                6.280000   \n",
       "7   Cfa (Humid Subtropical: mild with no dry seaso...               33.900000   \n",
       "8   Cfa (Humid Subtropical: mild with no dry seaso...                     NaN   \n",
       "9      Csa (Mediterranean: mild with dry, hot summer)               13.630000   \n",
       "10  Cfa (Humid Subtropical: mild with no dry seaso...               11.040000   \n",
       "11                  Dsa (Dry Continental: hot summer)                     NaN   \n",
       "12    Cwa (Humid Subtropical: dry winter, hot summer)               23.770000   \n",
       "13  Cfa (Humid Subtropical: mild with no dry seaso...               33.900000   \n",
       "14  Cfa (Humid Subtropical: mild with no dry seaso...                     NaN   \n",
       "15  Cfa (Humid Subtropical: mild with no dry seaso...               10.850000   \n",
       "16    Csb (Mediterranean: mild with dry, warm summer)                7.594914   \n",
       "17  Cfa (Humid Subtropical: mild with no dry seaso...               14.940000   \n",
       "18  Cfa (Humid Subtropical: mild with no dry seaso...               13.520000   \n",
       "19  Cfa (Humid Subtropical: mild with no dry seaso...               13.710000   \n",
       "20  Cfa (Humid Subtropical: mild with no dry seaso...               20.070000   \n",
       "21     Csa (Mediterranean: mild with dry, hot summer)               15.500000   \n",
       "22  Cfa (Humid Subtropical: mild with no dry seaso...               19.480000   \n",
       "23     Csa (Mediterranean: mild with dry, hot summer)               15.800000   \n",
       "24  Cfa (Humid Subtropical: mild with no dry seaso...               14.320000   \n",
       "25  Cfa (Humid Subtropical: mild with no dry seaso...               15.890000   \n",
       "26     Csa (Mediterranean: mild with dry, hot summer)               15.800000   \n",
       "27     Csa (Mediterranean: mild with dry, hot summer)               15.600000   \n",
       "28     Csa (Mediterranean: mild with dry, hot summer)               15.900000   \n",
       "29     Csa (Mediterranean: mild with dry, hot summer)               15.600000   \n",
       "30     Csa (Mediterranean: mild with dry, hot summer)               15.500000   \n",
       "31     Csa (Mediterranean: mild with dry, hot summer)               15.600000   \n",
       "\n",
       "    Mean Annual Precip. (mm): Flux Species Measured: Years Data Collected:  \\\n",
       "0                   843.00000               CO2, H2O           2002 - 2019   \n",
       "1                         NaN            CO2, H, H2O           2009 - 2012   \n",
       "2                  1014.00000               CO2, H2O           2007 - 2019   \n",
       "3                  1194.00000            CO2, H, H2O           2014 - 2019   \n",
       "4                   867.00000               CO2, H2O           2006 - 2019   \n",
       "5                   338.00000          CO2, CH4, H2O           2017 - 2019   \n",
       "6                   523.00000               CO2, H2O           2002 - 2019   \n",
       "7                   889.00000            CO2, H, H2O           2016 - 2019   \n",
       "8                         NaN          CO2, CH4, H2O           2017 - 2017   \n",
       "9                   553.00000               CO2, H2O           1997 - 2019   \n",
       "10                 1138.00000            CO2, H, H2O           2005 - 2019   \n",
       "11                        NaN            CO2, H, H2O           2009 - 2019   \n",
       "12                 1259.00000               CO2, H2O           2004 - 2019   \n",
       "13                  889.00000            CO2, H, H2O           2015 - 2019   \n",
       "14                        NaN       CO2, CH4, H, H2O           2017 - 2017   \n",
       "15                 1032.00000            CO2, H, H2O           1999 - 2019   \n",
       "16                  494.34069               CO2, H2O           2010 - 2019   \n",
       "17                  866.34000                    CO2           1997 - 2001   \n",
       "18                  881.00000                    CO2           2001 - 2004   \n",
       "19                 1372.05000                    CO2           1995 - 1999   \n",
       "20                 1314.41000                    CO2           1998 - 2008   \n",
       "21                  421.00000                    CO2           2012 - 2013   \n",
       "22                  864.00000                    CO2           2004 - 2019   \n",
       "23                  559.00000                    CO2           2001 - 2019   \n",
       "24                  897.91000                    CO2           1997 - 2001   \n",
       "25                 1425.77000                    CO2           2002 - 2006   \n",
       "26                  559.00000                    CO2           2000 - 2019   \n",
       "27                  421.00000               CO2, CH4           2013 - 2019   \n",
       "28                  338.00000               CO2, CH4           2010 - 2019   \n",
       "29                  421.00000               CO2, CH4           2009 - 2019   \n",
       "30                  421.00000               CO2, CH4           2012 - 2019   \n",
       "31                  358.00000               CO2, CH4           2007 - 2015   \n",
       "\n",
       "                                          Description  \n",
       "0   Central facility tower crop field (winter whea...  \n",
       "1   The ARM USDA UNL OSU Woodward Switchgrass 2 to...  \n",
       "2   The study is an abandoned grassland at the Kan...  \n",
       "3   he site was established in summer 2014 and is ...  \n",
       "4   Burned on an annual basis. Bison reintroduced ...  \n",
       "5   corn is growing on an island in the Sacramento...  \n",
       "6   The mean stand age is 71 years old and the sta...  \n",
       "7   This site is located near the ARM SGP Central ...  \n",
       "8   Conventional flood irrigation method on a rice...  \n",
       "9   The Sky Oaks Old site is located near the Sky ...  \n",
       "10  Wildfires and prescribed fires are a common oc...  \n",
       "11  The ARM USDA UNL OSU Woodward Switchgrass 1 to...  \n",
       "12  The Florida Everglades Shark River Slough Mang...  \n",
       "13  This site is located at the ARM SGP Extended F...  \n",
       "14  Zero grade rice field (25 ha) under continuous...  \n",
       "15  Owned by the Indiana Department of Natural Res...  \n",
       "16  The study site is located east of the Cascade ...  \n",
       "17  The Ponca Winter Wheat site is a 65 ha rainfed...  \n",
       "18  The Walnut River Watershed site rests on a C3/...  \n",
       "19  ... The stand is over 50 years old, having reg...  \n",
       "20  Even aged slash pine (Pinus elliottii) plantat...  \n",
       "21  The Twitchell Corn site is a corn field on pea...  \n",
       "22  Freeman Ranch is a 4200 ha research area owned...  \n",
       "23  Located in the lower foothills of the Sierra N...  \n",
       "24  Native tall grass prairie. A prairie managemen...  \n",
       "25  The Goodwin Creek site is located in the Bluff...  \n",
       "26  Located in the lower foothills of the Sierra N...  \n",
       "27  The Twitchell Alfalfa site is an alfalfa field...  \n",
       "28  The Mayberry Wetland site is a 300-acre restor...  \n",
       "29  The Twitchell Island site is a rice paddy that...  \n",
       "30  The Twitchell Wetland site is a 7.4-acre resto...  \n",
       "31  The Sherman Island site is a 38-ha peatland pa...  "
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Helpers.read_sites_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
