{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Load Libraries </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "import zipfile\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Helpers:\n",
    "    def __init__(self):\n",
    "        print(\"Helper\")\n",
    "        \n",
    "    def convert_missing_values_nan(df):\n",
    "        '''This function will convert -9999 to NaN'''\n",
    "        df = df.replace(-9999.000000, np.NaN)\n",
    "        return df\n",
    "\n",
    "    def drop_nan_columns(df):\n",
    "        '''Drops the columns having all theirs rows as Nans'''\n",
    "        columns_to_exclude = [\"Date\", \"Day\", \"Year\", \"Month\", \"Timestamp start\"\n",
    "                              , \"Time\", \"TIMESTAMP\", \"Tier\", \"TIMESTAMP_START\", \"TIMESTAMP_END\", \"Day Status\"]\n",
    "        columns = df.columns\n",
    "        for i in range(len(columns)):\n",
    "            col = columns[i]\n",
    "            if col in columns_to_exclude:\n",
    "                continue\n",
    "            nan_sum_col = df[col].isnull().sum()\n",
    "            if nan_sum_col == len(df):\n",
    "                df.drop(col, axis=1, inplace=True)\n",
    "        return df\n",
    "    \n",
    "    def drop_nans_rows(df):\n",
    "        '''This function will drop the rows having NaNs'''\n",
    "        print(\"Before removing missing values:\")\n",
    "        print(\"number of rows:\", df.shape[0], \"\\nnumber of columns:\", df.shape[1])\n",
    "        df = df.dropna(how='any')\n",
    "        print(\"After removing missing values:\")\n",
    "        print(\"number of rows:\", df.shape[0], \"\\nnumber of columns:\", df.shape[1])\n",
    "        return df\n",
    "        \n",
    "    def get_all_matching_columns(df, keyword):\n",
    "        return df.filter(like=keyword).columns\n",
    "\n",
    "    def generate_lags(df, column, lags_count): \n",
    "        for i in range(lags_count):\n",
    "            lag_name = column + \"-\" + str(i + 1)\n",
    "            df[lag_name] = df[column].shift(i + 1)\n",
    "#             for j in range(i):\n",
    "#                 df.loc[str(j+1), lag_name] = np.nan\n",
    "#         df = df.dropna(how='any')\n",
    "        return df\n",
    "\n",
    "    def add_LE_conversion_rate(df, col):\n",
    "        conversion_rate = 28.94\n",
    "        new_col = col + \"(mm)\"\n",
    "        df[new_col] = df[col] / conversion_rate\n",
    "        return df\n",
    "\n",
    "    def read_sites_data():\n",
    "        file_path = os.path.join(base_path, \"filtered_sites_all.xlsx\")\n",
    "        df = pd.read_excel(file_path)\n",
    "        df.head()\n",
    "        return df\n",
    "\n",
    "    def export_data(df, file_path):\n",
    "        export_path = os.path.join(base_path, file_path + \".csv\")\n",
    "        export_csv = df.to_csv(export_path, index=None, header=True)\n",
    "\n",
    "    def load_data(file_path):\n",
    "        df = pd.read_csv(file_path + \".csv\", delimiter=',')\n",
    "        return df\n",
    "    \n",
    "    def list_to_df(list_to_convert):\n",
    "        '''This function will convert the provided list into a dataframe'''\n",
    "        df = pd.concat(list_to_convert, sort=True)\n",
    "        return df\n",
    "    \n",
    "    def get_files_directory(dirName):\n",
    "    # create a list of file and sub directories \n",
    "    # names in the given directory \n",
    "        listOfFile = os.listdir(dirName)\n",
    "        allFiles = list()\n",
    "        # Iterate over all the entries\n",
    "        for entry in listOfFile:\n",
    "            # Create full path\n",
    "            if entry.endswith(\".xlsx\") or entry.endswith(\".icloud\") or entry.endswith(\".DS_Store\"):\n",
    "                continue\n",
    "            fullPath = os.path.join(dirName, entry)\n",
    "            # If entry is a directory then get the list of files in this directory \n",
    "            if os.path.isdir(fullPath):\n",
    "                allFiles = allFiles + Helpers.get_files_directory(fullPath)\n",
    "            else:\n",
    "                allFiles.append(fullPath)\n",
    "\n",
    "        return allFiles\n",
    "\n",
    "    def concat_dataframe_from_files(files, skipRowsNum, split_num):\n",
    "        values = []\n",
    "        for i in range(len(files)):\n",
    "            file_path = files[i]\n",
    "            head, file_name = os.path.split(file_path)\n",
    "            #Get only the sheets having the variables\n",
    "            if file_name.endswith(\".csv\"):\n",
    "#                 print(\"file name\", file_name)\n",
    "                df = pd.read_csv(file_path, delimiter=',', skiprows=skipRowsNum)\n",
    "                site_id = file_name.split(\"_\")[split_num]\n",
    "#                 print(\"site id in file:\", site_id)\n",
    "                df[\"Site Id\"] = site_id\n",
    "                values.append(df)\n",
    "        return Helpers.list_to_df(values)   \n",
    "    \n",
    "    def generate_dataframe_from_files(dirName, skipRowsNum = 0, split_num = 0):\n",
    "        files = Helpers.get_files_directory(dirName)\n",
    "        df = Helpers.concat_dataframe_from_files(files, skipRowsNum, split_num)\n",
    "        return df\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializer\n",
      "L2 file: EFDC_L2_Flx_FIJok_2002_v07_30m.txt\n",
      "L2 file: EFDC_L2_Flx_ITCA2_2014_v014_30m.txt\n",
      "L2 file: EFDC_L2_Flx_IECa1_2008_v02_30m.txt\n",
      "L2 file: EFDC_L2_Flx_ITBCi_2010_v030_30m.txt\n",
      "L2 file: EFDC_L2_Flx_FRGri_2007_v09_30m.txt\n",
      "L2 file: EFDC_L2_Flx_FRGri_2013_v06_30m.txt\n",
      "L2 file: EFDC_L2_Flx_FRAvi_2004_v01_30m.txt\n",
      "L2 file: EFDC_L2_Flx_IECa1_2004_v03_30m.txt\n",
      "L2 file: EFDC_L2_Flx_ITCA2_2012_v015_30m.txt\n",
      "L2 file: EFDC_L2_Flx_ITCA2_2011_v06_30m.txt\n",
      "L2 file: EFDC_L2_Flx_ITBCi_2014_v07_30m.txt\n",
      "L2 file: EFDC_L2_Flx_FRGri_2006_v07_30m.txt\n",
      "L2 file: EFDC_L2_Flx_FRGri_2015_v04_30m.txt\n",
      "L2 file: EFDC_L2_Flx_ITCas_2007_v02_30m.txt\n",
      "L2 file: EFDC_L2_Flx_ITCA2_2013_v017_30m.txt\n",
      "L2 file: EFDC_L2_Flx_IECa1_2007_v02_30m.txt\n",
      "L2 file: EFDC_L2_Flx_ITBCi_2008_v05_30m.txt\n",
      "L2 file: EFDC_L2_Flx_ITCas_2008_v01_30m.txt\n",
      "L2 file: EFDC_L2_Flx_FRGri_2009_v07_30m.txt\n",
      "L2 file: EFDC_L2_Flx_FRGri_2016_v05_30m.txt\n",
      "L2 file: EFDC_L2_Flx_ITBCi_2006_v01_30m.txt\n",
      "L2 file: EFDC_L2_Flx_FIJok_2001_v07_30m.txt\n",
      "L2 file: EFDC_L2_Flx_FRAvi_2006_v02_30m.txt\n",
      "L2 file: EFDC_L2_Flx_ESES2_2009_v04_30m.txt\n",
      "L2 file: EFDC_L2_Flx_ITBCi_2015_v07_30m.txt\n",
      "L2 file: EFDC_L2_Flx_FRGri_2008_v010_30m.txt\n",
      "L2 file: EFDC_L2_Flx_FIJok_2000_v04_30m.txt\n",
      "L2 file: EFDC_L2_Flx_FRGri_2012_v06_30m.txt\n",
      "L2 file: EFDC_L2_Flx_IECa1_2005_v03_30m.txt\n",
      "L2 file: EFDC_L2_Flx_ITCas_2009_v02_30m.txt\n",
      "L2 file: EFDC_L2_Flx_IECa1_2006_v01_30m.txt\n",
      "L2 file: EFDC_L2_Flx_FRGri_2014_v05_30m.txt\n",
      "L2 file: EFDC_L2_Flx_ITCas_2010_v03_30m.txt\n",
      "L2 file: EFDC_L2_Flx_FIJok_2003_v07_30m.txt\n",
      "L2 file: EFDC_L2_Flx_ITCas_2006_v01_30m.txt\n",
      "L2 file: EFDC_L2_Flx_ITBCi_2013_v07_30m.txt\n",
      "L2 file: EFDC_L2_Flx_ITBCi_2007_v01_30m.txt\n",
      "L2 file: EFDC_L2_Flx_FRGri_2004_v06_30m.txt\n",
      "L2 file: EFDC_L2_Flx_ITBCi_2004_v03_30m.txt\n",
      "L2 file: EFDC_L2_Flx_BELon_2018_v08_30m.txt\n",
      "L2 file: EFDC_L2_Flx_FRGri_2011_v06_30m.txt\n",
      "L2 file: EFDC_L2_Flx_FRGri_2005_v011_30m.txt\n",
      "L2 file: EFDC_L2_Flx_DERuS_2018_v04_30m.txt\n",
      "L2 file: EFDC_L2_Flx_ESES2_2010_v06_30m.txt\n",
      "L2 file: EFDC_L2_Flx_ITBCi_2009_v05_30m.txt\n",
      "L2 file: EFDC_L2_Flx_FRGri_2010_v08_30m.txt\n",
      "L2 file: EFDC_L2_Flx_BELon_2017_v010_30m.txt\n",
      "L2 file: EFDC_L2_Flx_ITBCi_2012_v09_30m.txt\n",
      "L2 file: EFDC_L2_Flx_ITBCi_2011_v012_30m.txt\n",
      "L2 file: EFDC_L2_Flx_ITBCi_2005_v04_30m.txt\n",
      "L2 file: EFDC_L2_Flx_FRGri_2005_v011_1hr.txt\n",
      "L2 file: EFDC_L2_Flx_FRGri_2017_v04_30m.txt\n",
      "L2 file: EFDC_L2_Flx_FRAvi_2005_v02_30m.txt\n",
      "L2 file: EFDC_L2_Flx_UKESa_2005_v01_30m.txt\n",
      "L2 file: EFDC_L2_Flx_UKESa_2003_v02_30m.txt\n",
      "L2 file: EFDC_L2_Flx_NLLan_2006_v01_30m.txt\n",
      "L2 file: EFDC_L2_Flx_ITRo3_2007_v01_30m.txt\n",
      "L2 file: EFDC_L2_Flx_UKHer_2006_v01_30m.txt\n",
      "L2 file: EFDC_L2_Flx_ITRo3_2009_v04_30m.txt\n",
      "L2 file: EFDC_L2_Flx_NLLan_2005_v01_30m.txt\n",
      "L2 file: EFDC_L2_Flx_ITRo3_2008_v03_30m.txt\n",
      "L2 file: EFDC_L2_Flx_ITRo4_2012_v05_30m.txt\n",
      "L2 file: EFDC_L2_Flx_UKESa_2006_v01_30m.txt\n",
      "L2 file: EFDC_L2_Flx_ITRo3_2011_v07_30m.txt\n",
      "L2 file: EFDC_L2_Flx_ITRo4_2008_v03_30m.txt\n",
      "L2 file: EFDC_L2_Flx_ITRo3_2012_v05_30m.txt\n",
      "L2 file: EFDC_L2_Flx_ITRo4_2007_v01_30m.txt\n",
      "L2 file: EFDC_L2_Flx_NLLut_2007_v04_30m.txt\n",
      "L2 file: EFDC_L2_Flx_NLLut_2006_v02_30m.txt\n",
      "L2 file: EFDC_L2_Flx_ITRo3_2013_v02_30m.txt\n",
      "L2 file: EFDC_L2_Flx_ITRo4_2009_v04_30m.txt\n",
      "L2 file: EFDC_L2_Flx_ITRo4_2011_v01_30m.txt\n",
      "L2 file: EFDC_L2_Flx_NLMol_2006_v01_30m.txt\n",
      "L2 file: EFDC_L2_Flx_ITRo4_2013_v05_30m.txt\n",
      "L2 file: EFDC_L2_Flx_NLMol_2005_v02_30m.txt\n",
      "L2 file: EFDC_L2_Flx_UKESa_2004_v02_30m.txt\n",
      "L2 file: EFDC_L2_Flx_ITRo3_2010_v03_30m.txt\n",
      "L2 file: EFDC_L2_Flx_CHOe2_2017_v04_30m.txt\n",
      "L2 file: EFDC_L2_Flx_CHOe2_2018_v05_30m.txt\n",
      "-----------------------------------------\n",
      "L3 file: CEIP_EC_L3_UKESa_2005_v01.txt\n",
      "L3 file: CEIP_EC_L3_UKESa_2004_v01.txt\n",
      "L3 file: CEIP_EC_L3_NLLan_2005_v01.txt\n",
      "L3 file: CEIP_EC_L3_ITBCi_2009_v01.txt\n",
      "L3 file: CEIP_EC_L3_ITCA2_2012_v01.txt\n",
      "L3 file: CEIP_EC_L3_ITRo4_2008_v01.txt\n",
      "L3 file: CEIP_EC_L3_NLLan_2006_v01.txt\n",
      "L3 file: CEIP_EC_L3_UKESa_2003_v01.txt\n",
      "L3 file: CEIP_EC_L3_ITCas_2006_v01.txt\n",
      "L3 file: CEIP_EC_L3_ITCas_2007_v01.txt\n",
      "L3 file: CEIP_EC_L3_NLLut_2007_v02.txt\n",
      "L3 file: CEIP_EC_L3_IECa1_2007_v01.txt\n",
      "L3 file: CEIP_EC_L3_NLMol_2005_v02.txt\n",
      "L3 file: CEIP_EC_L3_IECa1_2006_v01.txt\n",
      "L3 file: CEIP_EC_L3_ITCas_2008_v02.txt\n",
      "L3 file: CEIP_EC_L3_IECa1_2004_v01.txt\n",
      "L3 file: CEIP_EC_L3_FRAvi_2004_v02.txt\n",
      "L3 file: CEIP_EC_L3_FRAvi_2005_v02.txt\n",
      "L3 file: CEIP_EC_L3_IECa1_2005_v01.txt\n",
      "L3 file: CEIP_EC_L3_ITCas_2009_v02.txt\n",
      "L3 file: CEIP_EC_L3_ESES2_2009_v02.txt\n",
      "L3 file: CEIP_EC_L3_ITRo3_2008_v01.txt\n",
      "L3 file: CEIP_EC_L3_ITRo3_2009_v01.txt\n",
      "L3 file: CEIP_EC_L3_UKHer_2006_v01.txt\n",
      "L3 file: CEIP_EC_L3_ITRo3_2011_v01.txt\n",
      "L3 file: CEIP_EC_L3_ITRo3_2013_v01.txt\n",
      "L3 file: CEIP_EC_L3_ITBCi_2008_v02.txt\n",
      "L3 file: CEIP_EC_L3_ITRo4_2009_v02.txt\n",
      "L3 file: CEIP_EC_L3_ESES2_2010_v02.txt\n",
      "L3 file: CEIP_EC_L3_ITRo3_2012_v01.txt\n",
      "L3 file: CEIP_EC_L3_ITCas_2010_v02.txt\n",
      "L3 file: CEIP_EC_L3_FRGri_2004_v01.txt\n",
      "L3 file: CEIP_EC_L3_FRGri_2005_v01.txt\n",
      "L3 file: CEIP_EC_L3_FRGri_2007_v01.txt\n",
      "L3 file: CEIP_EC_L3_FRGri_2006_v01.txt\n",
      "L3 file: CEIP_EC_L3_NLLut_2006_v01.txt\n",
      "L3 file: CEIP_EC_L3_FRAvi_2006_v01.txt\n",
      "L3 file: CEIP_EC_L3_NLMol_2006_v01.txt\n",
      "L3 file: CEIP_EC_L3_ITBCi_2005_v01.txt\n",
      "L3 file: CEIP_EC_L3_ITRo4_2011_v01.txt\n",
      "L3 file: CEIP_EC_L3_ITBCi_2010_v01.txt\n",
      "L3 file: CEIP_EC_L3_ITBCi_2004_v01.txt\n",
      "L3 file: CEIP_EC_L3_ITBCi_2006_v01.txt\n",
      "L3 file: CEIP_EC_L3_ITRo4_2013_v01.txt\n",
      "L3 file: CEIP_EC_L3_ITRo4_2012_v01.txt\n",
      "L3 file: CEIP_EC_L3_ITBCi_2007_v01.txt\n",
      "-----------------------------------------\n",
      "L4 file: CEIP_EC_L4_h_ITRo4_2008_v01.txt\n",
      "L4 file: CEIP_EC_L4_h_ITCA2_2012_v01.txt\n",
      "L4 file: CEIP_EC_L4_h_ITBCi_2009_v01.txt\n",
      "L4 file: CEIP_EC_L4_h_ESES2_2010_v01.txt\n",
      "L4 file: CEIP_EC_L4_h_NLLan_2006_v01.txt\n",
      "L4 file: CEIP_EC_L4_h_NLLan_2005_v01.txt\n",
      "L4 file: CEIP_EC_L4_h_ITCas_2006_v01.txt\n",
      "L4 file: CEIP_EC_L4_h_NLLut_2007_v02.txt\n",
      "L4 file: CEIP_EC_L4_h_ITCas_2007_v01.txt\n",
      "L4 file: CEIP_EC_L4_h_FRGri_2005_v02.txt\n",
      "L4 file: CEIP_EC_L4_h_UKESa_2003_v01.txt\n",
      "L4 file: CEIP_EC_L4_h_ITCas_2008_v02.txt\n",
      "L4 file: CEIP_EC_L4_h_FRAvi_2004_v02.txt\n",
      "L4 file: CEIP_EC_L4_h_FRAvi_2005_v02.txt\n",
      "L4 file: CEIP_EC_L4_h_ITCas_2009_v02.txt\n",
      "L4 file: CEIP_EC_L4_h_IECa1_2007_v01.txt\n",
      "L4 file: CEIP_EC_L4_h_IECa1_2006_v01.txt\n",
      "L4 file: CEIP_EC_L4_h_NLMol_2005_v02.txt\n",
      "L4 file: CEIP_EC_L4_h_ITRo3_2008_v01.txt\n",
      "L4 file: CEIP_EC_L4_h_ITRo3_2009_v01.txt\n",
      "L4 file: CEIP_EC_L4_h_ITBCi_2004_v02.txt\n",
      "L4 file: CEIP_EC_L4_h_ITBCi_2005_v02.txt\n",
      "L4 file: CEIP_EC_L4_h_ITRo3_2013_v01.txt\n",
      "L4 file: CEIP_EC_L4_h_ITRo4_2009_v02.txt\n",
      "L4 file: CEIP_EC_L4_h_ITBCi_2008_v02.txt\n",
      "L4 file: CEIP_EC_L4_h_ITRo3_2012_v01.txt\n",
      "L4 file: CEIP_EC_L4_h_UKESa_2004_v02.txt\n",
      "L4 file: CEIP_EC_L4_h_UKHer_2006_v01.txt\n",
      "L4 file: CEIP_EC_L4_h_ITRo3_2011_v01.txt\n",
      "L4 file: CEIP_EC_L4_h_UKESa_2005_v02.txt\n",
      "L4 file: CEIP_EC_L4_h_FRGri_2007_v01.txt\n",
      "L4 file: CEIP_EC_L4_h_FRGri_2006_v01.txt\n",
      "L4 file: CEIP_EC_L4_h_NLLut_2006_v01.txt\n",
      "L4 file: CEIP_EC_L4_h_ITCas_2010_v02.txt\n",
      "L4 file: CEIP_EC_L4_h_FRGri_2004_v01.txt\n",
      "L4 file: CEIP_EC_L4_h_NLMol_2006_v01.txt\n",
      "L4 file: CEIP_EC_L4_h_IECa1_2005_v02.txt\n",
      "L4 file: CEIP_EC_L4_h_IECa1_2004_v02.txt\n",
      "L4 file: CEIP_EC_L4_h_FRAvi_2006_v01.txt\n",
      "L4 file: CEIP_EC_L4_h_ITRo4_2013_v01.txt\n",
      "L4 file: CEIP_EC_L4_h_ITBCi_2006_v01.txt\n",
      "L4 file: CEIP_EC_L4_h_ITBCi_2007_v01.txt\n",
      "L4 file: CEIP_EC_L4_h_ITRo4_2012_v01.txt\n",
      "L4 file: CEIP_EC_L4_h_ESES2_2009_v01.txt\n",
      "L4 file: CEIP_EC_L4_h_ITBCi_2010_v01.txt\n",
      "L4 file: CEIP_EC_L4_h_ITRo4_2011_v01.txt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Day</th>\n",
       "      <th>DoY</th>\n",
       "      <th>GPP_or_ANN</th>\n",
       "      <th>GPP_or_MDS</th>\n",
       "      <th>GPP_st_ANN</th>\n",
       "      <th>GPP_st_MDS</th>\n",
       "      <th>H_f</th>\n",
       "      <th>H_fqc</th>\n",
       "      <th>Hour</th>\n",
       "      <th>LE_f</th>\n",
       "      <th>...</th>\n",
       "      <th>Ta_f</th>\n",
       "      <th>Ta_fqc</th>\n",
       "      <th>Ts_f</th>\n",
       "      <th>Ts_fqc</th>\n",
       "      <th>VPD_f</th>\n",
       "      <th>VPD_fqc</th>\n",
       "      <th>Version</th>\n",
       "      <th>Year</th>\n",
       "      <th>qf_NEE_or</th>\n",
       "      <th>qf_NEE_st</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.021</td>\n",
       "      <td>-0.141</td>\n",
       "      <td>-0.029</td>\n",
       "      <td>-0.248</td>\n",
       "      <td>-0.026</td>\n",
       "      <td>-26.67</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.19</td>\n",
       "      <td>...</td>\n",
       "      <td>8.12</td>\n",
       "      <td>0</td>\n",
       "      <td>8.31</td>\n",
       "      <td>0</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>-9999</td>\n",
       "      <td>v01.txt</td>\n",
       "      <td>2008</td>\n",
       "      <td>259</td>\n",
       "      <td>259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.042</td>\n",
       "      <td>0.387</td>\n",
       "      <td>0.387</td>\n",
       "      <td>0.391</td>\n",
       "      <td>0.391</td>\n",
       "      <td>-25.78</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.06</td>\n",
       "      <td>...</td>\n",
       "      <td>7.78</td>\n",
       "      <td>0</td>\n",
       "      <td>8.25</td>\n",
       "      <td>0</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>-9999</td>\n",
       "      <td>v01.txt</td>\n",
       "      <td>2008</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1.063</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.229</td>\n",
       "      <td>0.229</td>\n",
       "      <td>-29.29</td>\n",
       "      <td>0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.25</td>\n",
       "      <td>...</td>\n",
       "      <td>7.43</td>\n",
       "      <td>0</td>\n",
       "      <td>8.20</td>\n",
       "      <td>0</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>-9999</td>\n",
       "      <td>v01.txt</td>\n",
       "      <td>2008</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1.083</td>\n",
       "      <td>0.321</td>\n",
       "      <td>0.321</td>\n",
       "      <td>0.325</td>\n",
       "      <td>0.325</td>\n",
       "      <td>-25.95</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.05</td>\n",
       "      <td>...</td>\n",
       "      <td>7.62</td>\n",
       "      <td>0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>-9999</td>\n",
       "      <td>v01.txt</td>\n",
       "      <td>2008</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1.104</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.229</td>\n",
       "      <td>0.229</td>\n",
       "      <td>-33.06</td>\n",
       "      <td>0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.72</td>\n",
       "      <td>...</td>\n",
       "      <td>7.31</td>\n",
       "      <td>0</td>\n",
       "      <td>8.10</td>\n",
       "      <td>0</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>-9999</td>\n",
       "      <td>v01.txt</td>\n",
       "      <td>2008</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Day    DoY  GPP_or_ANN  GPP_or_MDS  GPP_st_ANN  GPP_st_MDS    H_f  H_fqc  \\\n",
       "0    1  1.021      -0.141      -0.029      -0.248      -0.026 -26.67      0   \n",
       "1    1  1.042       0.387       0.387       0.391       0.391 -25.78      0   \n",
       "2    1  1.063       0.225       0.225       0.229       0.229 -29.29      0   \n",
       "3    1  1.083       0.321       0.321       0.325       0.325 -25.95      0   \n",
       "4    1  1.104       0.225       0.225       0.229       0.229 -33.06      0   \n",
       "\n",
       "   Hour  LE_f  ...  Ta_f  Ta_fqc  Ts_f  Ts_fqc   VPD_f  VPD_fqc  Version  \\\n",
       "0   0.5  2.19  ...  8.12       0  8.31       0 -9999.0    -9999  v01.txt   \n",
       "1   1.0  2.06  ...  7.78       0  8.25       0 -9999.0    -9999  v01.txt   \n",
       "2   1.5  1.25  ...  7.43       0  8.20       0 -9999.0    -9999  v01.txt   \n",
       "3   2.0  1.05  ...  7.62       0  8.14       0 -9999.0    -9999  v01.txt   \n",
       "4   2.5  0.72  ...  7.31       0  8.10       0 -9999.0    -9999  v01.txt   \n",
       "\n",
       "   Year  qf_NEE_or  qf_NEE_st  \n",
       "0  2008        259        259  \n",
       "1  2008          0          0  \n",
       "2  2008          0          0  \n",
       "3  2008          0          0  \n",
       "4  2008          0          0  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class EuroFlux:\n",
    "\n",
    "    def __init__(self, input_path, output_path):\n",
    "        print(\"Initializer\")\n",
    "        self.input_path = input_path\n",
    "        self.output_path = output_path\n",
    "        \n",
    "    def unzip_folder(self, filename):\n",
    "        if filename.endswith(\".zip\"):\n",
    "            name = os.path.splitext(os.path.basename(filename))[0]\n",
    "            path = self.input_path + name\n",
    "            if not os.path.isdir(path):\n",
    "                try:\n",
    "                    zip = zipfile.ZipFile(filename)\n",
    "\n",
    "                    os.mkdir(path)\n",
    "                    zip.extractall(path=path)\n",
    "                    zip.close()\n",
    "                    os.remove(filename)\n",
    "                except:\n",
    "                    print(\"BAD ZIP: \", filename)\n",
    "        \n",
    "    def unzip_folders(self):\n",
    "        files = Helpers.get_files_directory(input_path)\n",
    "        for i in range(len(files)):\n",
    "            file = files[i]\n",
    "            head, file_name = os.path.split(file)\n",
    "            if file_name.endswith(\".zip\"):\n",
    "                self.unzip_folder(file)\n",
    "                \n",
    "    def read_l2_data(self):\n",
    "        files = Helpers.get_files_directory(input_path)\n",
    "        l2_files = []\n",
    "        df_list = []\n",
    "        for i in range(len(files)):\n",
    "            file = files[i]\n",
    "            head, file_name = os.path.split(file)\n",
    "            if file_name.endswith(\".txt\"):\n",
    "                components = file_name.split(\"_\")\n",
    "                if components[1] == \"L2\":\n",
    "                    print(\"L2 file:\", file_name)\n",
    "                    l2_files.append(file_name)\n",
    "                    df = pd.read_csv(file , sep=\",\")\n",
    "                    df[\"Site Id\"] = components[3]\n",
    "                    df[\"Year\"] = components[4]\n",
    "                    df[\"Version\"] = components[5]\n",
    "                    df_list.append(df)\n",
    "                    \n",
    "        return Helpers.list_to_df(df_list)\n",
    "\n",
    "    def read_l3_data(self):\n",
    "        files = Helpers.get_files_directory(input_path)\n",
    "        l2_files = []\n",
    "        df_list = []\n",
    "        for i in range(len(files)):\n",
    "            file = files[i]\n",
    "            head, file_name = os.path.split(file)\n",
    "            if file_name.endswith(\".txt\"):\n",
    "                components = file_name.split(\"_\")\n",
    "                if len(components) > 2:\n",
    "                    if components[2] == \"L3\":\n",
    "                        print(\"L3 file:\", file_name)\n",
    "                        l2_files.append(file_name)\n",
    "                        df = pd.read_csv(file , sep=\",\")\n",
    "                        df[\"Site Id\"] = components[3]\n",
    "                        df[\"Year\"] = components[4]\n",
    "                        df[\"Version\"] = components[5]\n",
    "                        df_list.append(df)\n",
    "                    \n",
    "        return Helpers.list_to_df(df_list)\n",
    "    \n",
    "    def read_l4_data(self):\n",
    "        files = Helpers.get_files_directory(input_path)\n",
    "        l2_files = []\n",
    "        df_list = []\n",
    "        for i in range(len(files)):\n",
    "            file = files[i]\n",
    "            head, file_name = os.path.split(file)\n",
    "            if file_name.endswith(\".txt\"):\n",
    "                components = file_name.split(\"_\")\n",
    "                if len(components) > 2:\n",
    "                    if (components[2] == \"L4\") and (components[3] == \"h\"):\n",
    "                        print(\"L4 file:\", file_name)\n",
    "                        l2_files.append(file_name)\n",
    "                        df = pd.read_csv(file , sep=\",\")\n",
    "                        df[\"Site Id\"] = components[4]\n",
    "                        df[\"Year\"] = components[5]\n",
    "                        df[\"Version\"] = components[6]\n",
    "                        df_list.append(df)\n",
    "                    \n",
    "        return Helpers.list_to_df(df_list)\n",
    "                    \n",
    "input_path = \"/Users/saraawad/Desktop/Datasets/Google/Euroflux/\"\n",
    "output_path = \"\"\n",
    "ef = EuroFlux(input_path, output_path)\n",
    "ef.unzip_folders()\n",
    "df2_list = ef.read_l2_data()\n",
    "df2_list.head()\n",
    "print(\"-----------------------------------------\")\n",
    "\n",
    "df3_list = ef.read_l3_data()\n",
    "df3_list.head()\n",
    "print(\"-----------------------------------------\")\n",
    "\n",
    "df4_list = ef.read_l4_data()\n",
    "df4_list.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ALB', 'APAR', 'CH4', 'CO2', 'DTime', 'D_SNOW', 'FC', 'FCH4',\n",
      "       'FC_SSITC_TEST', 'FETCH_70', 'FETCH_90', 'FETCH_MAX', 'FO3', 'G', 'G_2',\n",
      "       'H', 'H2O', 'H_SSITC_TEST', 'LE', 'LE_SSITC_TEST', 'LW_IN', 'LW_OUT',\n",
      "       'MO_LENGTH', 'NDVI', 'NEE_PI', 'NETRAD', 'O3', 'P', 'PA', 'PPFD_BC_IN',\n",
      "       'PPFD_DIF', 'PPFD_IN', 'PPFD_OUT', 'RH', 'RH_3', 'SB', 'SC', 'SCH4',\n",
      "       'SH', 'SLE', 'SWC', 'SWC_2', 'SWC_3', 'SW_BC_IN', 'SW_DIF', 'SW_IN',\n",
      "       'SW_OUT', 'Site Id', 'TA', 'TAU', 'TAU_SSITC_TEST', 'TIMESTAMP_END',\n",
      "       'TIMESTAMP_START', 'TR', 'TS', 'TS_2', 'TS_3', 'T_BOLE', 'T_CANOPY',\n",
      "       'T_SONIC', 'T_SONIC_SIGMA', 'USTAR', 'V_SIGMA', 'Version', 'WD', 'WS',\n",
      "       'WTD', 'W_SIGMA', 'Year', 'ZL'],\n",
      "      dtype='object')\n",
      "Index(['APAR', 'CO2', 'Day', 'DoY', 'Fc', 'G1', 'G2', 'H', 'H2O', 'Hour', 'LE',\n",
      "       'Month', 'NEE_or', 'NEE_st', 'PPFD', 'Precip', 'R_pot', 'Rd', 'Rg',\n",
      "       'Rh', 'Rn', 'Rr', 'SWC1', 'SWC2', 'Site Id', 'Ta', 'Ts1', 'Ts2',\n",
      "       'Version', 'WD', 'WS', 'Year', 'ZL', 'qf_Fc', 'qf_NEE_or', 'qf_NEE_st',\n",
      "       'qf_Rad', 'qf_Rg', 'qf_ust', 'ustar'],\n",
      "      dtype='object')\n",
      "Index(['Day', 'DoY', 'GPP_or_ANN', 'GPP_or_MDS', 'GPP_st_ANN', 'GPP_st_MDS',\n",
      "       'H_f', 'H_fqc', 'Hour', 'LE_f', 'LE_fqc', 'Month', 'NEE_or_fANN',\n",
      "       'NEE_or_fANNqc', 'NEE_or_fMDS', 'NEE_or_fMDSqc', 'NEE_st_fANN',\n",
      "       'NEE_st_fANNqc', 'NEE_st_fMDS', 'NEE_st_fMDSqc', 'Precip', 'Reco_or',\n",
      "       'Reco_st', 'Rg_f', 'Rg_fqc', 'SWC', 'Site Id', 'Ta_f', 'Ta_fqc', 'Ts_f',\n",
      "       'Ts_fqc', 'VPD_f', 'VPD_fqc', 'Version', 'Year', 'qf_NEE_or',\n",
      "       'qf_NEE_st'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df2_list.columns)\n",
    "print(df3_list.columns)\n",
    "print(df4_list.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['FIJok' 'ITCA2' 'IECa1' 'ITBCi' 'FRGri' 'FRAvi' 'ITCas' 'ESES2' 'BELon'\n",
      " 'DERuS' 'UKESa' 'NLLan' 'ITRo3' 'UKHer' 'ITRo4' 'NLLut' 'NLMol' 'CHOe2']\n",
      "['UKESa' 'NLLan' 'ITBCi' 'ITCA2' 'ITRo4' 'ITCas' 'NLLut' 'IECa1' 'NLMol'\n",
      " 'FRAvi' 'ESES2' 'ITRo3' 'UKHer' 'FRGri']\n",
      "['ITRo4' 'ITCA2' 'ITBCi' 'ESES2' 'NLLan' 'ITCas' 'NLLut' 'FRGri' 'UKESa'\n",
      " 'FRAvi' 'IECa1' 'NLMol' 'ITRo3' 'UKHer']\n"
     ]
    }
   ],
   "source": [
    "print(df2_list[\"Site Id\"].unique())\n",
    "print(df3_list[\"Site Id\"].unique())\n",
    "print(df4_list[\"Site Id\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_path = \"/Users/saraawad/Desktop/Datasets/Google/\"\n",
    "Helpers.export_data(df2_list, \"EuroFlux/Processed Data/L2\")\n",
    "Helpers.export_data(df3_list, \"EuroFlux/Processed Data/L3\")\n",
    "Helpers.export_data(df4_list, \"EuroFlux/Processed Data/L4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2002', '2014', '2008', '2010', '2007', '2013', '2004', '2012',\n",
       "       '2011', '2006', '2015', '2009', '2016', '2001', '2000', '2005',\n",
       "       '2003', '2018', '2017'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_list[\"Year\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALB</th>\n",
       "      <th>APAR</th>\n",
       "      <th>CH4</th>\n",
       "      <th>CO2</th>\n",
       "      <th>DTime</th>\n",
       "      <th>D_SNOW</th>\n",
       "      <th>FC</th>\n",
       "      <th>FCH4</th>\n",
       "      <th>FC_SSITC_TEST</th>\n",
       "      <th>FETCH_70</th>\n",
       "      <th>...</th>\n",
       "      <th>T_SONIC_SIGMA</th>\n",
       "      <th>USTAR</th>\n",
       "      <th>V_SIGMA</th>\n",
       "      <th>Version</th>\n",
       "      <th>WD</th>\n",
       "      <th>WS</th>\n",
       "      <th>WTD</th>\n",
       "      <th>W_SIGMA</th>\n",
       "      <th>Year</th>\n",
       "      <th>ZL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>364.646</td>\n",
       "      <td>1.021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.511613</td>\n",
       "      <td>NaN</td>\n",
       "      <td>v01</td>\n",
       "      <td>323.076</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2004</td>\n",
       "      <td>0.002802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>364.604</td>\n",
       "      <td>1.042</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.520275</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.595937</td>\n",
       "      <td>NaN</td>\n",
       "      <td>v01</td>\n",
       "      <td>322.671</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2004</td>\n",
       "      <td>0.001990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>364.873</td>\n",
       "      <td>1.062</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.028347</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.496811</td>\n",
       "      <td>NaN</td>\n",
       "      <td>v01</td>\n",
       "      <td>321.506</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2004</td>\n",
       "      <td>0.002879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>364.719</td>\n",
       "      <td>1.083</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.657292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.554576</td>\n",
       "      <td>NaN</td>\n",
       "      <td>v01</td>\n",
       "      <td>314.502</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2004</td>\n",
       "      <td>0.002166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>364.492</td>\n",
       "      <td>1.104</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.943508</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.439567</td>\n",
       "      <td>NaN</td>\n",
       "      <td>v01</td>\n",
       "      <td>314.187</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2004</td>\n",
       "      <td>0.004476</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ALB  APAR  CH4      CO2  DTime  D_SNOW           FC  FCH4  FC_SSITC_TEST  \\\n",
       "0  NaN   NaN  NaN  364.646  1.021     NaN -9999.000000   NaN        -9999.0   \n",
       "1  NaN   NaN  NaN  364.604  1.042     NaN     0.520275   NaN            1.0   \n",
       "2  NaN   NaN  NaN  364.873  1.062     NaN     0.028347   NaN            1.0   \n",
       "3  NaN   NaN  NaN  364.719  1.083     NaN     1.657292   NaN            1.0   \n",
       "4  NaN   NaN  NaN  364.492  1.104     NaN     0.943508   NaN            1.0   \n",
       "\n",
       "   FETCH_70  ...  T_SONIC_SIGMA     USTAR  V_SIGMA  Version       WD  WS  WTD  \\\n",
       "0       NaN  ...            NaN  0.511613      NaN      v01  323.076 NaN  NaN   \n",
       "1       NaN  ...            NaN  0.595937      NaN      v01  322.671 NaN  NaN   \n",
       "2       NaN  ...            NaN  0.496811      NaN      v01  321.506 NaN  NaN   \n",
       "3       NaN  ...            NaN  0.554576      NaN      v01  314.502 NaN  NaN   \n",
       "4       NaN  ...            NaN  0.439567      NaN      v01  314.187 NaN  NaN   \n",
       "\n",
       "   W_SIGMA  Year        ZL  \n",
       "0      NaN  2004  0.002802  \n",
       "1      NaN  2004  0.001990  \n",
       "2      NaN  2004  0.002879  \n",
       "3      NaN  2004  0.002166  \n",
       "4      NaN  2004  0.004476  \n",
       "\n",
       "[5 rows x 70 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fr_df = df2_list[df2_list[\"Site Id\"] == \"FRAvi\"]\n",
    "fr_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WS</th>\n",
       "      <th>RH</th>\n",
       "      <th>TA</th>\n",
       "      <th>NETRAD</th>\n",
       "      <th>G</th>\n",
       "      <th>H</th>\n",
       "      <th>LE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>0.0</td>\n",
       "      <td>52606.000000</td>\n",
       "      <td>52608.000000</td>\n",
       "      <td>42843.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39172.000000</td>\n",
       "      <td>36788.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>65.799117</td>\n",
       "      <td>14.472807</td>\n",
       "      <td>65.552653</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.773627</td>\n",
       "      <td>53.645473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>20.247881</td>\n",
       "      <td>8.343256</td>\n",
       "      <td>178.227439</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93.640369</td>\n",
       "      <td>79.862986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>12.170000</td>\n",
       "      <td>-8.593333</td>\n",
       "      <td>-122.955060</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-195.711000</td>\n",
       "      <td>-24.808700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>50.250000</td>\n",
       "      <td>7.626250</td>\n",
       "      <td>-64.371161</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-29.801525</td>\n",
       "      <td>4.862455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>65.750000</td>\n",
       "      <td>14.535000</td>\n",
       "      <td>-10.184287</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.667165</td>\n",
       "      <td>25.121750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>82.490000</td>\n",
       "      <td>20.710000</td>\n",
       "      <td>152.182347</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.198775</td>\n",
       "      <td>64.666475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>37.300000</td>\n",
       "      <td>720.530230</td>\n",
       "      <td>NaN</td>\n",
       "      <td>533.348000</td>\n",
       "      <td>585.891000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        WS            RH            TA        NETRAD    G             H  \\\n",
       "count  0.0  52606.000000  52608.000000  42843.000000  0.0  39172.000000   \n",
       "mean   NaN     65.799117     14.472807     65.552653  NaN     23.773627   \n",
       "std    NaN     20.247881      8.343256    178.227439  NaN     93.640369   \n",
       "min    NaN     12.170000     -8.593333   -122.955060  NaN   -195.711000   \n",
       "25%    NaN     50.250000      7.626250    -64.371161  NaN    -29.801525   \n",
       "50%    NaN     65.750000     14.535000    -10.184287  NaN     -2.667165   \n",
       "75%    NaN     82.490000     20.710000    152.182347  NaN     45.198775   \n",
       "max    NaN    100.000000     37.300000    720.530230  NaN    533.348000   \n",
       "\n",
       "                 LE  \n",
       "count  36788.000000  \n",
       "mean      53.645473  \n",
       "std       79.862986  \n",
       "min      -24.808700  \n",
       "25%        4.862455  \n",
       "50%       25.121750  \n",
       "75%       64.666475  \n",
       "max      585.891000  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fr_df = Helpers.convert_missing_values_nan(fr_df)\n",
    "fr_df[[\"WS\", \"RH\", \"TA\", \"NETRAD\", \"G\", \"H\", \"LE\"]].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52608, 9)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fr_df = fr_df[[\"TIMESTAMP_START\", \"TIMESTAMP_END\", \"WS\", \"RH\", \"TA\", \"NETRAD\", \"G\", \"H\", \"LE\"]]\n",
    "fr_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fr_df[fr_df['LE'].notnull()]\n",
    "fr_df.dropna(subset=[\"NETRAD\", \"H\", \"LE\", \"TA\", \"RH\", \"WS\", \"G\"], how='all', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TIMESTAMP_START</th>\n",
       "      <th>TIMESTAMP_END</th>\n",
       "      <th>WS</th>\n",
       "      <th>RH</th>\n",
       "      <th>TA</th>\n",
       "      <th>NETRAD</th>\n",
       "      <th>G</th>\n",
       "      <th>H</th>\n",
       "      <th>LE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.260800e+04</td>\n",
       "      <td>5.260800e+04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52606.000000</td>\n",
       "      <td>52608.000000</td>\n",
       "      <td>42843.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39172.000000</td>\n",
       "      <td>36788.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.005066e+11</td>\n",
       "      <td>2.005066e+11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65.799117</td>\n",
       "      <td>14.472807</td>\n",
       "      <td>65.552653</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.773627</td>\n",
       "      <td>53.645473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.174679e+07</td>\n",
       "      <td>8.174988e+07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.247881</td>\n",
       "      <td>8.343256</td>\n",
       "      <td>178.227439</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93.640369</td>\n",
       "      <td>79.862986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.004010e+11</td>\n",
       "      <td>2.004010e+11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.170000</td>\n",
       "      <td>-8.593333</td>\n",
       "      <td>-122.955060</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-195.711000</td>\n",
       "      <td>-24.808700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.004098e+11</td>\n",
       "      <td>2.004100e+11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.250000</td>\n",
       "      <td>7.626250</td>\n",
       "      <td>-64.371161</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-29.801525</td>\n",
       "      <td>4.862455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.005070e+11</td>\n",
       "      <td>2.005070e+11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65.750000</td>\n",
       "      <td>14.535000</td>\n",
       "      <td>-10.184287</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.667165</td>\n",
       "      <td>25.121750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.006040e+11</td>\n",
       "      <td>2.006040e+11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82.490000</td>\n",
       "      <td>20.710000</td>\n",
       "      <td>152.182347</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.198775</td>\n",
       "      <td>64.666475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.006123e+11</td>\n",
       "      <td>2.007010e+11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>37.300000</td>\n",
       "      <td>720.530230</td>\n",
       "      <td>NaN</td>\n",
       "      <td>533.348000</td>\n",
       "      <td>585.891000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       TIMESTAMP_START  TIMESTAMP_END   WS            RH            TA  \\\n",
       "count     5.260800e+04   5.260800e+04  0.0  52606.000000  52608.000000   \n",
       "mean      2.005066e+11   2.005066e+11  NaN     65.799117     14.472807   \n",
       "std       8.174679e+07   8.174988e+07  NaN     20.247881      8.343256   \n",
       "min       2.004010e+11   2.004010e+11  NaN     12.170000     -8.593333   \n",
       "25%       2.004098e+11   2.004100e+11  NaN     50.250000      7.626250   \n",
       "50%       2.005070e+11   2.005070e+11  NaN     65.750000     14.535000   \n",
       "75%       2.006040e+11   2.006040e+11  NaN     82.490000     20.710000   \n",
       "max       2.006123e+11   2.007010e+11  NaN    100.000000     37.300000   \n",
       "\n",
       "             NETRAD    G             H            LE  \n",
       "count  42843.000000  0.0  39172.000000  36788.000000  \n",
       "mean      65.552653  NaN     23.773627     53.645473  \n",
       "std      178.227439  NaN     93.640369     79.862986  \n",
       "min     -122.955060  NaN   -195.711000    -24.808700  \n",
       "25%      -64.371161  NaN    -29.801525      4.862455  \n",
       "50%      -10.184287  NaN     -2.667165     25.121750  \n",
       "75%      152.182347  NaN     45.198775     64.666475  \n",
       "max      720.530230  NaN    533.348000    585.891000  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fr_df.shape\n",
    "fr_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x11efa7400>]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(2, figsize=(20, 80)) \n",
    "plt.plot(fr_df[\"LE\"], marker='o', markersize=7.0, color='green', linestyle='dashed', linewidth=2)\n",
    "plt.plot(fr_df3[\"LE\"], marker='v', markersize=7.0, color='blue', linestyle='dashed', linewidth=2)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAASgAAAEKCAYAAAChY8gkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlgPKzErLAWVmpeWAMrPSckCZWWn9P7L0OmkU9REkAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11dcd7a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.regplot(x=\"LE\", y=\"LE\", data=fr_df);\n",
    "lims = [\n",
    "    np.min([ax.get_xlim(), ax.get_ylim()]),  # min of both axes\n",
    "    np.max([ax.get_xlim(), ax.get_ylim()]),  # max of both axes\n",
    "    ]\n",
    "\n",
    "# now plot both limits against eachother\n",
    "ax.plot(lims, lims, 'k-', alpha=0.75, zorder=0)\n",
    "ax.set_aspect('equal')\n",
    "ax.set_xlim(lims)\n",
    "ax.set_ylim(lims)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'FIJok' 'ITCA2' 'IECa1' 'ITBCi' 'FRGri' 'FRAvi' 'ITCas' 'ESES2' 'BELon'\n",
    " 'DERuS' 'UKESa' 'NLLan' 'ITRo3' 'UKHer' 'ITRo4' 'NLLut' 'NLMol' 'CHOe2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'/Users/saraawad/Desktop/Datasets/Google/Euroflux/Processed\\\\ Data/L2.csv' does not exist: b'/Users/saraawad/Desktop/Datasets/Google/Euroflux/Processed\\\\ Data/L2.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-4d9c0e9f7896>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHelpers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/Users/saraawad/Desktop/Datasets/Google/Euroflux/Processed\\ Data/L2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf_site\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_site\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Site Id\"\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"BE-Lon\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_site\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Year\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-ae2a29ae089b>\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    683\u001b[0m         )\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1917\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'/Users/saraawad/Desktop/Datasets/Google/Euroflux/Processed\\\\ Data/L2.csv' does not exist: b'/Users/saraawad/Desktop/Datasets/Google/Euroflux/Processed\\\\ Data/L2.csv'"
     ]
    }
   ],
   "source": [
    "df = Helpers.load_data(\"/Users/saraawad/Desktop/Datasets/Google/Euroflux/Processed\\ Data/L2\")\n",
    "df_site = df_site[\"Site Id\" == \"BE-Lon\"]\n",
    "print(df_site[\"Year\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
