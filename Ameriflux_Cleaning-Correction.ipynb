{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "base_path = \"/Users/saraawad/Desktop/Datasets/Google/\"\n",
    "hourly_classified_path = os.path.join(base_path + \"Ameriflux/\", \"Ameriflux Hourly Classified/\")\n",
    "daily_classified_path = os.path.join(base_path + \"Ameriflux/\", \"Jan-11-2020_Hourly/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Helpers </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Helpers:\n",
    "    def __init__(self):\n",
    "        print(\"Helper\")\n",
    "        \n",
    "    def convert_missing_values_nan(df):\n",
    "        '''This function will convert -9999 to NaN'''\n",
    "        df = df.replace(-9999.000000, np.NaN)\n",
    "        return df\n",
    "\n",
    "    def drop_nan_columns(df):\n",
    "        '''Drops the columns having all theirs rows as Nans'''\n",
    "        columns_to_exclude = [\"Date\", \"Day\", \"Year\", \"Month\", \"Timestamp start\"\n",
    "                              , \"Time\", \"TIMESTAMP\", \"Tier\", \"TIMESTAMP_START\", \"TIMESTAMP_END\", \"Day Status\"]\n",
    "        columns = df.columns\n",
    "        for i in range(len(columns)):\n",
    "            col = columns[i]\n",
    "            if col in columns_to_exclude:\n",
    "                continue\n",
    "            nan_sum_col = df[col].isnull().sum()\n",
    "            if nan_sum_col == len(df):\n",
    "                df.drop(col, axis=1, inplace=True)\n",
    "        return df\n",
    "    \n",
    "    def drop_nans_rows(df):\n",
    "        '''This function will drop the rows having NaNs'''\n",
    "        print(\"Before removing missing values:\")\n",
    "        print(\"number of rows:\", df.shape[0], \"\\nnumber of columns:\", df.shape[1])\n",
    "        df = df.dropna(how='any')\n",
    "        print(\"After removing missing values:\")\n",
    "        print(\"number of rows:\", df.shape[0], \"\\nnumber of columns:\", df.shape[1])\n",
    "        return df\n",
    "        \n",
    "    def get_all_matching_columns(df, keyword):\n",
    "        return df.filter(like=keyword).columns\n",
    "\n",
    "    def generate_lags(df, column, lags_count): \n",
    "        for i in range(lags_count):\n",
    "            lag_name = column + \"-\" + str(i + 1)\n",
    "            df[lag_name] = df[column].shift(i + 1)\n",
    "#             for j in range(i):\n",
    "#                 df.loc[str(j+1), lag_name] = np.nan\n",
    "#         df = df.dropna(how='any')\n",
    "        return df\n",
    "\n",
    "    def add_LE_conversion_rate(df, col):\n",
    "        conversion_rate = 28.94\n",
    "        new_col = col + \"(mm)\"\n",
    "        df[new_col] = df[col] / conversion_rate\n",
    "        return df\n",
    "\n",
    "    def read_sites_data():\n",
    "        file_path = os.path.join(base_path, \"filtered_sites_all.xlsx\")\n",
    "        df = pd.read_excel(file_path)\n",
    "        df.head()\n",
    "        return df\n",
    "\n",
    "    def export_data(df, file_path):\n",
    "        export_path = os.path.join(base_path, file_path + \".csv\")\n",
    "        export_csv = df.to_csv(export_path, index=None, header=True)\n",
    "\n",
    "    def load_data(file_path):\n",
    "        df = pd.read_csv(file_path + \".csv\", delimiter=',')\n",
    "        return df\n",
    "    \n",
    "    def list_to_df(list_to_convert):\n",
    "        '''This function will convert the provided list into a dataframe'''\n",
    "        df = pd.concat(list_to_convert, sort=True)\n",
    "        return df\n",
    "    \n",
    "    def get_files_directory(dirName):\n",
    "    # create a list of file and sub directories \n",
    "    # names in the given directory \n",
    "        listOfFile = os.listdir(dirName)\n",
    "        allFiles = list()\n",
    "        # Iterate over all the entries\n",
    "        for entry in listOfFile:\n",
    "            # Create full path\n",
    "            if entry.endswith(\".xlsx\") or entry.endswith(\".icloud\") or entry.endswith(\".DS_Store\"):\n",
    "                continue\n",
    "            fullPath = os.path.join(dirName, entry)\n",
    "            # If entry is a directory then get the list of files in this directory \n",
    "            if os.path.isdir(fullPath):\n",
    "                allFiles = allFiles + Helpers.get_files_directory(fullPath)\n",
    "            else:\n",
    "                allFiles.append(fullPath)\n",
    "\n",
    "        return allFiles\n",
    "\n",
    "    def concat_dataframe_from_files(files, skipRowsNum, split_num):\n",
    "        values = []\n",
    "        for i in range(len(files)):\n",
    "            file_path = files[i]\n",
    "            head, file_name = os.path.split(file_path)\n",
    "            #Get only the sheets having the variables\n",
    "            if file_name.endswith(\".csv\"):\n",
    "#                 print(\"file name\", file_name)\n",
    "                df = pd.read_csv(file_path, delimiter=',', skiprows=skipRowsNum)\n",
    "                site_id = file_name.split(\"_\")[split_num]\n",
    "#                 print(\"site id in file:\", site_id)\n",
    "                df[\"Site Id\"] = site_id\n",
    "                values.append(df)\n",
    "        return Helpers.list_to_df(values)   \n",
    "    \n",
    "    def generate_dataframe_from_files(dirName, skipRowsNum = 0, split_num = 0):\n",
    "        files = Helpers.get_files_directory(dirName)\n",
    "        df = Helpers.concat_dataframe_from_files(files, skipRowsNum, split_num)\n",
    "        return df\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Ameriflux & Joint Class </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Ameriflux:\n",
    "\n",
    "    def __init__(self, folder_path, skipRowsNum, split_num, lags_count, is_hourly, is_joint, output_name):\n",
    "        print(\"Initializer\")\n",
    "        self.folder_path = folder_path\n",
    "        self.skipRowsNum = skipRowsNum\n",
    "        self.split_num = split_num\n",
    "        self.lags_count = lags_count\n",
    "        self.is_hourly = is_hourly\n",
    "        self.is_joint = is_joint\n",
    "        self.output_name = output_name\n",
    "        \n",
    "        \n",
    "    def are_bowes_elements_exists(self, df):\n",
    "        bowens_columns = [\"H\", \"LE\", \"NETRAD\", \"G\"]\n",
    "        if all([item in df.columns for item in bowens_columns]):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "    def compute_bowens_elements(self, df):\n",
    "        if self.are_bowes_elements_exists(df):\n",
    "            df[\"LATENT_SENSIBLE\"] = np.where(df[\"NETRAD\"] > 20, df[\"H\"] + df[\"LE\"], 0)\n",
    "            df[\"NETRAD_SOIL\"] = np.where(df[\"NETRAD\"] > 20, df[\"NETRAD\"] + df[\"G\"], 0)\n",
    "        return df\n",
    "    \n",
    "    def compute_bowens_ratio(self, df):\n",
    "        bowens_columns = [\"LATENT_SENSIBLE\", \"NETRAD_SOIL\"]\n",
    "        if all([item in df.columns for item in bowens_columns]):\n",
    "            df[\"C_BOWENS\"] = np.divide(df[\"LATENT_SENSIBLE\"], df[\"NETRAD_SOIL\"])\n",
    "            #If net radiation is not valid set the corrected columns as NaN and then remove their rows\n",
    "            df[\"LE_CORRECTED\"] = np.where(df[\"C_BOWENS\"] > 0, np.divide(df[\"LE\"], df[\"C_BOWENS\"]), np.NaN)\n",
    "            df[\"H_CORRECTED\"] = np.where(df[\"C_BOWENS\"] > 0, np.divide(df[\"H\"], df[\"C_BOWENS\"]), np.NaN)  \n",
    "            df.dropna(subset=[\"LE_CORRECTED\", \"H_CORRECTED\"], how='all', inplace=True)\n",
    "            df.drop(bowens_columns, axis=1, inplace=True)\n",
    "        return df\n",
    "            \n",
    "    def impute_temperature(self, df):\n",
    "        '''This function imputes the temperature by the mean when TA is negative otherwise set it to 0 \n",
    "        if the mean is negative'''\n",
    "        columns_list = [\"TA\"]\n",
    "\n",
    "        #Get the mean air temperature, if less than zero\n",
    "        #fall back to zero and then delete the mean column\n",
    "        for i in range(len(columns_list)):\n",
    "            col = columns_list[i]\n",
    "            new_col = col + \"-avg\"\n",
    "            df[new_col] = df[col].mean()\n",
    "            df[new_col] = np.where(df[new_col] < 0, 0, df[new_col])\n",
    "            df[col] = np.where(df[col] < 0, df[new_col], df[col])\n",
    "            \n",
    "        #Drop the new mean columns that are generated temporarly\n",
    "        new_columns_lists = []\n",
    "        for i in range(len(columns_list)):\n",
    "            col = columns_list[i]\n",
    "            new_col = col + \"-avg\" \n",
    "            new_columns_lists.append(new_col)\n",
    "        df.drop(new_columns_lists, axis=1, inplace=True)\n",
    "        \n",
    "        return df\n",
    "        \n",
    "    def transform_input_variants(self, df):\n",
    "        '''This function gets all the input column variants'''\n",
    "        ws_list = list(Helpers.get_all_matching_columns(df, \"WS_\"))\n",
    "        rh_list = list(Helpers.get_all_matching_columns(df, \"RH_\"))\n",
    "        ta_list = list(Helpers.get_all_matching_columns(df, \"TA_\"))\n",
    "        g_list = list(Helpers.get_all_matching_columns(df, \"G_\"))\n",
    "        h_list = [col for col in df if col.startswith('H_')]\n",
    "        netrad_list = list(Helpers.get_all_matching_columns(df, \"NETRAD_\"))\n",
    "        \n",
    "        df = self.group_input_variants(df, ws_list, \"WS\")\n",
    "        df = self.group_input_variants(df, rh_list, \"RH\")\n",
    "        df = self.group_input_variants(df, ta_list, \"TA\")\n",
    "        df = self.group_input_variants(df, g_list, \"G\")\n",
    "        df = self.group_input_variants(df, h_list, \"H\")\n",
    "        df = self.group_input_variants(df, netrad_list, \"NETRAD\")\n",
    "        df = self.impute_temperature(df)\n",
    "        print(\"After grouping\", df.columns)\n",
    "        return df\n",
    "        \n",
    "    def group_input_variants(self, df, variant_list, mean_column):\n",
    "        '''This function imputes all the input columnn variants with the mean of them and drop the variants'''\n",
    "        if len(variant_list) > 1:\n",
    "            df[mean_column] = \"\"\n",
    "            df[mean_column] = df[variant_list].mean(axis=1)\n",
    "        elif len(variant_list) > 0:\n",
    "             df[mean_column] = df[variant_list[0]]\n",
    "        \n",
    "        df = df.drop(variant_list, axis=1)\n",
    "        return df\n",
    "    \n",
    "    def check_If_TA_has_negative(self, df):\n",
    "        '''This function counts the number of negative air temperature'''\n",
    "        if \"TA\" in df.columns:\n",
    "            print(\"TA negative values count:\", df[\"TA\"].lt(0).sum())\n",
    "            \n",
    "    def generate_input_lags(self, df):\n",
    "        '''This function generates the lags for the list of input columns'''\n",
    "        input_columns = [\"RH\", \"TA\", \"G\", \"WS\", \"NETRAD\"]\n",
    "        h_corr_name = \"H_CORRECTED\"\n",
    "        if (h_corr_name in df.columns):\n",
    "            input_columns.append(h_corr_name)\n",
    "        elif \"H\" in df.columns:\n",
    "            input_columns.append(\"H\")\n",
    "        \n",
    "        for k in range(len(input_columns)):\n",
    "            col = input_columns[k]\n",
    "            if col in df.columns:\n",
    "                df = Helpers.generate_lags(df, col, self.lags_count)\n",
    "        return df\n",
    "    \n",
    "    def add_LE_converstion_to_lags(self, df):\n",
    "        '''This function adds the conversion for LE incase LE exists and generate lags \n",
    "        for it after adding the conversion'''\n",
    "        #Remove LE for sites having a variant of LE column\n",
    "        le_corrected_name = \"LE_CORRECTED\"\n",
    "        columns_to_drop = (list(df.filter(like='LE_').columns))\n",
    "        if le_corrected_name in columns_to_drop:\n",
    "            columns_to_drop.remove(le_corrected_name)\n",
    "        df.drop(columns_to_drop, axis=1, inplace=True)\n",
    "        \n",
    "        if le_corrected_name in df.columns:\n",
    "            column_to_convert = le_corrected_name\n",
    "        elif \"LE\" in df.columns:\n",
    "            column_to_convert = \"LE\"\n",
    "        if column_to_convert != \"\":\n",
    "            df = Helpers.add_LE_conversion_rate(df, column_to_convert)\n",
    "            columns_list = (list(df.filter(like='LE').columns))\n",
    "            filt_col_list = [col for col in columns_list if \"(mm)\" in col]\n",
    "            for k in range(len(filt_col_list)):\n",
    "                col = filt_col_list[k]\n",
    "                if col in df.columns:\n",
    "                    df = Helpers.generate_lags(df, col, self.lags_count)   \n",
    "        return df\n",
    "        \n",
    "    def remove_unneeded_columns_hourly(self, df):\n",
    "        main_columns = self.order_hourly_columns(df)\n",
    "        main_columns.extend([\"WS\", \"RH\", \"TA\", \"G\",  \"H\", \"NETRAD\", \"LE\"])\n",
    "        main_columns_exists = False\n",
    "        if all([item in df.columns for item in main_columns]):\n",
    "            #Remove rows having NaNs\n",
    "            df = df[main_columns]\n",
    "            df = Helpers.drop_nans_rows(df)\n",
    "            df = self.generate_input_lags(df)\n",
    "            df = self.add_LE_converstion_to_lags(df)\n",
    "            df = self.order_columns(df)\n",
    "            main_columns_exists = True\n",
    "        return (df, main_columns_exists)\n",
    "    \n",
    "    def remove_unneeded_columns_daily(self, df):\n",
    "        main_columns = self.order_daily_columns(df)\n",
    "        main_columns.extend([\"WS\", \"RH\", \"TA\", \"G\",  \"H\", \"NETRAD\", \"LE\", \"LATENT_SENSIBLE\", \"NETRAD_SOIL\"])\n",
    "        main_columns_exists = False\n",
    "        if all([item in df.columns for item in main_columns]):\n",
    "            #Remove rows having NaNs\n",
    "            df = df[main_columns]\n",
    "            df = Helpers.drop_nans_rows(df)\n",
    "            df = self.compute_bowens_ratio(df)\n",
    "            df = self.generate_input_lags(df)\n",
    "            df = self.add_LE_converstion_to_lags(df)\n",
    "            df = self.order_columns(df)\n",
    "            main_columns_exists = True\n",
    "        return (df, main_columns_exists)\n",
    "    \n",
    "            \n",
    "    def order_columns(self, df):\n",
    "        '''This function will specify the columns required and will order the columns'''\n",
    "        all_columns = self.order_hourly_columns(df) if is_hourly else self.order_daily_columns(df)\n",
    "        if \"WS\" in df.columns:\n",
    "            all_columns.append(\"WS\")\n",
    "        ws_list = [col for col in df if col.startswith('WS-')]\n",
    "        all_columns.extend(ws_list)\n",
    "        if \"RH\" in df.columns:\n",
    "            all_columns.append(\"RH\")\n",
    "        rh_list = [col for col in df if col.startswith('RH-')]\n",
    "        all_columns.extend(rh_list)\n",
    "        if \"TA\" in df.columns:\n",
    "            all_columns.append(\"TA\")\n",
    "        ta_list = [col for col in df if col.startswith('TA-')]\n",
    "        all_columns.extend(ta_list)\n",
    "        if \"G\" in df.columns:\n",
    "            all_columns.append(\"G\")\n",
    "        g_list = [col for col in df if col.startswith('G-')]\n",
    "        all_columns.extend(g_list)\n",
    "        if \"H\" in df.columns:\n",
    "            all_columns.append(\"H\")\n",
    "            h_list = [col for col in df if col.startswith('H-')]\n",
    "            all_columns.extend(h_list)\n",
    "        if \"H_CORRECTED\" in df.columns:\n",
    "            all_columns.append(\"H_CORRECTED\")\n",
    "            h_list = [col for col in df if col.startswith('H_CORRECTED-')]\n",
    "            all_columns.extend(h_list)\n",
    "            \n",
    "        netrad_list = [col for col in df if col.startswith('NETRAD')]\n",
    "        all_columns.extend(netrad_list)\n",
    "        \n",
    "        if \"LE_CORRECTED\" not in df.columns:\n",
    "            le_list = [col for col in df if col.startswith('LE')]\n",
    "            all_columns.extend(le_list)\n",
    "        else:\n",
    "            all_columns.append(\"LE\")\n",
    "            le_list = [col for col in df if col.startswith('LE_CORRECTED')]\n",
    "            all_columns.extend(le_list)\n",
    " \n",
    "        bowens_columns = [\"LATENT_SENSIBLE\", \"NETRAD_SOIL\"]\n",
    "        if (all([item in df.columns for item in bowens_columns])) and (self.is_hourly):\n",
    "            all_columns.extend(bowens_columns)\n",
    "            \n",
    "        if \"C_BOWENS\" in df.columns:\n",
    "            all_columns.append(\"C_BOWENS\")\n",
    "        print(\"ordered columns\", all_columns)\n",
    "        df = df[all_columns]\n",
    "        return df\n",
    "    \n",
    "    def order_hourly_columns(self, df):\n",
    "        '''This function will specify the calendar and main columns for the hourly data'''\n",
    "        all_columns = [\"Timestamp start\", \"TIMESTAMP_END\", \"Site Id\", \"Year\", \"Month\", \"Day\"]\n",
    "        return all_columns\n",
    "\n",
    "    def order_daily_columns(self, df):\n",
    "        '''This function will specify the calendar and main columns for the daily data'''\n",
    "        all_columns = [\"Date\", \"Site Id\", \"Year\", \"Month\", \"Day\"]\n",
    "        return all_columns\n",
    "    \n",
    "    def resample_date_todays(self, df):\n",
    "        '''This function will add a date column removing the hours and minutes'''\n",
    "        time_stamp = []\n",
    "        index_date_column = 0\n",
    "        if \"TIMESTAMP_END\" in df.columns:\n",
    "            index_date_column = df.columns.get_loc(\"TIMESTAMP_END\")\n",
    "        elif \"TIMESTAMP_start\" in df.columns:\n",
    "            index_date_column = df.columns.get_loc(\"TIMESTAMP_start\")\n",
    "        for i in range(df.shape[0]):\n",
    "            date = datetime.strptime(str(df.iloc[i, index_date_column]), \"%Y%m%d%H%M\").strftime('%m/%d/%y')\n",
    "            time_stamp.append(date)\n",
    "        df[\"Date\"] = time_stamp\n",
    "        return df\n",
    "\n",
    "    def generate_date_components(self, df):\n",
    "        '''This function creates new columns for year, month, day from the time stamp\n",
    "        and converts the data frame into a time series with the data sorted\n",
    "        in an ascending order'''\n",
    "        years = []\n",
    "        months = []\n",
    "        days = []\n",
    "        full_dates = []\n",
    "        for j in range(df.shape[0]):\n",
    "            #Gets the index of time stamp start column\n",
    "            index_date_column = df.columns.get_loc(\"Date\")\n",
    "            full_date_time = str(df.iloc[j, index_date_column])\n",
    "            years.append(full_date_time[0:4])\n",
    "            months.append(full_date_time[5:7])\n",
    "            days.append(full_date_time[8:10])\n",
    "            full_dates.append(full_date_time[0:10])\n",
    "        df[\"Year\"] = years\n",
    "        df[\"Month\"] = months\n",
    "        df[\"Day\"] = days\n",
    "        df[\"Date\"] = full_dates\n",
    "        df[\"Full Date\"] = full_dates\n",
    "        df[\"Full Date\"] = pd.to_datetime(df[\"Full Date\"])\n",
    "        df = df.set_index('Full Date')\n",
    "        df.sort_values(by=[\"Full Date\"], inplace=True)\n",
    "        return df\n",
    "\n",
    "    def group_dates_mean(self, df):\n",
    "        '''This function will resample the half-hourly data to daily'''\n",
    "        avg_columns = []\n",
    "        sum_columns = []\n",
    "        if \"RH\" in df.columns:\n",
    "            avg_columns.append(\"RH\")\n",
    "        if \"NETRAD\" in df.columns:\n",
    "            avg_columns.append(\"NETRAD\")\n",
    "        if \"TA\" in df.columns:\n",
    "            avg_columns.append(\"TA\")\n",
    "        if \"WS\" in df.columns:\n",
    "            avg_columns.append(\"WS\")\n",
    "        if \"H\" in df.columns:\n",
    "            avg_columns.append(\"H\")\n",
    "        if \"G\" in df.columns:\n",
    "            avg_columns.append(\"G\")\n",
    "        if \"LE\" in df.columns:\n",
    "            avg_columns.append(\"LE\")\n",
    "            \n",
    "        bowens_columns = [\"LATENT_SENSIBLE\", \"NETRAD_SOIL\"]\n",
    "        if all([item in df.columns for item in bowens_columns]):\n",
    "            sum_columns.extend(bowens_columns)\n",
    "        \n",
    "        dictionary_avg = {\n",
    "        i : np.mean for i in avg_columns\n",
    "        }\n",
    "        dictionary_sum = {\n",
    "        i : sum for i in sum_columns\n",
    "        }\n",
    "        result_dictionary = {**dictionary_avg , **dictionary_sum}\n",
    "        \"\"\"Get the average of the variables for each day\"\"\"\n",
    "        df = df.groupby(['Site Id','Date'], as_index=False).agg(result_dictionary)\n",
    "        df[\"Date\"] = pd.to_datetime(df[\"Date\"], format=\"%m/%d/%y\")\n",
    "        df = df.sort_values(by='Date')\n",
    "        return df\n",
    "    \n",
    "    def drop_invalid_columns(self, df):\n",
    "        '''This function will remove un-needed columns that have different unit of measure than the\n",
    "        other variants so they should be dropped before grouping variants'''\n",
    "        ssitc_list = list(Helpers.get_all_matching_columns(df, \"_SSITC_TEST\"))\n",
    "        max_list = list(Helpers.get_all_matching_columns(df, \"WS_MAX\"))\n",
    "        columnsToDrop = []\n",
    "        columnsToDrop.extend(ssitc_list)\n",
    "        columnsToDrop.extend(max_list)\n",
    "        print(\"columns to drop\", columnsToDrop)\n",
    "        df = df.drop(columnsToDrop, axis=1)\n",
    "        return df\n",
    "    \n",
    "    def generate_hourly_data(self, df):\n",
    "        '''This function will process the half-hourly data'''\n",
    "        df = self.drop_invalid_columns(df)\n",
    "        #-9999 is converted to NaNs\n",
    "        df = Helpers.convert_missing_values_nan(df)\n",
    "        #Remove rows having NaNs\n",
    "        df = Helpers.drop_nans_rows(df)\n",
    "        print(\"df shape:\", df.shape)\n",
    "        df = self.transform_input_variants(df)\n",
    "        (df, status) = self.remove_unneeded_columns_hourly(df)\n",
    "        df = self.compute_bowens_elements(df)\n",
    "        return (df, status)\n",
    "    \n",
    "    def generate_daily_data(self, df):\n",
    "        '''This function will process the daily data'''\n",
    "        df = self.resample_date_todays(df)\n",
    "        df = self.group_dates_mean(df)\n",
    "        df = self.generate_date_components(df)\n",
    "        (df, status) = self.remove_unneeded_columns_daily(df)\n",
    "        return (df, status)\n",
    "        \n",
    "    def generate_site_data(self, sites_df):\n",
    "        files = Helpers.get_files_directory(self.folder_path)\n",
    "        sites = []\n",
    "        group_sites_list = []\n",
    "        sites_dict = {}\n",
    "        for i in range(len(files)):\n",
    "            file_path = files[i]\n",
    "            head, file_name = os.path.split(file_path)\n",
    "            #Get only the sheets having the variables\n",
    "            if file_name.endswith(\".csv\"):\n",
    "                df_filt = pd.read_csv(file_path, delimiter=',', skiprows=self.skipRowsNum)\n",
    "                site_id = file_name.split(\"_\")[self.split_num]\n",
    "                df_filt[\"Site Id\"] = site_id\n",
    "                print(\"Site:\", site_id)\n",
    "                if self.is_hourly:\n",
    "                    (df_filt, status) = self.generate_hourly_data(df_filt)\n",
    "                    if not status:\n",
    "                        continue\n",
    "                else:\n",
    "                    (df_filt, status) = self.generate_daily_data(df_filt)\n",
    "                    if not status:\n",
    "                        continue\n",
    "                    print(\"columns:\", df_filt.columns)\n",
    "                    \n",
    "                #Concat all hours updated to a list\n",
    "                if (len(df_filt) > 0) and (\"LE\" in df_filt.columns) :\n",
    "                    sites.append(site_id)\n",
    "                    group_sites_list.append(df_filt)\n",
    "                    self.check_If_TA_has_negative(df_filt)\n",
    "#                     df_final = df_filt.replace(np.NaN, 0)\n",
    "                    sites_dict[site_id] = df_filt.columns \n",
    "                    \n",
    "                    \n",
    "                    suffix_name = \"Hourly\" if is_hourly else \"Daily\"\n",
    "                    file_name = os.path.join(self.output_name, site_id + \"_\" + suffix_name)\n",
    "                    Helpers.export_data(df_filt, file_name) \n",
    "\n",
    "            sites_dict_df = pd.DataFrame.from_dict(sites_dict, orient='index').transpose()\n",
    "            file_name = os.path.join(self.output_name, \"Sites_Variables\")\n",
    "            Helpers.export_data(sites_dict_df, file_name)  \n",
    "        \n",
    "        print(\"Valid Sites are\", sites)\n",
    "        return Helpers.list_to_df(group_sites_list)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Ameriflux Hourly Data </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializer\n",
      "Site: US-Twt\n",
      "columns to drop ['FC_SSITC_TEST', 'FCH4_SSITC_TEST', 'H_SSITC_TEST', 'LE_SSITC_TEST', 'TAU_SSITC_TEST_PI_F']\n",
      "Before removing missing values:\n",
      "number of rows: 144768 \n",
      "number of columns: 47\n",
      "After removing missing values:\n",
      "number of rows: 50155 \n",
      "number of columns: 47\n",
      "df shape: (50155, 47)\n",
      "After grouping Index(['TIMESTAMP_END', 'CO2', 'H2O', 'CH4', 'FC', 'FCH4', 'G', 'H', 'LE',\n",
      "       'WD', 'WS', 'USTAR', 'ZL', 'TAU', 'MO_LENGTH', 'V_SIGMA', 'W_SIGMA',\n",
      "       'PA', 'TA', 'VPD_PI', 'T_SONIC', 'T_SONIC_SIGMA', 'TS_PI_1', 'TS_PI_2',\n",
      "       'TS_PI_3', 'TS_PI_4', 'TS_PI_5', 'WTD', 'NETRAD', 'PPFD_IN', 'PPFD_OUT',\n",
      "       'SW_IN', 'P', 'FC_PI_F', 'RECO_PI_F', 'GPP_PI_F', 'FCH4_PI_F',\n",
      "       'LE_PI_F', 'Site Id', 'Category', 'Year', 'Month', 'Day', 'Date',\n",
      "       'Timestamp start', 'RH'],\n",
      "      dtype='object')\n",
      "Before removing missing values:\n",
      "number of rows: 50155 \n",
      "number of columns: 13\n",
      "After removing missing values:\n",
      "number of rows: 50155 \n",
      "number of columns: 13\n",
      "ordered columns ['Timestamp start', 'TIMESTAMP_END', 'Site Id', 'Year', 'Month', 'Day', 'WS', 'WS-1', 'WS-2', 'WS-3', 'WS-4', 'WS-5', 'RH', 'RH-1', 'RH-2', 'RH-3', 'RH-4', 'RH-5', 'TA', 'TA-1', 'TA-2', 'TA-3', 'TA-4', 'TA-5', 'G', 'G-1', 'G-2', 'G-3', 'G-4', 'G-5', 'H', 'H-1', 'H-2', 'H-3', 'H-4', 'H-5', 'NETRAD', 'NETRAD-1', 'NETRAD-2', 'NETRAD-3', 'NETRAD-4', 'NETRAD-5', 'LE', 'LE(mm)', 'LE(mm)-1', 'LE(mm)-2', 'LE(mm)-3', 'LE(mm)-4', 'LE(mm)-5']\n",
      "TA negative values count: 0\n",
      "Site: US-Wlr\n",
      "columns to drop []\n",
      "Before removing missing values:\n",
      "number of rows: 65700 \n",
      "number of columns: 28\n",
      "After removing missing values:\n",
      "number of rows: 48911 \n",
      "number of columns: 28\n",
      "df shape: (48911, 28)\n",
      "After grouping Index(['TIMESTAMP_END', 'FC', 'H', 'LE', 'TAU', 'TA', 'RH', 'NETRAD', 'SW_IN',\n",
      "       'SW_OUT', 'ALB', 'PPFD_IN', 'WS', 'WD', 'USTAR', 'ZL', 'PA', 'P', 'G',\n",
      "       'TS_1_1_1', 'SWC_1_1_1', 'Site Id', 'Category', 'Year', 'Month', 'Day',\n",
      "       'Date', 'Timestamp start'],\n",
      "      dtype='object')\n",
      "Before removing missing values:\n",
      "number of rows: 48911 \n",
      "number of columns: 13\n",
      "After removing missing values:\n",
      "number of rows: 48911 \n",
      "number of columns: 13\n",
      "ordered columns ['Timestamp start', 'TIMESTAMP_END', 'Site Id', 'Year', 'Month', 'Day', 'WS', 'WS-1', 'WS-2', 'WS-3', 'WS-4', 'WS-5', 'RH', 'RH-1', 'RH-2', 'RH-3', 'RH-4', 'RH-5', 'TA', 'TA-1', 'TA-2', 'TA-3', 'TA-4', 'TA-5', 'G', 'G-1', 'G-2', 'G-3', 'G-4', 'G-5', 'H', 'H-1', 'H-2', 'H-3', 'H-4', 'H-5', 'NETRAD', 'NETRAD-1', 'NETRAD-2', 'NETRAD-3', 'NETRAD-4', 'NETRAD-5', 'LE', 'LE(mm)', 'LE(mm)-1', 'LE(mm)-2', 'LE(mm)-3', 'LE(mm)-4', 'LE(mm)-5']\n",
      "TA negative values count: 0\n",
      "Site: US-ARM\n",
      "columns to drop ['TAU_SSITC_TEST_1_1_1', 'H_SSITC_TEST_1_1_1', 'LE_SSITC_TEST_1_1_1', 'FC_SSITC_TEST_1_1_1', 'WS_MAX_1_1_1']\n",
      "Before removing missing values:\n",
      "number of rows: 280548 \n",
      "number of columns: 76\n",
      "After removing missing values:\n",
      "number of rows: 0 \n",
      "number of columns: 76\n",
      "df shape: (0, 76)\n",
      "After grouping Index(['TIMESTAMP_END', 'CO2_1_1_1', 'H2O_1_1_1', 'TAU_1_1_1', 'LE_1_1_1',\n",
      "       'FC_1_1_1', 'WD_1_1_1', 'U_SIGMA_1_1_1', 'V_SIGMA_1_1_1',\n",
      "       'W_SIGMA_1_1_1', 'USTAR_1_1_1', 'MO_LENGTH_1_1_1', 'ZL_1_1_1',\n",
      "       'VPD_PI_1_1_1', 'T_SONIC_1_1_1', 'T_SONIC_SIGMA_1_1_1', 'WD_1_2_1',\n",
      "       'PA_1_1_1', 'SW_IN_1_1_1', 'LW_IN_1_1_1', 'SW_OUT_1_1_1',\n",
      "       'LW_OUT_1_1_1', 'SW_IN_1_1_2', 'PPFD_IN_1_1_1', 'P_1_1_1', 'SWC_1_1_1',\n",
      "       'SWC_2_1_1', 'SWC_1_2_1', 'SWC_2_2_1', 'SWC_3_1_1', 'SWC_4_1_1',\n",
      "       'SWC_3_2_1', 'SWC_4_2_1', 'TS_1_1_1', 'TS_1_2_1', 'TS_1_3_1',\n",
      "       'TS_2_1_1', 'TS_2_2_1', 'TS_2_3_1', 'PPFD_OUT_1_1_1', 'SWC_1_3_1',\n",
      "       'SWC_1_4_1', 'TS_1_4_1', 'SWC_1_5_1', 'TS_1_5_1', 'SWC_1_6_1',\n",
      "       'TS_1_6_1', 'SWC_2_3_1', 'SWC_2_3_2', 'TS_2_3_2', 'SWC_2_2_2',\n",
      "       'TS_2_2_2', 'SWC_2_1_2', 'TS_2_1_2', 'SW_DIR_1_1_1', 'SW_DIF_1_1_1',\n",
      "       'T_CANOPY_1_1_1', 'Site Id', 'Category', 'Year', 'Month', 'Day', 'Date',\n",
      "       'Timestamp start', 'WS', 'RH', 'TA', 'G', 'H', 'NETRAD'],\n",
      "      dtype='object')\n",
      "Site: US-Ced\n",
      "columns to drop []\n",
      "Before removing missing values:\n",
      "number of rows: 175296 \n",
      "number of columns: 28\n",
      "After removing missing values:\n",
      "number of rows: 57031 \n",
      "number of columns: 28\n",
      "df shape: (57031, 28)\n",
      "After grouping Index(['TIMESTAMP_END', 'USTAR', 'TA', 'WD', 'WS', 'NEE_PI', 'FC', 'SC', 'H',\n",
      "       'LE', 'G', 'TS_1', 'P', 'RH', 'PA', 'CO2_1', 'CO2_2', 'VPD_PI',\n",
      "       'NETRAD', 'PPFD_IN', 'SW_IN', 'Site Id', 'Category', 'Year', 'Month',\n",
      "       'Day', 'Date', 'Timestamp start'],\n",
      "      dtype='object')\n",
      "Before removing missing values:\n",
      "number of rows: 57031 \n",
      "number of columns: 13\n",
      "After removing missing values:\n",
      "number of rows: 57031 \n",
      "number of columns: 13\n",
      "ordered columns ['Timestamp start', 'TIMESTAMP_END', 'Site Id', 'Year', 'Month', 'Day', 'WS', 'WS-1', 'WS-2', 'WS-3', 'WS-4', 'WS-5', 'RH', 'RH-1', 'RH-2', 'RH-3', 'RH-4', 'RH-5', 'TA', 'TA-1', 'TA-2', 'TA-3', 'TA-4', 'TA-5', 'G', 'G-1', 'G-2', 'G-3', 'G-4', 'G-5', 'H', 'H-1', 'H-2', 'H-3', 'H-4', 'H-5', 'NETRAD', 'NETRAD-1', 'NETRAD-2', 'NETRAD-3', 'NETRAD-4', 'NETRAD-5', 'LE', 'LE(mm)', 'LE(mm)-1', 'LE(mm)-2', 'LE(mm)-3', 'LE(mm)-4', 'LE(mm)-5']\n",
      "TA negative values count: 0\n",
      "Site: US-Tw1\n",
      "columns to drop ['FC_SSITC_TEST', 'FCH4_SSITC_TEST', 'H_SSITC_TEST', 'LE_SSITC_TEST', 'TAU_SSITC_TEST_PI_F']\n",
      "Before removing missing values:\n",
      "number of rows: 149328 \n",
      "number of columns: 49\n",
      "After removing missing values:\n",
      "number of rows: 0 \n",
      "number of columns: 49\n",
      "df shape: (0, 49)\n",
      "After grouping Index(['TIMESTAMP_END', 'CO2', 'H2O', 'CH4', 'FC', 'FCH4', 'H', 'LE', 'WD',\n",
      "       'WS', 'USTAR', 'ZL', 'MO_LENGTH', 'V_SIGMA', 'W_SIGMA', 'PA', 'RH',\n",
      "       'TA', 'VPD_PI', 'T_SONIC', 'T_SONIC_SIGMA', 'TS_PI_1', 'TS_PI_2',\n",
      "       'TS_PI_3', 'TS_PI_4', 'TS_PI_5', 'TS_PI_6', 'NETRAD', 'PPFD_IN',\n",
      "       'PPFD_OUT', 'SW_IN', 'SW_OUT', 'LW_IN', 'LW_OUT', 'FC_PI_F',\n",
      "       'RECO_PI_F', 'GPP_PI_F', 'FCH4_PI_F', 'LE_PI_F', 'TAU', 'WTD',\n",
      "       'Site Id', 'Category', 'Year', 'Month', 'Day', 'Date',\n",
      "       'Timestamp start'],\n",
      "      dtype='object')\n",
      "Site: US-Kon\n",
      "columns to drop []\n",
      "Before removing missing values:\n",
      "number of rows: 122736 \n",
      "number of columns: 33\n",
      "After removing missing values:\n",
      "number of rows: 44817 \n",
      "number of columns: 33\n",
      "df shape: (44817, 33)\n",
      "After grouping Index(['TIMESTAMP_END', 'USTAR', 'TA', 'WD', 'WS', 'NEE_PI', 'FC', 'SC', 'H',\n",
      "       'LE', 'G', 'TS_1', 'TS_2', 'P', 'RH', 'PA', 'CO2_1', 'CO2_2', 'VPD_PI',\n",
      "       'SWC_1', 'NETRAD', 'PPFD_IN', 'SW_IN', 'SW_OUT', 'H2O', 'RECO_PI',\n",
      "       'Site Id', 'Category', 'Year', 'Month', 'Day', 'Date',\n",
      "       'Timestamp start'],\n",
      "      dtype='object')\n",
      "Before removing missing values:\n",
      "number of rows: 44817 \n",
      "number of columns: 13\n",
      "After removing missing values:\n",
      "number of rows: 44817 \n",
      "number of columns: 13\n",
      "ordered columns ['Timestamp start', 'TIMESTAMP_END', 'Site Id', 'Year', 'Month', 'Day', 'WS', 'WS-1', 'WS-2', 'WS-3', 'WS-4', 'WS-5', 'RH', 'RH-1', 'RH-2', 'RH-3', 'RH-4', 'RH-5', 'TA', 'TA-1', 'TA-2', 'TA-3', 'TA-4', 'TA-5', 'G', 'G-1', 'G-2', 'G-3', 'G-4', 'G-5', 'H', 'H-1', 'H-2', 'H-3', 'H-4', 'H-5', 'NETRAD', 'NETRAD-1', 'NETRAD-2', 'NETRAD-3', 'NETRAD-4', 'NETRAD-5', 'LE', 'LE(mm)', 'LE(mm)-1', 'LE(mm)-2', 'LE(mm)-3', 'LE(mm)-4', 'LE(mm)-5']\n",
      "TA negative values count: 0\n",
      "Site: US-MMS\n",
      "columns to drop []\n",
      "Before removing missing values:\n",
      "number of rows: 177528 \n",
      "number of columns: 82\n",
      "After removing missing values:\n",
      "number of rows: 0 \n",
      "number of columns: 82\n",
      "df shape: (0, 82)\n",
      "After grouping Index(['TIMESTAMP_END', 'USTAR_1_1_1', 'WD_1_1_1', 'FC_1_1_1', 'LE_1_1_1',\n",
      "       'TS_2_1_1', 'P_1_1_1', 'PA_1_1_1', 'CO2_1_1_1', 'VPD_PI_1_1_1',\n",
      "       'SWC_PI_1', 'PPFD_IN_1_1_1', 'SW_IN_1_1_1', 'SW_OUT_1_1_1',\n",
      "       'LW_IN_1_1_1', 'LW_OUT_1_1_1', 'H2O_1_1_1', 'RECO_PI_1_1_1',\n",
      "       'PPFD_DIF_1_1_1', 'T_SONIC_1_2_1', 'CO2_1_2_1', 'H2O_1_2_1',\n",
      "       'SW_IN_1_2_1', 'SW_OUT_1_2_1', 'LW_IN_1_2_1', 'LW_OUT_1_2_1',\n",
      "       'U_SIGMA_1_2_1', 'V_SIGMA_1_2_1', 'W_SIGMA_1_2_1',\n",
      "       'T_SONIC_SIGMA_1_2_1', 'T_SONIC_1_1_1', 'T_SONIC_SIGMA_1_1_1',\n",
      "       'PPFD_IN_1_1_2', 'WD_1_1_2', 'U_SIGMA_1_1_1', 'V_SIGMA_1_1_1',\n",
      "       'W_SIGMA_1_1_1', 'T_SONIC_2_1_1', 'CO2_2_1_1', 'H2O_2_1_1',\n",
      "       'SW_BC_IN_1_1_1', 'SW_BC_OUT_1_1_1', 'LW_BC_IN_1_1_1',\n",
      "       'LW_BC_OUT_1_1_1', 'PPFD_BC_IN_1_1_1', 'P_2_1_1', 'U_SIGMA_2_1_1',\n",
      "       'V_SIGMA_2_1_1', 'W_SIGMA_2_1_1', 'T_SONIC_SIGMA_2_1_1', 'WD_1_2_1',\n",
      "       'WD_2_1_1', 'SWC_1_1_1', 'SWC_2_1_1', 'SWC_3_1_1', 'SWC_4_1_1',\n",
      "       'SWC_5_1_1', 'SWC_6_1_1', 'Site Id', 'Category', 'Year', 'Month', 'Day',\n",
      "       'Date', 'Timestamp start', 'WS', 'RH', 'TA', 'G', 'H', 'NETRAD'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Site: US-Snd\n",
      "columns to drop []\n",
      "Before removing missing values:\n",
      "number of rows: 140256 \n",
      "number of columns: 35\n",
      "After removing missing values:\n",
      "number of rows: 44511 \n",
      "number of columns: 35\n",
      "df shape: (44511, 35)\n",
      "After grouping Index(['TIMESTAMP_END', 'USTAR', 'TA', 'WD', 'WS', 'NEE_PI', 'FC', 'SC', 'H',\n",
      "       'LE', 'G', 'TS_1', 'TS_2', 'P', 'RH', 'PA', 'CO2_1', 'CO2_2', 'VPD_PI',\n",
      "       'SWC_1', 'SWC_2', 'NETRAD', 'PPFD_IN', 'SW_IN', 'PPFD_OUT', 'H2O',\n",
      "       'PPFD_DIF', 'ZL', 'Site Id', 'Category', 'Year', 'Month', 'Day', 'Date',\n",
      "       'Timestamp start'],\n",
      "      dtype='object')\n",
      "Before removing missing values:\n",
      "number of rows: 44511 \n",
      "number of columns: 13\n",
      "After removing missing values:\n",
      "number of rows: 44511 \n",
      "number of columns: 13\n",
      "ordered columns ['Timestamp start', 'TIMESTAMP_END', 'Site Id', 'Year', 'Month', 'Day', 'WS', 'WS-1', 'WS-2', 'WS-3', 'WS-4', 'WS-5', 'RH', 'RH-1', 'RH-2', 'RH-3', 'RH-4', 'RH-5', 'TA', 'TA-1', 'TA-2', 'TA-3', 'TA-4', 'TA-5', 'G', 'G-1', 'G-2', 'G-3', 'G-4', 'G-5', 'H', 'H-1', 'H-2', 'H-3', 'H-4', 'H-5', 'NETRAD', 'NETRAD-1', 'NETRAD-2', 'NETRAD-3', 'NETRAD-4', 'NETRAD-5', 'LE', 'LE(mm)', 'LE(mm)-1', 'LE(mm)-2', 'LE(mm)-3', 'LE(mm)-4', 'LE(mm)-5']\n",
      "TA negative values count: 0\n",
      "Site: US-AR1\n",
      "columns to drop []\n",
      "Before removing missing values:\n",
      "number of rows: 70128 \n",
      "number of columns: 33\n",
      "After removing missing values:\n",
      "number of rows: 50164 \n",
      "number of columns: 33\n",
      "df shape: (50164, 33)\n",
      "After grouping Index(['TIMESTAMP_END', 'USTAR', 'WD', 'WS', 'FC', 'H', 'LE', 'G', 'TS_1_1_1',\n",
      "       'TS_1_2_1', 'P', 'PA_1_1_1', 'CO2', 'VPD_PI_1_1_1', 'SWC_1_1_1',\n",
      "       'SWC_1_2_1', 'NETRAD', 'PPFD_IN', 'SW_IN', 'PPFD_OUT', 'SW_OUT',\n",
      "       'LW_IN', 'LW_OUT', 'H2O', 'Site Id', 'Category', 'Year', 'Month', 'Day',\n",
      "       'Date', 'Timestamp start', 'RH', 'TA'],\n",
      "      dtype='object')\n",
      "Before removing missing values:\n",
      "number of rows: 50164 \n",
      "number of columns: 13\n",
      "After removing missing values:\n",
      "number of rows: 50164 \n",
      "number of columns: 13\n",
      "ordered columns ['Timestamp start', 'TIMESTAMP_END', 'Site Id', 'Year', 'Month', 'Day', 'WS', 'WS-1', 'WS-2', 'WS-3', 'WS-4', 'WS-5', 'RH', 'RH-1', 'RH-2', 'RH-3', 'RH-4', 'RH-5', 'TA', 'TA-1', 'TA-2', 'TA-3', 'TA-4', 'TA-5', 'G', 'G-1', 'G-2', 'G-3', 'G-4', 'G-5', 'H', 'H-1', 'H-2', 'H-3', 'H-4', 'H-5', 'NETRAD', 'NETRAD-1', 'NETRAD-2', 'NETRAD-3', 'NETRAD-4', 'NETRAD-5', 'LE', 'LE(mm)', 'LE(mm)-1', 'LE(mm)-2', 'LE(mm)-3', 'LE(mm)-4', 'LE(mm)-5']\n",
      "TA negative values count: 0\n",
      "Site: US-Myb\n",
      "columns to drop ['FC_SSITC_TEST', 'FCH4_SSITC_TEST', 'H_SSITC_TEST', 'LE_SSITC_TEST', 'TAU_SSITC_TEST']\n",
      "Before removing missing values:\n",
      "number of rows: 168768 \n",
      "number of columns: 45\n",
      "After removing missing values:\n",
      "number of rows: 18316 \n",
      "number of columns: 45\n",
      "df shape: (18316, 45)\n",
      "After grouping Index(['TIMESTAMP_END', 'CO2', 'H2O', 'CH4', 'FC', 'FCH4', 'H', 'LE', 'WD',\n",
      "       'WS', 'USTAR', 'ZL', 'TAU', 'MO_LENGTH', 'V_SIGMA', 'W_SIGMA', 'PA',\n",
      "       'RH', 'TA', 'VPD_PI', 'T_SONIC', 'T_SONIC_SIGMA', 'TS_PI_1', 'TS_PI_2',\n",
      "       'TS_PI_3', 'TS_PI_4', 'TS_PI_5', 'NETRAD', 'PPFD_IN', 'PPFD_OUT', 'P',\n",
      "       'WTD', 'FC_PI_F', 'RECO_PI_F', 'GPP_PI_F', 'FCH4_PI_F', 'LE_PI_F',\n",
      "       'Site Id', 'Category', 'Year', 'Month', 'Day', 'Date',\n",
      "       'Timestamp start'],\n",
      "      dtype='object')\n",
      "Site: US-A32\n",
      "columns to drop []\n",
      "Before removing missing values:\n",
      "number of rows: 52608 \n",
      "number of columns: 57\n",
      "After removing missing values:\n",
      "number of rows: 7589 \n",
      "number of columns: 57\n",
      "df shape: (7589, 57)\n",
      "After grouping Index(['TIMESTAMP_END', 'WS', 'U_SIGMA', 'V_SIGMA', 'W_SIGMA', 'WD', 'TA',\n",
      "       'T_CANOPY', 'RH', 'PA', 'T_SONIC', 'T_SONIC_SIGMA', 'P_RAIN', 'CO2',\n",
      "       'H2O', 'FC', 'NEE_PI', 'H', 'LE', 'USTAR', 'ZL', 'SW_IN', 'SW_OUT',\n",
      "       'LW_IN', 'LW_OUT', 'SW_DIF', 'SW_DIR', 'PPFD_IN', 'PPFD_OUT', 'NETRAD',\n",
      "       'NDVI', 'PRI', 'ALB', 'TS_1_1_1', 'TS_1_1_2', 'TS_PI_1_1_A', 'TS_1_2_1',\n",
      "       'TS_1_2_2', 'TS_PI_1_2_A', 'SWC_1_1_1', 'SWC_1_1_2', 'SWC_PI_1_1_A',\n",
      "       'SWC_1_2_1', 'SWC_1_2_2', 'SWC_PI_1_2_A', 'Site Id', 'Category', 'Year',\n",
      "       'Month', 'Day', 'Date', 'Timestamp start', 'G'],\n",
      "      dtype='object')\n",
      "Before removing missing values:\n",
      "number of rows: 7589 \n",
      "number of columns: 13\n",
      "After removing missing values:\n",
      "number of rows: 7589 \n",
      "number of columns: 13\n",
      "ordered columns ['Timestamp start', 'TIMESTAMP_END', 'Site Id', 'Year', 'Month', 'Day', 'WS', 'WS-1', 'WS-2', 'WS-3', 'WS-4', 'WS-5', 'RH', 'RH-1', 'RH-2', 'RH-3', 'RH-4', 'RH-5', 'TA', 'TA-1', 'TA-2', 'TA-3', 'TA-4', 'TA-5', 'G', 'G-1', 'G-2', 'G-3', 'G-4', 'G-5', 'H', 'H-1', 'H-2', 'H-3', 'H-4', 'H-5', 'NETRAD', 'NETRAD-1', 'NETRAD-2', 'NETRAD-3', 'NETRAD-4', 'NETRAD-5', 'LE', 'LE(mm)', 'LE(mm)-1', 'LE(mm)-2', 'LE(mm)-3', 'LE(mm)-4', 'LE(mm)-5']\n",
      "TA negative values count: 0\n",
      "Site: US-Me2\n",
      "columns to drop []\n",
      "Before removing missing values:\n",
      "number of rows: 290784 \n",
      "number of columns: 79\n",
      "After removing missing values:\n",
      "number of rows: 0 \n",
      "number of columns: 79\n",
      "df shape: (0, 79)\n",
      "After grouping Index(['TIMESTAMP_END', 'FC', 'LE', 'H', 'CO2', 'H2O', 'PA', 'T_SONIC',\n",
      "       'T_SONIC_SIGMA', 'RH', 'P', 'PPFD_IN', 'PPFD_DIF', 'PPFD_DIR', 'SW_IN',\n",
      "       'SW_OUT', 'LW_IN', 'LW_OUT', 'NETRAD', 'ALB', 'SWC_1_1_1', 'SWC_1_2_1',\n",
      "       'SWC_1_3_1', 'SWC_1_4_1', 'SWC_1_5_1', 'SWC_1_6_1', 'SWC_1_7_1',\n",
      "       'SWC_1_8_1', 'SWC_2_1_1', 'SWC_2_2_1', 'SWC_2_3_1', 'SWC_2_4_1',\n",
      "       'SWC_2_5_1', 'SWC_2_6_1', 'SWC_2_7_1', 'SWC_2_8_1', 'SWC_3_1_1',\n",
      "       'SWC_3_2_1', 'SWC_3_3_1', 'SWC_3_4_1', 'SWC_3_5_1', 'SWC_3_6_1',\n",
      "       'SWC_3_7_1', 'SWC_3_8_1', 'SWC_4_1_1', 'TS_1_1_1', 'TS_1_2_1',\n",
      "       'TS_1_3_1', 'TS_1_4_1', 'TS_1_5_1', 'TS_1_6_1', 'D_SNOW', 'USTAR',\n",
      "       'U_SIGMA', 'V_SIGMA', 'W_SIGMA', 'WS', 'WD', 'NEE_PI', 'RECO_PI',\n",
      "       'GPP_PI', 'Site Id', 'Category', 'Year', 'Month', 'Day', 'Date',\n",
      "       'Timestamp start', 'TA', 'G'],\n",
      "      dtype='object')\n",
      "Before removing missing values:\n",
      "number of rows: 0 \n",
      "number of columns: 13\n",
      "After removing missing values:\n",
      "number of rows: 0 \n",
      "number of columns: 13\n",
      "ordered columns ['Timestamp start', 'TIMESTAMP_END', 'Site Id', 'Year', 'Month', 'Day', 'WS', 'WS-1', 'WS-2', 'WS-3', 'WS-4', 'WS-5', 'RH', 'RH-1', 'RH-2', 'RH-3', 'RH-4', 'RH-5', 'TA', 'TA-1', 'TA-2', 'TA-3', 'TA-4', 'TA-5', 'G', 'G-1', 'G-2', 'G-3', 'G-4', 'G-5', 'H', 'H-1', 'H-2', 'H-3', 'H-4', 'H-5', 'NETRAD', 'NETRAD-1', 'NETRAD-2', 'NETRAD-3', 'NETRAD-4', 'NETRAD-5', 'LE', 'LE(mm)', 'LE(mm)-1', 'LE(mm)-2', 'LE(mm)-3', 'LE(mm)-4', 'LE(mm)-5']\n",
      "Site: US-Goo\n",
      "columns to drop []\n",
      "Before removing missing values:\n",
      "number of rows: 87648 \n",
      "number of columns: 27\n",
      "After removing missing values:\n",
      "number of rows: 29299 \n",
      "number of columns: 27\n",
      "df shape: (29299, 27)\n",
      "After grouping Index(['TIMESTAMP_END', 'USTAR', 'TA', 'WD', 'WS', 'FC', 'H', 'LE', 'G', 'P',\n",
      "       'RH', 'PA', 'VPD_PI', 'NETRAD', 'PPFD_IN', 'SW_IN', 'PPFD_OUT',\n",
      "       'SW_OUT', 'LW_IN', 'LW_OUT', 'Site Id', 'Category', 'Year', 'Month',\n",
      "       'Day', 'Date', 'Timestamp start'],\n",
      "      dtype='object')\n",
      "Before removing missing values:\n",
      "number of rows: 29299 \n",
      "number of columns: 13\n",
      "After removing missing values:\n",
      "number of rows: 29299 \n",
      "number of columns: 13\n",
      "ordered columns ['Timestamp start', 'TIMESTAMP_END', 'Site Id', 'Year', 'Month', 'Day', 'WS', 'WS-1', 'WS-2', 'WS-3', 'WS-4', 'WS-5', 'RH', 'RH-1', 'RH-2', 'RH-3', 'RH-4', 'RH-5', 'TA', 'TA-1', 'TA-2', 'TA-3', 'TA-4', 'TA-5', 'G', 'G-1', 'G-2', 'G-3', 'G-4', 'G-5', 'H', 'H-1', 'H-2', 'H-3', 'H-4', 'H-5', 'NETRAD', 'NETRAD-1', 'NETRAD-2', 'NETRAD-3', 'NETRAD-4', 'NETRAD-5', 'LE', 'LE(mm)', 'LE(mm)-1', 'LE(mm)-2', 'LE(mm)-3', 'LE(mm)-4', 'LE(mm)-5']\n",
      "TA negative values count: 0\n",
      "Site: US-Skr\n",
      "columns to drop []\n",
      "Before removing missing values:\n",
      "number of rows: 140256 \n",
      "number of columns: 34\n",
      "After removing missing values:\n",
      "number of rows: 12724 \n",
      "number of columns: 34\n",
      "df shape: (12724, 34)\n",
      "After grouping Index(['TIMESTAMP_END', 'USTAR', 'TA', 'WD', 'WS', 'NEE_PI', 'FC', 'SC', 'H',\n",
      "       'LE', 'G', 'TS_1', 'TS_2', 'P', 'RH', 'PA', 'CO2_1', 'CO2_2', 'VPD_PI',\n",
      "       'NETRAD', 'PPFD_IN', 'SW_IN', 'PPFD_OUT', 'SW_OUT', 'LW_IN', 'LW_OUT',\n",
      "       'H2O', 'Site Id', 'Category', 'Year', 'Month', 'Day', 'Date',\n",
      "       'Timestamp start'],\n",
      "      dtype='object')\n",
      "Before removing missing values:\n",
      "number of rows: 12724 \n",
      "number of columns: 13\n",
      "After removing missing values:\n",
      "number of rows: 12724 \n",
      "number of columns: 13\n",
      "ordered columns ['Timestamp start', 'TIMESTAMP_END', 'Site Id', 'Year', 'Month', 'Day', 'WS', 'WS-1', 'WS-2', 'WS-3', 'WS-4', 'WS-5', 'RH', 'RH-1', 'RH-2', 'RH-3', 'RH-4', 'RH-5', 'TA', 'TA-1', 'TA-2', 'TA-3', 'TA-4', 'TA-5', 'G', 'G-1', 'G-2', 'G-3', 'G-4', 'G-5', 'H', 'H-1', 'H-2', 'H-3', 'H-4', 'H-5', 'NETRAD', 'NETRAD-1', 'NETRAD-2', 'NETRAD-3', 'NETRAD-4', 'NETRAD-5', 'LE', 'LE(mm)', 'LE(mm)-1', 'LE(mm)-2', 'LE(mm)-3', 'LE(mm)-4', 'LE(mm)-5']\n",
      "TA negative values count: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Site: US-Var\n",
      "columns to drop []\n",
      "Before removing missing values:\n",
      "number of rows: 342528 \n",
      "number of columns: 67\n",
      "After removing missing values:\n",
      "number of rows: 50215 \n",
      "number of columns: 67\n",
      "df shape: (50215, 67)\n",
      "After grouping Index(['TIMESTAMP_END', 'FC', 'CO2', 'CO2_SIGMA', 'LE', 'H2O', 'H2O_SIGMA',\n",
      "       'H', 'T_SONIC', 'T_SONIC_SIGMA', 'WD', 'WS', 'USTAR', 'W_SIGMA',\n",
      "       'U_SIGMA', 'V_SIGMA', 'TA', 'VPD_PI', 'RH', 'PA', 'TS_PI_1_1_A',\n",
      "       'TS_PI_1_2_A', 'TS_PI_1_3_A', 'TS_PI_1_4_A', 'TS_PI_1_5_A',\n",
      "       'SWC_PI_1_1_A', 'SWC_PI_1_2_A', 'SWC_PI_1_3_A', 'P', 'ZL', 'NETRAD',\n",
      "       'SW_IN_1_1_1', 'PPFD_IN', 'PPFD_OUT', 'SW_IN_1_1_2', 'SW_OUT', 'LW_IN',\n",
      "       'LW_OUT', 'PPFD_DIR', 'PPFD_DIF', 'NEE_PI_F', 'GPP_PI_F', 'RECO_PI_F',\n",
      "       'FC_PI_F', 'LE_PI_F', 'VPD_PI_F', 'PA_PI_F', 'TS_PI_F_1_1_A',\n",
      "       'TS_PI_F_1_2_A', 'TS_PI_F_1_3_A', 'TS_PI_F_1_4_A', 'TS_PI_F_1_5_A',\n",
      "       'SWC_PI_F_1_1_A', 'SWC_PI_F_1_2_A', 'SWC_PI_F_1_3_A', 'P_PI_F',\n",
      "       'Site Id', 'Category', 'Year', 'Month', 'Day', 'Date',\n",
      "       'Timestamp start', 'G'],\n",
      "      dtype='object')\n",
      "Before removing missing values:\n",
      "number of rows: 50215 \n",
      "number of columns: 13\n",
      "After removing missing values:\n",
      "number of rows: 50215 \n",
      "number of columns: 13\n",
      "ordered columns ['Timestamp start', 'TIMESTAMP_END', 'Site Id', 'Year', 'Month', 'Day', 'WS', 'WS-1', 'WS-2', 'WS-3', 'WS-4', 'WS-5', 'RH', 'RH-1', 'RH-2', 'RH-3', 'RH-4', 'RH-5', 'TA', 'TA-1', 'TA-2', 'TA-3', 'TA-4', 'TA-5', 'G', 'G-1', 'G-2', 'G-3', 'G-4', 'G-5', 'H', 'H-1', 'H-2', 'H-3', 'H-4', 'H-5', 'NETRAD', 'NETRAD-1', 'NETRAD-2', 'NETRAD-3', 'NETRAD-4', 'NETRAD-5', 'LE', 'LE(mm)', 'LE(mm)-1', 'LE(mm)-2', 'LE(mm)-3', 'LE(mm)-4', 'LE(mm)-5']\n",
      "TA negative values count: 0\n",
      "Site: US-A74\n",
      "columns to drop []\n",
      "Before removing missing values:\n",
      "number of rows: 52608 \n",
      "number of columns: 57\n",
      "After removing missing values:\n",
      "number of rows: 3019 \n",
      "number of columns: 57\n",
      "df shape: (3019, 57)\n",
      "After grouping Index(['TIMESTAMP_END', 'WS', 'U_SIGMA', 'V_SIGMA', 'W_SIGMA', 'WD', 'TA',\n",
      "       'T_CANOPY', 'RH', 'PA', 'T_SONIC', 'T_SONIC_SIGMA', 'P_RAIN', 'CO2',\n",
      "       'H2O', 'FC', 'NEE_PI', 'H', 'LE', 'USTAR', 'ZL', 'SW_IN', 'SW_OUT',\n",
      "       'LW_IN', 'LW_OUT', 'SW_DIF', 'SW_DIR', 'PPFD_IN', 'PPFD_OUT', 'NETRAD',\n",
      "       'NDVI', 'PRI', 'ALB', 'TS_1_1_1', 'TS_1_1_2', 'TS_PI_1_1_A', 'TS_1_2_1',\n",
      "       'TS_1_2_2', 'TS_PI_1_2_A', 'SWC_1_1_1', 'SWC_1_1_2', 'SWC_PI_1_1_A',\n",
      "       'SWC_1_2_1', 'SWC_1_2_2', 'SWC_PI_1_2_A', 'Site Id', 'Category', 'Year',\n",
      "       'Month', 'Day', 'Date', 'Timestamp start', 'G'],\n",
      "      dtype='object')\n",
      "Before removing missing values:\n",
      "number of rows: 3019 \n",
      "number of columns: 13\n",
      "After removing missing values:\n",
      "number of rows: 3019 \n",
      "number of columns: 13\n",
      "ordered columns ['Timestamp start', 'TIMESTAMP_END', 'Site Id', 'Year', 'Month', 'Day', 'WS', 'WS-1', 'WS-2', 'WS-3', 'WS-4', 'WS-5', 'RH', 'RH-1', 'RH-2', 'RH-3', 'RH-4', 'RH-5', 'TA', 'TA-1', 'TA-2', 'TA-3', 'TA-4', 'TA-5', 'G', 'G-1', 'G-2', 'G-3', 'G-4', 'G-5', 'H', 'H-1', 'H-2', 'H-3', 'H-4', 'H-5', 'NETRAD', 'NETRAD-1', 'NETRAD-2', 'NETRAD-3', 'NETRAD-4', 'NETRAD-5', 'LE', 'LE(mm)', 'LE(mm)-1', 'LE(mm)-2', 'LE(mm)-3', 'LE(mm)-4', 'LE(mm)-5']\n",
      "TA negative values count: 0\n",
      "Site: US-SO2\n",
      "columns to drop []\n",
      "Before removing missing values:\n",
      "number of rows: 175296 \n",
      "number of columns: 30\n",
      "After removing missing values:\n",
      "number of rows: 7918 \n",
      "number of columns: 30\n",
      "df shape: (7918, 30)\n",
      "After grouping Index(['TIMESTAMP_END', 'USTAR', 'TA', 'WD', 'WS', 'FC', 'H', 'LE', 'G',\n",
      "       'TS_1', 'TS_2', 'P', 'RH', 'PA', 'CO2_1', 'CO2_2', 'VPD_PI', 'SWC_1',\n",
      "       'SWC_2', 'NETRAD', 'PPFD_IN', 'SW_IN', 'H2O', 'Site Id', 'Category',\n",
      "       'Year', 'Month', 'Day', 'Date', 'Timestamp start'],\n",
      "      dtype='object')\n",
      "Before removing missing values:\n",
      "number of rows: 7918 \n",
      "number of columns: 13\n",
      "After removing missing values:\n",
      "number of rows: 7918 \n",
      "number of columns: 13\n",
      "ordered columns ['Timestamp start', 'TIMESTAMP_END', 'Site Id', 'Year', 'Month', 'Day', 'WS', 'WS-1', 'WS-2', 'WS-3', 'WS-4', 'WS-5', 'RH', 'RH-1', 'RH-2', 'RH-3', 'RH-4', 'RH-5', 'TA', 'TA-1', 'TA-2', 'TA-3', 'TA-4', 'TA-5', 'G', 'G-1', 'G-2', 'G-3', 'G-4', 'G-5', 'H', 'H-1', 'H-2', 'H-3', 'H-4', 'H-5', 'NETRAD', 'NETRAD-1', 'NETRAD-2', 'NETRAD-3', 'NETRAD-4', 'NETRAD-5', 'LE', 'LE(mm)', 'LE(mm)-1', 'LE(mm)-2', 'LE(mm)-3', 'LE(mm)-4', 'LE(mm)-5']\n",
      "TA negative values count: 0\n",
      "Site: US-Wgr\n",
      "columns to drop []\n",
      "Before removing missing values:\n",
      "number of rows: 17520 \n",
      "number of columns: 33\n",
      "After removing missing values:\n",
      "number of rows: 2786 \n",
      "number of columns: 33\n",
      "df shape: (2786, 33)\n",
      "After grouping Index(['TIMESTAMP_END', 'FC', 'LE', 'H', 'CO2', 'H2O', 'USTAR', 'U_SIGMA',\n",
      "       'V_SIGMA', 'W_SIGMA', 'TA', 'WS', 'WD', 'PPFD_IN', 'PPFD_DIR',\n",
      "       'PPFD_DIF', 'SW_IN', 'SW_OUT', 'LW_IN', 'LW_OUT', 'NETRAD', 'ALB', 'PA',\n",
      "       'NEE_PI_F', 'GPP_PI_F', 'RECO_PI_F', 'Site Id', 'Category', 'Year',\n",
      "       'Month', 'Day', 'Date', 'Timestamp start'],\n",
      "      dtype='object')\n",
      "Site: US-WBW\n",
      "columns to drop []\n",
      "Before removing missing values:\n",
      "number of rows: 227904 \n",
      "number of columns: 36\n",
      "After removing missing values:\n",
      "number of rows: 0 \n",
      "number of columns: 36\n",
      "df shape: (0, 36)\n",
      "After grouping Index(['TIMESTAMP_END', 'USTAR', 'TA', 'WD', 'WS', 'NEE_PI', 'FC', 'SC', 'H',\n",
      "       'LE', 'G', 'TS_1', 'TS_2', 'P', 'RH', 'PA', 'CO2_1', 'CO2_2', 'VPD_PI',\n",
      "       'SWC_1', 'SWC_2', 'NETRAD', 'PPFD_IN', 'SW_IN', 'PPFD_OUT', 'SW_OUT',\n",
      "       'LW_IN', 'LW_OUT', 'PPFD_DIF', 'Site Id', 'Category', 'Year', 'Month',\n",
      "       'Day', 'Date', 'Timestamp start'],\n",
      "      dtype='object')\n",
      "Before removing missing values:\n",
      "number of rows: 0 \n",
      "number of columns: 13\n",
      "After removing missing values:\n",
      "number of rows: 0 \n",
      "number of columns: 13\n",
      "ordered columns ['Timestamp start', 'TIMESTAMP_END', 'Site Id', 'Year', 'Month', 'Day', 'WS', 'WS-1', 'WS-2', 'WS-3', 'WS-4', 'WS-5', 'RH', 'RH-1', 'RH-2', 'RH-3', 'RH-4', 'RH-5', 'TA', 'TA-1', 'TA-2', 'TA-3', 'TA-4', 'TA-5', 'G', 'G-1', 'G-2', 'G-3', 'G-4', 'G-5', 'H', 'H-1', 'H-2', 'H-3', 'H-4', 'H-5', 'NETRAD', 'NETRAD-1', 'NETRAD-2', 'NETRAD-3', 'NETRAD-4', 'NETRAD-5', 'LE', 'LE(mm)', 'LE(mm)-1', 'LE(mm)-2', 'LE(mm)-3', 'LE(mm)-4', 'LE(mm)-5']\n",
      "Site: US-KFS\n",
      "columns to drop []\n",
      "Before removing missing values:\n",
      "number of rows: 192863 \n",
      "number of columns: 70\n",
      "After removing missing values:\n",
      "number of rows: 0 \n",
      "number of columns: 70\n",
      "df shape: (0, 70)\n",
      "After grouping Index(['TIMESTAMP_END', 'WD_1_1_1', 'USTAR_1_1_1', 'NEE_PI_1_1_1',\n",
      "       'NEE_PI_F_1_1_1', 'SC_1_1_1', 'SH_1_1_1', 'LE_1_1_1', 'SLE_1_1_1',\n",
      "       'TS_2_1_1', 'TS_2_2_1', 'P_1_1_1', 'PA_1_1_1', 'CO2_1_1_1',\n",
      "       'VPD_PI_1_1_1', 'SWC_2_1_1', 'PPFD_IN_1_1_1', 'SW_IN_1_1_1',\n",
      "       'SW_OUT_1_1_1', 'LW_IN_1_1_1', 'LW_OUT_1_1_1', 'H2O_1_1_1',\n",
      "       'RECO_PI_F_1_1_1', 'ZL_1_1_1', 'FC_1_1_1', 'FC_PI_F_1_1_1',\n",
      "       'LE_PI_F_1_1_1', 'SW_IN_PI_F_1_1_1', 'GPP_PI_F_1_1_1', 'SWC_1_1_1',\n",
      "       'PPFD_OUT_1_1_1', 'PBLH_3_1_1', 'GPP_PI_1_1_1', 'WD_PI_F_1_1_1',\n",
      "       'SC_PI_F_1_1_1', 'SH_PI_F_1_1_1', 'SLE_PI_F_1_1_1', 'PA_PI_F_1_1_1',\n",
      "       'CO2_PI_F_1_1_1', 'VPD_PI_F_1_1_1', 'TS_PI_F_2_1_1', 'TS_PI_F_2_2_1',\n",
      "       'PPFD_OUT_PI_F_1_1_1', 'SW_OUT_PI_F_1_1_1', 'LW_IN_PI_F_1_1_1',\n",
      "       'LW_OUT_PI_F_1_1_1', 'H2O_PI_F_1_1_1', 'PBLH_1_1_1', 'RECO_PI_1_1_1',\n",
      "       'Site Id', 'Category', 'Year', 'Month', 'Day', 'Date',\n",
      "       'Timestamp start', 'WS', 'RH', 'TA', 'G', 'H', 'NETRAD'],\n",
      "      dtype='object')\n",
      "Site: US-Ton\n",
      "columns to drop []\n",
      "Before removing missing values:\n",
      "number of rows: 324960 \n",
      "number of columns: 92\n",
      "After removing missing values:\n",
      "number of rows: 33715 \n",
      "number of columns: 92\n",
      "df shape: (33715, 92)\n",
      "After grouping Index(['TIMESTAMP_END', 'FC_1_1_1', 'CO2_1_1_1', 'CO2_SIGMA_1_1_1', 'SC_1_1_1',\n",
      "       'LE_1_1_1', 'H2O_1_1_1', 'H2O_SIGMA_1_1_1', 'T_SONIC_1_1_1',\n",
      "       'T_SONIC_SIGMA_1_1_1', 'WD_1_1_1', 'USTAR_1_1_1', 'W_SIGMA_1_1_1',\n",
      "       'U_SIGMA_1_1_1', 'V_SIGMA_1_1_1', 'VPD_PI_1_1_1', 'PA', 'TS_PI_1_1_A',\n",
      "       'TS_PI_1_2_A', 'TS_PI_1_3_A', 'TS_PI_1_4_A', 'TS_PI_1_5_A',\n",
      "       'SWC_PI_1_1_A', 'SWC_PI_1_2_A', 'SWC_PI_1_3_A', 'P', 'ZL_1_1_1',\n",
      "       'SW_IN_1_1_1', 'PPFD_IN_1_1_1', 'PPFD_OUT_1_1_1', 'SW_IN_1_1_2',\n",
      "       'SW_OUT_1_1_1', 'LW_IN_1_1_1', 'LW_OUT_1_1_1', 'PPFD_DIR_1_1_1',\n",
      "       'PPFD_DIF_1_1_1', 'NEE_PI_F_1_1_1', 'GPP_PI_F_1_1_1', 'RECO_PI_F_1_1_1',\n",
      "       'FC_PI_F_1_1_1', 'LE_PI_F_1_1_1', 'VPD_PI_F_1_1_1', 'PA_PI_F',\n",
      "       'TS_PI_F_1_1_A', 'TS_PI_F_1_2_A', 'TS_PI_F_1_3_A', 'TS_PI_F_1_4_A',\n",
      "       'TS_PI_F_1_5_A', 'SWC_PI_F_1_1_A', 'SWC_PI_F_1_2_A', 'SWC_PI_F_1_3_A',\n",
      "       'P_PI_F', 'FC_1_2_1', 'CO2_1_2_1', 'CO2_SIGMA_1_2_1', 'LE_1_2_1',\n",
      "       'H2O_1_2_1', 'H2O_SIGMA_1_2_1', 'T_SONIC_1_2_1', 'T_SONIC_SIGMA_1_2_1',\n",
      "       'WD_1_2_1', 'USTAR_1_2_1', 'W_SIGMA_1_2_1', 'U_SIGMA_1_2_1',\n",
      "       'V_SIGMA_1_2_1', 'VPD_PI_1_2_1', 'NEE_PI_F_1_2_1', 'GPP_PI_F_1_2_1',\n",
      "       'RECO_PI_F_1_2_1', 'FC_PI_F_1_2_1', 'LE_PI_F_1_2_1', 'Site Id',\n",
      "       'Category', 'Year', 'Month', 'Day', 'Date', 'Timestamp start', 'WS',\n",
      "       'RH', 'TA', 'G', 'H', 'NETRAD'],\n",
      "      dtype='object')\n",
      "Site: US-Me6\n",
      "columns to drop []\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before removing missing values:\n",
      "number of rows: 154847 \n",
      "number of columns: 72\n",
      "After removing missing values:\n",
      "number of rows: 0 \n",
      "number of columns: 72\n",
      "df shape: (0, 72)\n",
      "After grouping Index(['TIMESTAMP_END', 'FC', 'LE', 'H', 'CO2', 'H2O', 'PA', 'T_SONIC',\n",
      "       'T_SONIC_SIGMA', 'RH', 'P', 'PPFD_IN', 'SW_IN', 'SW_OUT', 'LW_IN',\n",
      "       'LW_OUT', 'NETRAD', 'ALB', 'SWC_1_1_1', 'SWC_1_2_1', 'SWC_1_3_1',\n",
      "       'SWC_1_4_1', 'SWC_1_5_1', 'SWC_2_1_2', 'SWC_2_2_2', 'SWC_2_3_2',\n",
      "       'SWC_3_4_2', 'SWC_2_5_2', 'SWC_3_1_3', 'SWC_3_2_3', 'SWC_3_3_3',\n",
      "       'SWC_3_4_3', 'SWC_3_5_3', 'SWC_4_1_1', 'SWC_5_1_1', 'SWC_6_1_1',\n",
      "       'TS_1_1_1', 'TS_1_2_1', 'TS_1_3_1', 'TS_1_4_1', 'TS_1_5_1', 'TS_1_6_1',\n",
      "       'D_SNOW', 'USTAR', 'U_SIGMA', 'V_SIGMA', 'W_SIGMA', 'WS', 'WD',\n",
      "       'SWC_1_1_2', 'SWC_1_2_2', 'SWC_1_3_2', 'SWC_1_4_2', 'SWC_1_5_2',\n",
      "       'SWC_1_1_3', 'SWC_1_2_3', 'SWC_1_3_3', 'SWC_1_4_3', 'SWC_1_5_3',\n",
      "       'Site Id', 'Category', 'Year', 'Month', 'Day', 'Date',\n",
      "       'Timestamp start', 'TA', 'G'],\n",
      "      dtype='object')\n",
      "Before removing missing values:\n",
      "number of rows: 0 \n",
      "number of columns: 13\n",
      "After removing missing values:\n",
      "number of rows: 0 \n",
      "number of columns: 13\n",
      "ordered columns ['Timestamp start', 'TIMESTAMP_END', 'Site Id', 'Year', 'Month', 'Day', 'WS', 'WS-1', 'WS-2', 'WS-3', 'WS-4', 'WS-5', 'RH', 'RH-1', 'RH-2', 'RH-3', 'RH-4', 'RH-5', 'TA', 'TA-1', 'TA-2', 'TA-3', 'TA-4', 'TA-5', 'G', 'G-1', 'G-2', 'G-3', 'G-4', 'G-5', 'H', 'H-1', 'H-2', 'H-3', 'H-4', 'H-5', 'NETRAD', 'NETRAD-1', 'NETRAD-2', 'NETRAD-3', 'NETRAD-4', 'NETRAD-5', 'LE', 'LE(mm)', 'LE(mm)-1', 'LE(mm)-2', 'LE(mm)-3', 'LE(mm)-4', 'LE(mm)-5']\n",
      "Site: US-Bi2\n",
      "columns to drop ['FC_SSITC_TEST', 'FCH4_SSITC_TEST', 'H_SSITC_TEST', 'LE_SSITC_TEST', 'TAU_SSITC_TEST_PI_F']\n",
      "Before removing missing values:\n",
      "number of rows: 35040 \n",
      "number of columns: 52\n",
      "After removing missing values:\n",
      "number of rows: 13392 \n",
      "number of columns: 52\n",
      "df shape: (13392, 52)\n",
      "After grouping Index(['TIMESTAMP_END', 'CO2', 'H2O', 'CH4', 'FC', 'FCH4', 'G', 'H', 'LE',\n",
      "       'WD', 'WS', 'USTAR', 'ZL', 'TAU', 'MO_LENGTH', 'V_SIGMA', 'W_SIGMA',\n",
      "       'PA', 'RH', 'TA', 'VPD_PI', 'T_SONIC', 'T_SONIC_SIGMA', 'TS_PI_1',\n",
      "       'TS_PI_2', 'TS_PI_3', 'TS_PI_4', 'TS_PI_5', 'SWC_PI_1', 'SWC_PI_2',\n",
      "       'NETRAD', 'PPFD_IN', 'PPFD_OUT', 'SW_IN', 'SW_OUT', 'LW_IN', 'LW_OUT',\n",
      "       'P', 'SW_DIF', 'FC_PI_F', 'RECO_PI_F', 'GPP_PI_F', 'FCH4_PI_F',\n",
      "       'LE_PI_F', 'Site Id', 'Category', 'Year', 'Month', 'Day', 'Date',\n",
      "       'Timestamp start'],\n",
      "      dtype='object')\n",
      "Before removing missing values:\n",
      "number of rows: 13392 \n",
      "number of columns: 13\n",
      "After removing missing values:\n",
      "number of rows: 13392 \n",
      "number of columns: 13\n",
      "ordered columns ['Timestamp start', 'TIMESTAMP_END', 'Site Id', 'Year', 'Month', 'Day', 'WS', 'WS-1', 'WS-2', 'WS-3', 'WS-4', 'WS-5', 'RH', 'RH-1', 'RH-2', 'RH-3', 'RH-4', 'RH-5', 'TA', 'TA-1', 'TA-2', 'TA-3', 'TA-4', 'TA-5', 'G', 'G-1', 'G-2', 'G-3', 'G-4', 'G-5', 'H', 'H-1', 'H-2', 'H-3', 'H-4', 'H-5', 'NETRAD', 'NETRAD-1', 'NETRAD-2', 'NETRAD-3', 'NETRAD-4', 'NETRAD-5', 'LE', 'LE(mm)', 'LE(mm)-1', 'LE(mm)-2', 'LE(mm)-3', 'LE(mm)-4', 'LE(mm)-5']\n",
      "TA negative values count: 0\n",
      "Site: US-Tw2\n",
      "columns to drop []\n",
      "Before removing missing values:\n",
      "number of rows: 35088 \n",
      "number of columns: 34\n",
      "After removing missing values:\n",
      "number of rows: 9037 \n",
      "number of columns: 34\n",
      "df shape: (9037, 34)\n",
      "After grouping Index(['TIMESTAMP_END', 'USTAR', 'TA', 'WD', 'WS', 'NEE_PI', 'FC', 'H', 'LE',\n",
      "       'G', 'TS_1_1_1', 'TS_1_2_1', 'RH', 'PA', 'CO2', 'VPD_PI', 'SWC_1_1_1',\n",
      "       'SWC_1_2_1', 'NETRAD', 'PPFD_IN', 'SW_IN', 'PPFD_OUT', 'SW_OUT',\n",
      "       'LW_IN', 'LW_OUT', 'H2O', 'ZL', 'Site Id', 'Category', 'Year', 'Month',\n",
      "       'Day', 'Date', 'Timestamp start'],\n",
      "      dtype='object')\n",
      "Before removing missing values:\n",
      "number of rows: 9037 \n",
      "number of columns: 13\n",
      "After removing missing values:\n",
      "number of rows: 9037 \n",
      "number of columns: 13\n",
      "ordered columns ['Timestamp start', 'TIMESTAMP_END', 'Site Id', 'Year', 'Month', 'Day', 'WS', 'WS-1', 'WS-2', 'WS-3', 'WS-4', 'WS-5', 'RH', 'RH-1', 'RH-2', 'RH-3', 'RH-4', 'RH-5', 'TA', 'TA-1', 'TA-2', 'TA-3', 'TA-4', 'TA-5', 'G', 'G-1', 'G-2', 'G-3', 'G-4', 'G-5', 'H', 'H-1', 'H-2', 'H-3', 'H-4', 'H-5', 'NETRAD', 'NETRAD-1', 'NETRAD-2', 'NETRAD-3', 'NETRAD-4', 'NETRAD-5', 'LE', 'LE(mm)', 'LE(mm)-1', 'LE(mm)-2', 'LE(mm)-3', 'LE(mm)-4', 'LE(mm)-5']\n",
      "TA negative values count: 0\n",
      "Site: US-FR2\n",
      "columns to drop []\n",
      "Before removing missing values:\n",
      "number of rows: 70128 \n",
      "number of columns: 32\n",
      "After removing missing values:\n",
      "number of rows: 0 \n",
      "number of columns: 32\n",
      "df shape: (0, 32)\n",
      "After grouping Index(['TIMESTAMP_END', 'USTAR', 'TA', 'WD', 'WS', 'FC', 'H', 'LE', 'G',\n",
      "       'TS_1', 'P', 'RH', 'PA', 'CO2_1', 'CO2_2', 'VPD_PI', 'SWC_1', 'NETRAD',\n",
      "       'PPFD_IN', 'SW_IN', 'SW_OUT', 'LW_IN', 'LW_OUT', 'H2O', 'RECO_PI',\n",
      "       'Site Id', 'Category', 'Year', 'Month', 'Day', 'Date',\n",
      "       'Timestamp start'],\n",
      "      dtype='object')\n",
      "Before removing missing values:\n",
      "number of rows: 0 \n",
      "number of columns: 13\n",
      "After removing missing values:\n",
      "number of rows: 0 \n",
      "number of columns: 13\n",
      "ordered columns ['Timestamp start', 'TIMESTAMP_END', 'Site Id', 'Year', 'Month', 'Day', 'WS', 'WS-1', 'WS-2', 'WS-3', 'WS-4', 'WS-5', 'RH', 'RH-1', 'RH-2', 'RH-3', 'RH-4', 'RH-5', 'TA', 'TA-1', 'TA-2', 'TA-3', 'TA-4', 'TA-5', 'G', 'G-1', 'G-2', 'G-3', 'G-4', 'G-5', 'H', 'H-1', 'H-2', 'H-3', 'H-4', 'H-5', 'NETRAD', 'NETRAD-1', 'NETRAD-2', 'NETRAD-3', 'NETRAD-4', 'NETRAD-5', 'LE', 'LE(mm)', 'LE(mm)-1', 'LE(mm)-2', 'LE(mm)-3', 'LE(mm)-4', 'LE(mm)-5']\n",
      "Site: US-SP2\n",
      "columns to drop []\n",
      "Before removing missing values:\n",
      "number of rows: 175344 \n",
      "number of columns: 25\n",
      "After removing missing values:\n",
      "number of rows: 15382 \n",
      "number of columns: 25\n",
      "df shape: (15382, 25)\n",
      "After grouping Index(['TIMESTAMP_END', 'USTAR', 'TA', 'WD', 'WS', 'NEE_PI', 'FC', 'SC', 'H',\n",
      "       'LE', 'G', 'TS_1', 'P', 'RH', 'VPD_PI', 'NETRAD', 'PPFD_IN', 'SW_IN',\n",
      "       'Site Id', 'Category', 'Year', 'Month', 'Day', 'Date',\n",
      "       'Timestamp start'],\n",
      "      dtype='object')\n",
      "Before removing missing values:\n",
      "number of rows: 15382 \n",
      "number of columns: 13\n",
      "After removing missing values:\n",
      "number of rows: 15382 \n",
      "number of columns: 13\n",
      "ordered columns ['Timestamp start', 'TIMESTAMP_END', 'Site Id', 'Year', 'Month', 'Day', 'WS', 'WS-1', 'WS-2', 'WS-3', 'WS-4', 'WS-5', 'RH', 'RH-1', 'RH-2', 'RH-3', 'RH-4', 'RH-5', 'TA', 'TA-1', 'TA-2', 'TA-3', 'TA-4', 'TA-5', 'G', 'G-1', 'G-2', 'G-3', 'G-4', 'G-5', 'H', 'H-1', 'H-2', 'H-3', 'H-4', 'H-5', 'NETRAD', 'NETRAD-1', 'NETRAD-2', 'NETRAD-3', 'NETRAD-4', 'NETRAD-5', 'LE', 'LE(mm)', 'LE(mm)-1', 'LE(mm)-2', 'LE(mm)-3', 'LE(mm)-4', 'LE(mm)-5']\n",
      "TA negative values count: 0\n",
      "Site: US-Tw3\n",
      "columns to drop ['FC_SSITC_TEST', 'FCH4_SSITC_TEST', 'H_SSITC_TEST', 'LE_SSITC_TEST', 'TAU_SSITC_TEST']\n",
      "Before removing missing values:\n",
      "number of rows: 95088 \n",
      "number of columns: 51\n",
      "After removing missing values:\n",
      "number of rows: 0 \n",
      "number of columns: 51\n",
      "df shape: (0, 51)\n",
      "After grouping Index(['TIMESTAMP_END', 'CO2', 'H2O', 'CH4', 'FC', 'FCH4', 'G', 'H', 'LE',\n",
      "       'WD', 'WS', 'USTAR', 'ZL', 'TAU', 'MO_LENGTH', 'V_SIGMA', 'W_SIGMA',\n",
      "       'PA', 'RH', 'TA', 'VPD_PI', 'T_SONIC', 'T_SONIC_SIGMA', 'SWC_1_1_1',\n",
      "       'SWC_1_2_1', 'TS_1_1_1', 'TS_1_2_1', 'TS_1_3_1', 'TS_1_4_1', 'TS_1_5_1',\n",
      "       'NETRAD', 'PPFD_DIF', 'PPFD_IN', 'PPFD_OUT', 'SW_IN', 'SW_OUT', 'LW_IN',\n",
      "       'LW_OUT', 'P', 'FC_PI_F', 'RECO_PI_F', 'GPP_PI_F', 'LE_PI_F', 'Site Id',\n",
      "       'Category', 'Year', 'Month', 'Day', 'Date', 'Timestamp start'],\n",
      "      dtype='object')\n",
      "Before removing missing values:\n",
      "number of rows: 0 \n",
      "number of columns: 13\n",
      "After removing missing values:\n",
      "number of rows: 0 \n",
      "number of columns: 13\n",
      "ordered columns ['Timestamp start', 'TIMESTAMP_END', 'Site Id', 'Year', 'Month', 'Day', 'WS', 'WS-1', 'WS-2', 'WS-3', 'WS-4', 'WS-5', 'RH', 'RH-1', 'RH-2', 'RH-3', 'RH-4', 'RH-5', 'TA', 'TA-1', 'TA-2', 'TA-3', 'TA-4', 'TA-5', 'G', 'G-1', 'G-2', 'G-3', 'G-4', 'G-5', 'H', 'H-1', 'H-2', 'H-3', 'H-4', 'H-5', 'NETRAD', 'NETRAD-1', 'NETRAD-2', 'NETRAD-3', 'NETRAD-4', 'NETRAD-5', 'LE', 'LE(mm)', 'LE(mm)-1', 'LE(mm)-2', 'LE(mm)-3', 'LE(mm)-4', 'LE(mm)-5']\n",
      "Site: US-AR2\n",
      "columns to drop []\n",
      "Before removing missing values:\n",
      "number of rows: 70128 \n",
      "number of columns: 33\n",
      "After removing missing values:\n",
      "number of rows: 41783 \n",
      "number of columns: 33\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df shape: (41783, 33)\n",
      "After grouping Index(['TIMESTAMP_END', 'USTAR', 'WD', 'WS', 'FC', 'H', 'LE', 'G', 'TS_1_1_1',\n",
      "       'TS_1_2_1', 'P', 'PA_1_1_1', 'CO2', 'VPD_PI_1_1_1', 'SWC_1_1_1',\n",
      "       'SWC_1_2_1', 'NETRAD', 'PPFD_IN', 'SW_IN', 'PPFD_OUT', 'SW_OUT',\n",
      "       'LW_IN', 'LW_OUT', 'H2O', 'Site Id', 'Category', 'Year', 'Month', 'Day',\n",
      "       'Date', 'Timestamp start', 'RH', 'TA'],\n",
      "      dtype='object')\n",
      "Before removing missing values:\n",
      "number of rows: 41783 \n",
      "number of columns: 13\n",
      "After removing missing values:\n",
      "number of rows: 41783 \n",
      "number of columns: 13\n",
      "ordered columns ['Timestamp start', 'TIMESTAMP_END', 'Site Id', 'Year', 'Month', 'Day', 'WS', 'WS-1', 'WS-2', 'WS-3', 'WS-4', 'WS-5', 'RH', 'RH-1', 'RH-2', 'RH-3', 'RH-4', 'RH-5', 'TA', 'TA-1', 'TA-2', 'TA-3', 'TA-4', 'TA-5', 'G', 'G-1', 'G-2', 'G-3', 'G-4', 'G-5', 'H', 'H-1', 'H-2', 'H-3', 'H-4', 'H-5', 'NETRAD', 'NETRAD-1', 'NETRAD-2', 'NETRAD-3', 'NETRAD-4', 'NETRAD-5', 'LE', 'LE(mm)', 'LE(mm)-1', 'LE(mm)-2', 'LE(mm)-3', 'LE(mm)-4', 'LE(mm)-5']\n",
      "TA negative values count: 0\n",
      "Site: US-Pon\n",
      "columns to drop []\n",
      "Before removing missing values:\n",
      "number of rows: 70128 \n",
      "number of columns: 32\n",
      "After removing missing values:\n",
      "number of rows: 65 \n",
      "number of columns: 32\n",
      "df shape: (65, 32)\n",
      "After grouping Index(['TIMESTAMP_END', 'USTAR', 'TA', 'WD', 'WS', 'FC', 'SC', 'H', 'LE', 'G',\n",
      "       'TS_1', 'TS_2', 'P', 'RH', 'PA', 'CO2_1', 'CO2_2', 'VPD_PI', 'SWC_1',\n",
      "       'SWC_2', 'NETRAD', 'PPFD_IN', 'SW_IN', 'PPFD_OUT', 'SW_OUT', 'Site Id',\n",
      "       'Category', 'Year', 'Month', 'Day', 'Date', 'Timestamp start'],\n",
      "      dtype='object')\n",
      "Before removing missing values:\n",
      "number of rows: 65 \n",
      "number of columns: 13\n",
      "After removing missing values:\n",
      "number of rows: 65 \n",
      "number of columns: 13\n",
      "ordered columns ['Timestamp start', 'TIMESTAMP_END', 'Site Id', 'Year', 'Month', 'Day', 'WS', 'WS-1', 'WS-2', 'WS-3', 'WS-4', 'WS-5', 'RH', 'RH-1', 'RH-2', 'RH-3', 'RH-4', 'RH-5', 'TA', 'TA-1', 'TA-2', 'TA-3', 'TA-4', 'TA-5', 'G', 'G-1', 'G-2', 'G-3', 'G-4', 'G-5', 'H', 'H-1', 'H-2', 'H-3', 'H-4', 'H-5', 'NETRAD', 'NETRAD-1', 'NETRAD-2', 'NETRAD-3', 'NETRAD-4', 'NETRAD-5', 'LE', 'LE(mm)', 'LE(mm)-1', 'LE(mm)-2', 'LE(mm)-3', 'LE(mm)-4', 'LE(mm)-5']\n",
      "TA negative values count: 0\n",
      "Site: US-Shd\n",
      "columns to drop []\n",
      "Before removing missing values:\n",
      "number of rows: 70128 \n",
      "number of columns: 32\n",
      "After removing missing values:\n",
      "number of rows: 216 \n",
      "number of columns: 32\n",
      "df shape: (216, 32)\n",
      "After grouping Index(['TIMESTAMP_END', 'USTAR', 'TA', 'WD', 'WS', 'FC', 'SC', 'H', 'LE', 'G',\n",
      "       'TS_1', 'TS_2', 'P', 'RH', 'PA', 'CO2_1', 'CO2_2', 'VPD_PI', 'SWC_1',\n",
      "       'SWC_2', 'NETRAD', 'PPFD_IN', 'SW_IN', 'PPFD_OUT', 'SW_OUT', 'Site Id',\n",
      "       'Category', 'Year', 'Month', 'Day', 'Date', 'Timestamp start'],\n",
      "      dtype='object')\n",
      "Before removing missing values:\n",
      "number of rows: 216 \n",
      "number of columns: 13\n",
      "After removing missing values:\n",
      "number of rows: 216 \n",
      "number of columns: 13\n",
      "ordered columns ['Timestamp start', 'TIMESTAMP_END', 'Site Id', 'Year', 'Month', 'Day', 'WS', 'WS-1', 'WS-2', 'WS-3', 'WS-4', 'WS-5', 'RH', 'RH-1', 'RH-2', 'RH-3', 'RH-4', 'RH-5', 'TA', 'TA-1', 'TA-2', 'TA-3', 'TA-4', 'TA-5', 'G', 'G-1', 'G-2', 'G-3', 'G-4', 'G-5', 'H', 'H-1', 'H-2', 'H-3', 'H-4', 'H-5', 'NETRAD', 'NETRAD-1', 'NETRAD-2', 'NETRAD-3', 'NETRAD-4', 'NETRAD-5', 'LE', 'LE(mm)', 'LE(mm)-1', 'LE(mm)-2', 'LE(mm)-3', 'LE(mm)-4', 'LE(mm)-5']\n",
      "TA negative values count: 0\n",
      "Valid Sites are ['US-Twt', 'US-Wlr', 'US-Ced', 'US-Kon', 'US-Snd', 'US-AR1', 'US-A32', 'US-Goo', 'US-Skr', 'US-Var', 'US-A74', 'US-SO2', 'US-Bi2', 'US-Tw2', 'US-SP2', 'US-AR2', 'US-Pon', 'US-Shd']\n",
      "ordered columns ['Timestamp start', 'TIMESTAMP_END', 'Site Id', 'Year', 'Month', 'Day', 'WS', 'WS-1', 'WS-2', 'WS-3', 'WS-4', 'WS-5', 'RH', 'RH-1', 'RH-2', 'RH-3', 'RH-4', 'RH-5', 'TA', 'TA-1', 'TA-2', 'TA-3', 'TA-4', 'TA-5', 'G', 'G-1', 'G-2', 'G-3', 'G-4', 'G-5', 'H', 'H-1', 'H-2', 'H-3', 'H-4', 'H-5', 'NETRAD', 'NETRAD-1', 'NETRAD-2', 'NETRAD-3', 'NETRAD-4', 'NETRAD-5', 'NETRAD_SOIL', 'LE', 'LE(mm)', 'LE(mm)-1', 'LE(mm)-2', 'LE(mm)-3', 'LE(mm)-4', 'LE(mm)-5', 'LATENT_SENSIBLE', 'NETRAD_SOIL']\n",
      "      Timestamp start  TIMESTAMP_END Site Id  Year  Month  Day        WS  \\\n",
      "9744     200907230000   200907230030  US-Twt  2009      7   23  2.578392   \n",
      "9748     200907230200   200907230230  US-Twt  2009      7   23  3.329627   \n",
      "9750     200907230300   200907230330  US-Twt  2009      7   23  3.770757   \n",
      "9751     200907230330   200907230400  US-Twt  2009      7   23  2.996385   \n",
      "9752     200907230400   200907230430  US-Twt  2009      7   23  1.757107   \n",
      "\n",
      "          WS-1      WS-2      WS-3  ...  NETRAD_SOIL         LE    LE(mm)  \\\n",
      "9744       NaN       NaN       NaN  ...          0.0  27.281298  0.942685   \n",
      "9748  2.578392       NaN       NaN  ...          0.0  25.882064  0.894335   \n",
      "9750  3.329627  2.578392       NaN  ...          0.0  23.188757  0.801270   \n",
      "9751  3.770757  3.329627  2.578392  ...          0.0  22.534713  0.778670   \n",
      "9752  2.996385  3.770757  3.329627  ...          0.0  13.626492  0.470853   \n",
      "\n",
      "      LE(mm)-1  LE(mm)-2  LE(mm)-3  LE(mm)-4  LE(mm)-5  LATENT_SENSIBLE  \\\n",
      "9744       NaN       NaN       NaN       NaN       NaN              0.0   \n",
      "9748  0.942685       NaN       NaN       NaN       NaN              0.0   \n",
      "9750  0.894335  0.942685       NaN       NaN       NaN              0.0   \n",
      "9751  0.801270  0.894335  0.942685       NaN       NaN              0.0   \n",
      "9752  0.778670  0.801270  0.894335  0.942685       NaN              0.0   \n",
      "\n",
      "      NETRAD_SOIL  \n",
      "9744          0.0  \n",
      "9748          0.0  \n",
      "9750          0.0  \n",
      "9751          0.0  \n",
      "9752          0.0  \n",
      "\n",
      "[5 rows x 52 columns]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    is_hourly = True #Boolean to indicate if the data is hourly or daily\n",
    "    skipRowsNum = 0 #Defaults to zero, incase excel has meaningless rows to skip\n",
    "    split_num = 0 #The index to read the name of the site, defaults to 0\n",
    "    lags_count = 5 #The number of lags to generate the data for \n",
    "    output_name = os.path.join(base_path + \"Ameriflux/\", \"Jan-11-2020_Hourly/\")\n",
    "    am = Ameriflux(hourly_classified_path, skipRowsNum, split_num, lags_count, is_hourly, False, output_name)\n",
    "    sites_df = Helpers.read_sites_data()\n",
    "    all_sites_df = am.generate_site_data(sites_df)\n",
    "    all_sites_df = am.order_columns(all_sites_df)\n",
    "    file_name = os.path.join(output_name, \"All_Hourly\")\n",
    "    Helpers.export_data(all_sites_df, file_name) \n",
    "    print(all_sites_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Ameriflux Daily Data </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializer\n",
      "Site: US-Ced\n",
      "Before removing missing values:\n",
      "number of rows: 1834 \n",
      "number of columns: 14\n",
      "After removing missing values:\n",
      "number of rows: 1834 \n",
      "number of columns: 14\n",
      "ordered columns ['Date', 'Site Id', 'Year', 'Month', 'Day', 'WS', 'WS-1', 'WS-2', 'WS-3', 'WS-4', 'WS-5', 'RH', 'RH-1', 'RH-2', 'RH-3', 'RH-4', 'RH-5', 'TA', 'TA-1', 'TA-2', 'TA-3', 'TA-4', 'TA-5', 'G', 'G-1', 'G-2', 'G-3', 'G-4', 'G-5', 'H', 'H_CORRECTED', 'H_CORRECTED-1', 'H_CORRECTED-2', 'H_CORRECTED-3', 'H_CORRECTED-4', 'H_CORRECTED-5', 'NETRAD', 'NETRAD-1', 'NETRAD-2', 'NETRAD-3', 'NETRAD-4', 'NETRAD-5', 'LE', 'LE_CORRECTED', 'LE_CORRECTED(mm)', 'LE_CORRECTED(mm)-1', 'LE_CORRECTED(mm)-2', 'LE_CORRECTED(mm)-3', 'LE_CORRECTED(mm)-4', 'LE_CORRECTED(mm)-5', 'C_BOWENS']\n",
      "columns: Index(['Date', 'Site Id', 'Year', 'Month', 'Day', 'WS', 'WS-1', 'WS-2', 'WS-3',\n",
      "       'WS-4', 'WS-5', 'RH', 'RH-1', 'RH-2', 'RH-3', 'RH-4', 'RH-5', 'TA',\n",
      "       'TA-1', 'TA-2', 'TA-3', 'TA-4', 'TA-5', 'G', 'G-1', 'G-2', 'G-3', 'G-4',\n",
      "       'G-5', 'H', 'H_CORRECTED', 'H_CORRECTED-1', 'H_CORRECTED-2',\n",
      "       'H_CORRECTED-3', 'H_CORRECTED-4', 'H_CORRECTED-5', 'NETRAD', 'NETRAD-1',\n",
      "       'NETRAD-2', 'NETRAD-3', 'NETRAD-4', 'NETRAD-5', 'LE', 'LE_CORRECTED',\n",
      "       'LE_CORRECTED(mm)', 'LE_CORRECTED(mm)-1', 'LE_CORRECTED(mm)-2',\n",
      "       'LE_CORRECTED(mm)-3', 'LE_CORRECTED(mm)-4', 'LE_CORRECTED(mm)-5',\n",
      "       'C_BOWENS'],\n",
      "      dtype='object')\n",
      "TA negative values count: 0\n",
      "Site: US-Shd\n",
      "Before removing missing values:\n",
      "number of rows: 216 \n",
      "number of columns: 14\n",
      "After removing missing values:\n",
      "number of rows: 216 \n",
      "number of columns: 14\n",
      "ordered columns ['Date', 'Site Id', 'Year', 'Month', 'Day', 'WS', 'WS-1', 'WS-2', 'WS-3', 'WS-4', 'WS-5', 'RH', 'RH-1', 'RH-2', 'RH-3', 'RH-4', 'RH-5', 'TA', 'TA-1', 'TA-2', 'TA-3', 'TA-4', 'TA-5', 'G', 'G-1', 'G-2', 'G-3', 'G-4', 'G-5', 'H', 'H_CORRECTED', 'H_CORRECTED-1', 'H_CORRECTED-2', 'H_CORRECTED-3', 'H_CORRECTED-4', 'H_CORRECTED-5', 'NETRAD', 'NETRAD-1', 'NETRAD-2', 'NETRAD-3', 'NETRAD-4', 'NETRAD-5', 'LE', 'LE_CORRECTED', 'LE_CORRECTED(mm)', 'LE_CORRECTED(mm)-1', 'LE_CORRECTED(mm)-2', 'LE_CORRECTED(mm)-3', 'LE_CORRECTED(mm)-4', 'LE_CORRECTED(mm)-5', 'C_BOWENS']\n",
      "columns: Index(['Date', 'Site Id', 'Year', 'Month', 'Day', 'WS', 'WS-1', 'WS-2', 'WS-3',\n",
      "       'WS-4', 'WS-5', 'RH', 'RH-1', 'RH-2', 'RH-3', 'RH-4', 'RH-5', 'TA',\n",
      "       'TA-1', 'TA-2', 'TA-3', 'TA-4', 'TA-5', 'G', 'G-1', 'G-2', 'G-3', 'G-4',\n",
      "       'G-5', 'H', 'H_CORRECTED', 'H_CORRECTED-1', 'H_CORRECTED-2',\n",
      "       'H_CORRECTED-3', 'H_CORRECTED-4', 'H_CORRECTED-5', 'NETRAD', 'NETRAD-1',\n",
      "       'NETRAD-2', 'NETRAD-3', 'NETRAD-4', 'NETRAD-5', 'LE', 'LE_CORRECTED',\n",
      "       'LE_CORRECTED(mm)', 'LE_CORRECTED(mm)-1', 'LE_CORRECTED(mm)-2',\n",
      "       'LE_CORRECTED(mm)-3', 'LE_CORRECTED(mm)-4', 'LE_CORRECTED(mm)-5',\n",
      "       'C_BOWENS'],\n",
      "      dtype='object')\n",
      "TA negative values count: 0\n",
      "Site: US-Bi2\n",
      "Before removing missing values:\n",
      "number of rows: 391 \n",
      "number of columns: 14\n",
      "After removing missing values:\n",
      "number of rows: 391 \n",
      "number of columns: 14\n",
      "ordered columns ['Date', 'Site Id', 'Year', 'Month', 'Day', 'WS', 'WS-1', 'WS-2', 'WS-3', 'WS-4', 'WS-5', 'RH', 'RH-1', 'RH-2', 'RH-3', 'RH-4', 'RH-5', 'TA', 'TA-1', 'TA-2', 'TA-3', 'TA-4', 'TA-5', 'G', 'G-1', 'G-2', 'G-3', 'G-4', 'G-5', 'H', 'H_CORRECTED', 'H_CORRECTED-1', 'H_CORRECTED-2', 'H_CORRECTED-3', 'H_CORRECTED-4', 'H_CORRECTED-5', 'NETRAD', 'NETRAD-1', 'NETRAD-2', 'NETRAD-3', 'NETRAD-4', 'NETRAD-5', 'LE', 'LE_CORRECTED', 'LE_CORRECTED(mm)', 'LE_CORRECTED(mm)-1', 'LE_CORRECTED(mm)-2', 'LE_CORRECTED(mm)-3', 'LE_CORRECTED(mm)-4', 'LE_CORRECTED(mm)-5', 'C_BOWENS']\n",
      "columns: Index(['Date', 'Site Id', 'Year', 'Month', 'Day', 'WS', 'WS-1', 'WS-2', 'WS-3',\n",
      "       'WS-4', 'WS-5', 'RH', 'RH-1', 'RH-2', 'RH-3', 'RH-4', 'RH-5', 'TA',\n",
      "       'TA-1', 'TA-2', 'TA-3', 'TA-4', 'TA-5', 'G', 'G-1', 'G-2', 'G-3', 'G-4',\n",
      "       'G-5', 'H', 'H_CORRECTED', 'H_CORRECTED-1', 'H_CORRECTED-2',\n",
      "       'H_CORRECTED-3', 'H_CORRECTED-4', 'H_CORRECTED-5', 'NETRAD', 'NETRAD-1',\n",
      "       'NETRAD-2', 'NETRAD-3', 'NETRAD-4', 'NETRAD-5', 'LE', 'LE_CORRECTED',\n",
      "       'LE_CORRECTED(mm)', 'LE_CORRECTED(mm)-1', 'LE_CORRECTED(mm)-2',\n",
      "       'LE_CORRECTED(mm)-3', 'LE_CORRECTED(mm)-4', 'LE_CORRECTED(mm)-5',\n",
      "       'C_BOWENS'],\n",
      "      dtype='object')\n",
      "TA negative values count: 0\n",
      "Site: US-A32\n",
      "Before removing missing values:\n",
      "number of rows: 505 \n",
      "number of columns: 14\n",
      "After removing missing values:\n",
      "number of rows: 505 \n",
      "number of columns: 14\n",
      "ordered columns ['Date', 'Site Id', 'Year', 'Month', 'Day', 'WS', 'WS-1', 'WS-2', 'WS-3', 'WS-4', 'WS-5', 'RH', 'RH-1', 'RH-2', 'RH-3', 'RH-4', 'RH-5', 'TA', 'TA-1', 'TA-2', 'TA-3', 'TA-4', 'TA-5', 'G', 'G-1', 'G-2', 'G-3', 'G-4', 'G-5', 'H', 'H_CORRECTED', 'H_CORRECTED-1', 'H_CORRECTED-2', 'H_CORRECTED-3', 'H_CORRECTED-4', 'H_CORRECTED-5', 'NETRAD', 'NETRAD-1', 'NETRAD-2', 'NETRAD-3', 'NETRAD-4', 'NETRAD-5', 'LE', 'LE_CORRECTED', 'LE_CORRECTED(mm)', 'LE_CORRECTED(mm)-1', 'LE_CORRECTED(mm)-2', 'LE_CORRECTED(mm)-3', 'LE_CORRECTED(mm)-4', 'LE_CORRECTED(mm)-5', 'C_BOWENS']\n",
      "columns: Index(['Date', 'Site Id', 'Year', 'Month', 'Day', 'WS', 'WS-1', 'WS-2', 'WS-3',\n",
      "       'WS-4', 'WS-5', 'RH', 'RH-1', 'RH-2', 'RH-3', 'RH-4', 'RH-5', 'TA',\n",
      "       'TA-1', 'TA-2', 'TA-3', 'TA-4', 'TA-5', 'G', 'G-1', 'G-2', 'G-3', 'G-4',\n",
      "       'G-5', 'H', 'H_CORRECTED', 'H_CORRECTED-1', 'H_CORRECTED-2',\n",
      "       'H_CORRECTED-3', 'H_CORRECTED-4', 'H_CORRECTED-5', 'NETRAD', 'NETRAD-1',\n",
      "       'NETRAD-2', 'NETRAD-3', 'NETRAD-4', 'NETRAD-5', 'LE', 'LE_CORRECTED',\n",
      "       'LE_CORRECTED(mm)', 'LE_CORRECTED(mm)-1', 'LE_CORRECTED(mm)-2',\n",
      "       'LE_CORRECTED(mm)-3', 'LE_CORRECTED(mm)-4', 'LE_CORRECTED(mm)-5',\n",
      "       'C_BOWENS'],\n",
      "      dtype='object')\n",
      "TA negative values count: 0\n",
      "Site: US-Tw2\n",
      "Before removing missing values:\n",
      "number of rows: 283 \n",
      "number of columns: 14\n",
      "After removing missing values:\n",
      "number of rows: 283 \n",
      "number of columns: 14\n",
      "ordered columns ['Date', 'Site Id', 'Year', 'Month', 'Day', 'WS', 'WS-1', 'WS-2', 'WS-3', 'WS-4', 'WS-5', 'RH', 'RH-1', 'RH-2', 'RH-3', 'RH-4', 'RH-5', 'TA', 'TA-1', 'TA-2', 'TA-3', 'TA-4', 'TA-5', 'G', 'G-1', 'G-2', 'G-3', 'G-4', 'G-5', 'H', 'H_CORRECTED', 'H_CORRECTED-1', 'H_CORRECTED-2', 'H_CORRECTED-3', 'H_CORRECTED-4', 'H_CORRECTED-5', 'NETRAD', 'NETRAD-1', 'NETRAD-2', 'NETRAD-3', 'NETRAD-4', 'NETRAD-5', 'LE', 'LE_CORRECTED', 'LE_CORRECTED(mm)', 'LE_CORRECTED(mm)-1', 'LE_CORRECTED(mm)-2', 'LE_CORRECTED(mm)-3', 'LE_CORRECTED(mm)-4', 'LE_CORRECTED(mm)-5', 'C_BOWENS']\n",
      "columns: Index(['Date', 'Site Id', 'Year', 'Month', 'Day', 'WS', 'WS-1', 'WS-2', 'WS-3',\n",
      "       'WS-4', 'WS-5', 'RH', 'RH-1', 'RH-2', 'RH-3', 'RH-4', 'RH-5', 'TA',\n",
      "       'TA-1', 'TA-2', 'TA-3', 'TA-4', 'TA-5', 'G', 'G-1', 'G-2', 'G-3', 'G-4',\n",
      "       'G-5', 'H', 'H_CORRECTED', 'H_CORRECTED-1', 'H_CORRECTED-2',\n",
      "       'H_CORRECTED-3', 'H_CORRECTED-4', 'H_CORRECTED-5', 'NETRAD', 'NETRAD-1',\n",
      "       'NETRAD-2', 'NETRAD-3', 'NETRAD-4', 'NETRAD-5', 'LE', 'LE_CORRECTED',\n",
      "       'LE_CORRECTED(mm)', 'LE_CORRECTED(mm)-1', 'LE_CORRECTED(mm)-2',\n",
      "       'LE_CORRECTED(mm)-3', 'LE_CORRECTED(mm)-4', 'LE_CORRECTED(mm)-5',\n",
      "       'C_BOWENS'],\n",
      "      dtype='object')\n",
      "TA negative values count: 0\n",
      "Site: US-Pon\n",
      "Before removing missing values:\n",
      "number of rows: 65 \n",
      "number of columns: 14\n",
      "After removing missing values:\n",
      "number of rows: 65 \n",
      "number of columns: 14\n",
      "ordered columns ['Date', 'Site Id', 'Year', 'Month', 'Day', 'WS', 'WS-1', 'WS-2', 'WS-3', 'WS-4', 'WS-5', 'RH', 'RH-1', 'RH-2', 'RH-3', 'RH-4', 'RH-5', 'TA', 'TA-1', 'TA-2', 'TA-3', 'TA-4', 'TA-5', 'G', 'G-1', 'G-2', 'G-3', 'G-4', 'G-5', 'H', 'H_CORRECTED', 'H_CORRECTED-1', 'H_CORRECTED-2', 'H_CORRECTED-3', 'H_CORRECTED-4', 'H_CORRECTED-5', 'NETRAD', 'NETRAD-1', 'NETRAD-2', 'NETRAD-3', 'NETRAD-4', 'NETRAD-5', 'LE', 'LE_CORRECTED', 'LE_CORRECTED(mm)', 'LE_CORRECTED(mm)-1', 'LE_CORRECTED(mm)-2', 'LE_CORRECTED(mm)-3', 'LE_CORRECTED(mm)-4', 'LE_CORRECTED(mm)-5', 'C_BOWENS']\n",
      "columns: Index(['Date', 'Site Id', 'Year', 'Month', 'Day', 'WS', 'WS-1', 'WS-2', 'WS-3',\n",
      "       'WS-4', 'WS-5', 'RH', 'RH-1', 'RH-2', 'RH-3', 'RH-4', 'RH-5', 'TA',\n",
      "       'TA-1', 'TA-2', 'TA-3', 'TA-4', 'TA-5', 'G', 'G-1', 'G-2', 'G-3', 'G-4',\n",
      "       'G-5', 'H', 'H_CORRECTED', 'H_CORRECTED-1', 'H_CORRECTED-2',\n",
      "       'H_CORRECTED-3', 'H_CORRECTED-4', 'H_CORRECTED-5', 'NETRAD', 'NETRAD-1',\n",
      "       'NETRAD-2', 'NETRAD-3', 'NETRAD-4', 'NETRAD-5', 'LE', 'LE_CORRECTED',\n",
      "       'LE_CORRECTED(mm)', 'LE_CORRECTED(mm)-1', 'LE_CORRECTED(mm)-2',\n",
      "       'LE_CORRECTED(mm)-3', 'LE_CORRECTED(mm)-4', 'LE_CORRECTED(mm)-5',\n",
      "       'C_BOWENS'],\n",
      "      dtype='object')\n",
      "TA negative values count: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Site: US-Skr\n",
      "Before removing missing values:\n",
      "number of rows: 384 \n",
      "number of columns: 14\n",
      "After removing missing values:\n",
      "number of rows: 384 \n",
      "number of columns: 14\n",
      "ordered columns ['Date', 'Site Id', 'Year', 'Month', 'Day', 'WS', 'WS-1', 'WS-2', 'WS-3', 'WS-4', 'WS-5', 'RH', 'RH-1', 'RH-2', 'RH-3', 'RH-4', 'RH-5', 'TA', 'TA-1', 'TA-2', 'TA-3', 'TA-4', 'TA-5', 'G', 'G-1', 'G-2', 'G-3', 'G-4', 'G-5', 'H', 'H_CORRECTED', 'H_CORRECTED-1', 'H_CORRECTED-2', 'H_CORRECTED-3', 'H_CORRECTED-4', 'H_CORRECTED-5', 'NETRAD', 'NETRAD-1', 'NETRAD-2', 'NETRAD-3', 'NETRAD-4', 'NETRAD-5', 'LE', 'LE_CORRECTED', 'LE_CORRECTED(mm)', 'LE_CORRECTED(mm)-1', 'LE_CORRECTED(mm)-2', 'LE_CORRECTED(mm)-3', 'LE_CORRECTED(mm)-4', 'LE_CORRECTED(mm)-5', 'C_BOWENS']\n",
      "columns: Index(['Date', 'Site Id', 'Year', 'Month', 'Day', 'WS', 'WS-1', 'WS-2', 'WS-3',\n",
      "       'WS-4', 'WS-5', 'RH', 'RH-1', 'RH-2', 'RH-3', 'RH-4', 'RH-5', 'TA',\n",
      "       'TA-1', 'TA-2', 'TA-3', 'TA-4', 'TA-5', 'G', 'G-1', 'G-2', 'G-3', 'G-4',\n",
      "       'G-5', 'H', 'H_CORRECTED', 'H_CORRECTED-1', 'H_CORRECTED-2',\n",
      "       'H_CORRECTED-3', 'H_CORRECTED-4', 'H_CORRECTED-5', 'NETRAD', 'NETRAD-1',\n",
      "       'NETRAD-2', 'NETRAD-3', 'NETRAD-4', 'NETRAD-5', 'LE', 'LE_CORRECTED',\n",
      "       'LE_CORRECTED(mm)', 'LE_CORRECTED(mm)-1', 'LE_CORRECTED(mm)-2',\n",
      "       'LE_CORRECTED(mm)-3', 'LE_CORRECTED(mm)-4', 'LE_CORRECTED(mm)-5',\n",
      "       'C_BOWENS'],\n",
      "      dtype='object')\n",
      "TA negative values count: 0\n",
      "Site: US-Snd\n",
      "Before removing missing values:\n",
      "number of rows: 1342 \n",
      "number of columns: 14\n",
      "After removing missing values:\n",
      "number of rows: 1342 \n",
      "number of columns: 14\n",
      "ordered columns ['Date', 'Site Id', 'Year', 'Month', 'Day', 'WS', 'WS-1', 'WS-2', 'WS-3', 'WS-4', 'WS-5', 'RH', 'RH-1', 'RH-2', 'RH-3', 'RH-4', 'RH-5', 'TA', 'TA-1', 'TA-2', 'TA-3', 'TA-4', 'TA-5', 'G', 'G-1', 'G-2', 'G-3', 'G-4', 'G-5', 'H', 'H_CORRECTED', 'H_CORRECTED-1', 'H_CORRECTED-2', 'H_CORRECTED-3', 'H_CORRECTED-4', 'H_CORRECTED-5', 'NETRAD', 'NETRAD-1', 'NETRAD-2', 'NETRAD-3', 'NETRAD-4', 'NETRAD-5', 'LE', 'LE_CORRECTED', 'LE_CORRECTED(mm)', 'LE_CORRECTED(mm)-1', 'LE_CORRECTED(mm)-2', 'LE_CORRECTED(mm)-3', 'LE_CORRECTED(mm)-4', 'LE_CORRECTED(mm)-5', 'C_BOWENS']\n",
      "columns: Index(['Date', 'Site Id', 'Year', 'Month', 'Day', 'WS', 'WS-1', 'WS-2', 'WS-3',\n",
      "       'WS-4', 'WS-5', 'RH', 'RH-1', 'RH-2', 'RH-3', 'RH-4', 'RH-5', 'TA',\n",
      "       'TA-1', 'TA-2', 'TA-3', 'TA-4', 'TA-5', 'G', 'G-1', 'G-2', 'G-3', 'G-4',\n",
      "       'G-5', 'H', 'H_CORRECTED', 'H_CORRECTED-1', 'H_CORRECTED-2',\n",
      "       'H_CORRECTED-3', 'H_CORRECTED-4', 'H_CORRECTED-5', 'NETRAD', 'NETRAD-1',\n",
      "       'NETRAD-2', 'NETRAD-3', 'NETRAD-4', 'NETRAD-5', 'LE', 'LE_CORRECTED',\n",
      "       'LE_CORRECTED(mm)', 'LE_CORRECTED(mm)-1', 'LE_CORRECTED(mm)-2',\n",
      "       'LE_CORRECTED(mm)-3', 'LE_CORRECTED(mm)-4', 'LE_CORRECTED(mm)-5',\n",
      "       'C_BOWENS'],\n",
      "      dtype='object')\n",
      "TA negative values count: 0\n",
      "Site: US-AR2\n",
      "Before removing missing values:\n",
      "number of rows: 957 \n",
      "number of columns: 14\n",
      "After removing missing values:\n",
      "number of rows: 957 \n",
      "number of columns: 14\n",
      "ordered columns ['Date', 'Site Id', 'Year', 'Month', 'Day', 'WS', 'WS-1', 'WS-2', 'WS-3', 'WS-4', 'WS-5', 'RH', 'RH-1', 'RH-2', 'RH-3', 'RH-4', 'RH-5', 'TA', 'TA-1', 'TA-2', 'TA-3', 'TA-4', 'TA-5', 'G', 'G-1', 'G-2', 'G-3', 'G-4', 'G-5', 'H', 'H_CORRECTED', 'H_CORRECTED-1', 'H_CORRECTED-2', 'H_CORRECTED-3', 'H_CORRECTED-4', 'H_CORRECTED-5', 'NETRAD', 'NETRAD-1', 'NETRAD-2', 'NETRAD-3', 'NETRAD-4', 'NETRAD-5', 'LE', 'LE_CORRECTED', 'LE_CORRECTED(mm)', 'LE_CORRECTED(mm)-1', 'LE_CORRECTED(mm)-2', 'LE_CORRECTED(mm)-3', 'LE_CORRECTED(mm)-4', 'LE_CORRECTED(mm)-5', 'C_BOWENS']\n",
      "columns: Index(['Date', 'Site Id', 'Year', 'Month', 'Day', 'WS', 'WS-1', 'WS-2', 'WS-3',\n",
      "       'WS-4', 'WS-5', 'RH', 'RH-1', 'RH-2', 'RH-3', 'RH-4', 'RH-5', 'TA',\n",
      "       'TA-1', 'TA-2', 'TA-3', 'TA-4', 'TA-5', 'G', 'G-1', 'G-2', 'G-3', 'G-4',\n",
      "       'G-5', 'H', 'H_CORRECTED', 'H_CORRECTED-1', 'H_CORRECTED-2',\n",
      "       'H_CORRECTED-3', 'H_CORRECTED-4', 'H_CORRECTED-5', 'NETRAD', 'NETRAD-1',\n",
      "       'NETRAD-2', 'NETRAD-3', 'NETRAD-4', 'NETRAD-5', 'LE', 'LE_CORRECTED',\n",
      "       'LE_CORRECTED(mm)', 'LE_CORRECTED(mm)-1', 'LE_CORRECTED(mm)-2',\n",
      "       'LE_CORRECTED(mm)-3', 'LE_CORRECTED(mm)-4', 'LE_CORRECTED(mm)-5',\n",
      "       'C_BOWENS'],\n",
      "      dtype='object')\n",
      "TA negative values count: 0\n",
      "Site: US-Goo\n",
      "Before removing missing values:\n",
      "number of rows: 1277 \n",
      "number of columns: 14\n",
      "After removing missing values:\n",
      "number of rows: 1277 \n",
      "number of columns: 14\n",
      "ordered columns ['Date', 'Site Id', 'Year', 'Month', 'Day', 'WS', 'WS-1', 'WS-2', 'WS-3', 'WS-4', 'WS-5', 'RH', 'RH-1', 'RH-2', 'RH-3', 'RH-4', 'RH-5', 'TA', 'TA-1', 'TA-2', 'TA-3', 'TA-4', 'TA-5', 'G', 'G-1', 'G-2', 'G-3', 'G-4', 'G-5', 'H', 'H_CORRECTED', 'H_CORRECTED-1', 'H_CORRECTED-2', 'H_CORRECTED-3', 'H_CORRECTED-4', 'H_CORRECTED-5', 'NETRAD', 'NETRAD-1', 'NETRAD-2', 'NETRAD-3', 'NETRAD-4', 'NETRAD-5', 'LE', 'LE_CORRECTED', 'LE_CORRECTED(mm)', 'LE_CORRECTED(mm)-1', 'LE_CORRECTED(mm)-2', 'LE_CORRECTED(mm)-3', 'LE_CORRECTED(mm)-4', 'LE_CORRECTED(mm)-5', 'C_BOWENS']\n",
      "columns: Index(['Date', 'Site Id', 'Year', 'Month', 'Day', 'WS', 'WS-1', 'WS-2', 'WS-3',\n",
      "       'WS-4', 'WS-5', 'RH', 'RH-1', 'RH-2', 'RH-3', 'RH-4', 'RH-5', 'TA',\n",
      "       'TA-1', 'TA-2', 'TA-3', 'TA-4', 'TA-5', 'G', 'G-1', 'G-2', 'G-3', 'G-4',\n",
      "       'G-5', 'H', 'H_CORRECTED', 'H_CORRECTED-1', 'H_CORRECTED-2',\n",
      "       'H_CORRECTED-3', 'H_CORRECTED-4', 'H_CORRECTED-5', 'NETRAD', 'NETRAD-1',\n",
      "       'NETRAD-2', 'NETRAD-3', 'NETRAD-4', 'NETRAD-5', 'LE', 'LE_CORRECTED',\n",
      "       'LE_CORRECTED(mm)', 'LE_CORRECTED(mm)-1', 'LE_CORRECTED(mm)-2',\n",
      "       'LE_CORRECTED(mm)-3', 'LE_CORRECTED(mm)-4', 'LE_CORRECTED(mm)-5',\n",
      "       'C_BOWENS'],\n",
      "      dtype='object')\n",
      "TA negative values count: 0\n",
      "Site: US-Wlr\n",
      "Before removing missing values:\n",
      "number of rows: 1140 \n",
      "number of columns: 14\n",
      "After removing missing values:\n",
      "number of rows: 1140 \n",
      "number of columns: 14\n",
      "ordered columns ['Date', 'Site Id', 'Year', 'Month', 'Day', 'WS', 'WS-1', 'WS-2', 'WS-3', 'WS-4', 'WS-5', 'RH', 'RH-1', 'RH-2', 'RH-3', 'RH-4', 'RH-5', 'TA', 'TA-1', 'TA-2', 'TA-3', 'TA-4', 'TA-5', 'G', 'G-1', 'G-2', 'G-3', 'G-4', 'G-5', 'H', 'H_CORRECTED', 'H_CORRECTED-1', 'H_CORRECTED-2', 'H_CORRECTED-3', 'H_CORRECTED-4', 'H_CORRECTED-5', 'NETRAD', 'NETRAD-1', 'NETRAD-2', 'NETRAD-3', 'NETRAD-4', 'NETRAD-5', 'LE', 'LE_CORRECTED', 'LE_CORRECTED(mm)', 'LE_CORRECTED(mm)-1', 'LE_CORRECTED(mm)-2', 'LE_CORRECTED(mm)-3', 'LE_CORRECTED(mm)-4', 'LE_CORRECTED(mm)-5', 'C_BOWENS']\n",
      "columns: Index(['Date', 'Site Id', 'Year', 'Month', 'Day', 'WS', 'WS-1', 'WS-2', 'WS-3',\n",
      "       'WS-4', 'WS-5', 'RH', 'RH-1', 'RH-2', 'RH-3', 'RH-4', 'RH-5', 'TA',\n",
      "       'TA-1', 'TA-2', 'TA-3', 'TA-4', 'TA-5', 'G', 'G-1', 'G-2', 'G-3', 'G-4',\n",
      "       'G-5', 'H', 'H_CORRECTED', 'H_CORRECTED-1', 'H_CORRECTED-2',\n",
      "       'H_CORRECTED-3', 'H_CORRECTED-4', 'H_CORRECTED-5', 'NETRAD', 'NETRAD-1',\n",
      "       'NETRAD-2', 'NETRAD-3', 'NETRAD-4', 'NETRAD-5', 'LE', 'LE_CORRECTED',\n",
      "       'LE_CORRECTED(mm)', 'LE_CORRECTED(mm)-1', 'LE_CORRECTED(mm)-2',\n",
      "       'LE_CORRECTED(mm)-3', 'LE_CORRECTED(mm)-4', 'LE_CORRECTED(mm)-5',\n",
      "       'C_BOWENS'],\n",
      "      dtype='object')\n",
      "TA negative values count: 0\n",
      "Site: US-A74\n",
      "Before removing missing values:\n",
      "number of rows: 244 \n",
      "number of columns: 14\n",
      "After removing missing values:\n",
      "number of rows: 244 \n",
      "number of columns: 14\n",
      "ordered columns ['Date', 'Site Id', 'Year', 'Month', 'Day', 'WS', 'WS-1', 'WS-2', 'WS-3', 'WS-4', 'WS-5', 'RH', 'RH-1', 'RH-2', 'RH-3', 'RH-4', 'RH-5', 'TA', 'TA-1', 'TA-2', 'TA-3', 'TA-4', 'TA-5', 'G', 'G-1', 'G-2', 'G-3', 'G-4', 'G-5', 'H', 'H_CORRECTED', 'H_CORRECTED-1', 'H_CORRECTED-2', 'H_CORRECTED-3', 'H_CORRECTED-4', 'H_CORRECTED-5', 'NETRAD', 'NETRAD-1', 'NETRAD-2', 'NETRAD-3', 'NETRAD-4', 'NETRAD-5', 'LE', 'LE_CORRECTED', 'LE_CORRECTED(mm)', 'LE_CORRECTED(mm)-1', 'LE_CORRECTED(mm)-2', 'LE_CORRECTED(mm)-3', 'LE_CORRECTED(mm)-4', 'LE_CORRECTED(mm)-5', 'C_BOWENS']\n",
      "columns: Index(['Date', 'Site Id', 'Year', 'Month', 'Day', 'WS', 'WS-1', 'WS-2', 'WS-3',\n",
      "       'WS-4', 'WS-5', 'RH', 'RH-1', 'RH-2', 'RH-3', 'RH-4', 'RH-5', 'TA',\n",
      "       'TA-1', 'TA-2', 'TA-3', 'TA-4', 'TA-5', 'G', 'G-1', 'G-2', 'G-3', 'G-4',\n",
      "       'G-5', 'H', 'H_CORRECTED', 'H_CORRECTED-1', 'H_CORRECTED-2',\n",
      "       'H_CORRECTED-3', 'H_CORRECTED-4', 'H_CORRECTED-5', 'NETRAD', 'NETRAD-1',\n",
      "       'NETRAD-2', 'NETRAD-3', 'NETRAD-4', 'NETRAD-5', 'LE', 'LE_CORRECTED',\n",
      "       'LE_CORRECTED(mm)', 'LE_CORRECTED(mm)-1', 'LE_CORRECTED(mm)-2',\n",
      "       'LE_CORRECTED(mm)-3', 'LE_CORRECTED(mm)-4', 'LE_CORRECTED(mm)-5',\n",
      "       'C_BOWENS'],\n",
      "      dtype='object')\n",
      "TA negative values count: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Site: US-AR1\n",
      "Before removing missing values:\n",
      "number of rows: 1169 \n",
      "number of columns: 14\n",
      "After removing missing values:\n",
      "number of rows: 1169 \n",
      "number of columns: 14\n",
      "ordered columns ['Date', 'Site Id', 'Year', 'Month', 'Day', 'WS', 'WS-1', 'WS-2', 'WS-3', 'WS-4', 'WS-5', 'RH', 'RH-1', 'RH-2', 'RH-3', 'RH-4', 'RH-5', 'TA', 'TA-1', 'TA-2', 'TA-3', 'TA-4', 'TA-5', 'G', 'G-1', 'G-2', 'G-3', 'G-4', 'G-5', 'H', 'H_CORRECTED', 'H_CORRECTED-1', 'H_CORRECTED-2', 'H_CORRECTED-3', 'H_CORRECTED-4', 'H_CORRECTED-5', 'NETRAD', 'NETRAD-1', 'NETRAD-2', 'NETRAD-3', 'NETRAD-4', 'NETRAD-5', 'LE', 'LE_CORRECTED', 'LE_CORRECTED(mm)', 'LE_CORRECTED(mm)-1', 'LE_CORRECTED(mm)-2', 'LE_CORRECTED(mm)-3', 'LE_CORRECTED(mm)-4', 'LE_CORRECTED(mm)-5', 'C_BOWENS']\n",
      "columns: Index(['Date', 'Site Id', 'Year', 'Month', 'Day', 'WS', 'WS-1', 'WS-2', 'WS-3',\n",
      "       'WS-4', 'WS-5', 'RH', 'RH-1', 'RH-2', 'RH-3', 'RH-4', 'RH-5', 'TA',\n",
      "       'TA-1', 'TA-2', 'TA-3', 'TA-4', 'TA-5', 'G', 'G-1', 'G-2', 'G-3', 'G-4',\n",
      "       'G-5', 'H', 'H_CORRECTED', 'H_CORRECTED-1', 'H_CORRECTED-2',\n",
      "       'H_CORRECTED-3', 'H_CORRECTED-4', 'H_CORRECTED-5', 'NETRAD', 'NETRAD-1',\n",
      "       'NETRAD-2', 'NETRAD-3', 'NETRAD-4', 'NETRAD-5', 'LE', 'LE_CORRECTED',\n",
      "       'LE_CORRECTED(mm)', 'LE_CORRECTED(mm)-1', 'LE_CORRECTED(mm)-2',\n",
      "       'LE_CORRECTED(mm)-3', 'LE_CORRECTED(mm)-4', 'LE_CORRECTED(mm)-5',\n",
      "       'C_BOWENS'],\n",
      "      dtype='object')\n",
      "TA negative values count: 0\n",
      "Site: US-Kon\n",
      "Before removing missing values:\n",
      "number of rows: 1141 \n",
      "number of columns: 14\n",
      "After removing missing values:\n",
      "number of rows: 1141 \n",
      "number of columns: 14\n",
      "ordered columns ['Date', 'Site Id', 'Year', 'Month', 'Day', 'WS', 'WS-1', 'WS-2', 'WS-3', 'WS-4', 'WS-5', 'RH', 'RH-1', 'RH-2', 'RH-3', 'RH-4', 'RH-5', 'TA', 'TA-1', 'TA-2', 'TA-3', 'TA-4', 'TA-5', 'G', 'G-1', 'G-2', 'G-3', 'G-4', 'G-5', 'H', 'H_CORRECTED', 'H_CORRECTED-1', 'H_CORRECTED-2', 'H_CORRECTED-3', 'H_CORRECTED-4', 'H_CORRECTED-5', 'NETRAD', 'NETRAD-1', 'NETRAD-2', 'NETRAD-3', 'NETRAD-4', 'NETRAD-5', 'LE', 'LE_CORRECTED', 'LE_CORRECTED(mm)', 'LE_CORRECTED(mm)-1', 'LE_CORRECTED(mm)-2', 'LE_CORRECTED(mm)-3', 'LE_CORRECTED(mm)-4', 'LE_CORRECTED(mm)-5', 'C_BOWENS']\n",
      "columns: Index(['Date', 'Site Id', 'Year', 'Month', 'Day', 'WS', 'WS-1', 'WS-2', 'WS-3',\n",
      "       'WS-4', 'WS-5', 'RH', 'RH-1', 'RH-2', 'RH-3', 'RH-4', 'RH-5', 'TA',\n",
      "       'TA-1', 'TA-2', 'TA-3', 'TA-4', 'TA-5', 'G', 'G-1', 'G-2', 'G-3', 'G-4',\n",
      "       'G-5', 'H', 'H_CORRECTED', 'H_CORRECTED-1', 'H_CORRECTED-2',\n",
      "       'H_CORRECTED-3', 'H_CORRECTED-4', 'H_CORRECTED-5', 'NETRAD', 'NETRAD-1',\n",
      "       'NETRAD-2', 'NETRAD-3', 'NETRAD-4', 'NETRAD-5', 'LE', 'LE_CORRECTED',\n",
      "       'LE_CORRECTED(mm)', 'LE_CORRECTED(mm)-1', 'LE_CORRECTED(mm)-2',\n",
      "       'LE_CORRECTED(mm)-3', 'LE_CORRECTED(mm)-4', 'LE_CORRECTED(mm)-5',\n",
      "       'C_BOWENS'],\n",
      "      dtype='object')\n",
      "TA negative values count: 0\n",
      "Site: US-SO2\n",
      "Before removing missing values:\n",
      "number of rows: 334 \n",
      "number of columns: 14\n",
      "After removing missing values:\n",
      "number of rows: 334 \n",
      "number of columns: 14\n",
      "ordered columns ['Date', 'Site Id', 'Year', 'Month', 'Day', 'WS', 'WS-1', 'WS-2', 'WS-3', 'WS-4', 'WS-5', 'RH', 'RH-1', 'RH-2', 'RH-3', 'RH-4', 'RH-5', 'TA', 'TA-1', 'TA-2', 'TA-3', 'TA-4', 'TA-5', 'G', 'G-1', 'G-2', 'G-3', 'G-4', 'G-5', 'H', 'H_CORRECTED', 'H_CORRECTED-1', 'H_CORRECTED-2', 'H_CORRECTED-3', 'H_CORRECTED-4', 'H_CORRECTED-5', 'NETRAD', 'NETRAD-1', 'NETRAD-2', 'NETRAD-3', 'NETRAD-4', 'NETRAD-5', 'LE', 'LE_CORRECTED', 'LE_CORRECTED(mm)', 'LE_CORRECTED(mm)-1', 'LE_CORRECTED(mm)-2', 'LE_CORRECTED(mm)-3', 'LE_CORRECTED(mm)-4', 'LE_CORRECTED(mm)-5', 'C_BOWENS']\n",
      "columns: Index(['Date', 'Site Id', 'Year', 'Month', 'Day', 'WS', 'WS-1', 'WS-2', 'WS-3',\n",
      "       'WS-4', 'WS-5', 'RH', 'RH-1', 'RH-2', 'RH-3', 'RH-4', 'RH-5', 'TA',\n",
      "       'TA-1', 'TA-2', 'TA-3', 'TA-4', 'TA-5', 'G', 'G-1', 'G-2', 'G-3', 'G-4',\n",
      "       'G-5', 'H', 'H_CORRECTED', 'H_CORRECTED-1', 'H_CORRECTED-2',\n",
      "       'H_CORRECTED-3', 'H_CORRECTED-4', 'H_CORRECTED-5', 'NETRAD', 'NETRAD-1',\n",
      "       'NETRAD-2', 'NETRAD-3', 'NETRAD-4', 'NETRAD-5', 'LE', 'LE_CORRECTED',\n",
      "       'LE_CORRECTED(mm)', 'LE_CORRECTED(mm)-1', 'LE_CORRECTED(mm)-2',\n",
      "       'LE_CORRECTED(mm)-3', 'LE_CORRECTED(mm)-4', 'LE_CORRECTED(mm)-5',\n",
      "       'C_BOWENS'],\n",
      "      dtype='object')\n",
      "TA negative values count: 0\n",
      "Site: US-SP2\n",
      "Before removing missing values:\n",
      "number of rows: 1039 \n",
      "number of columns: 14\n",
      "After removing missing values:\n",
      "number of rows: 1039 \n",
      "number of columns: 14\n",
      "ordered columns ['Date', 'Site Id', 'Year', 'Month', 'Day', 'WS', 'WS-1', 'WS-2', 'WS-3', 'WS-4', 'WS-5', 'RH', 'RH-1', 'RH-2', 'RH-3', 'RH-4', 'RH-5', 'TA', 'TA-1', 'TA-2', 'TA-3', 'TA-4', 'TA-5', 'G', 'G-1', 'G-2', 'G-3', 'G-4', 'G-5', 'H', 'H_CORRECTED', 'H_CORRECTED-1', 'H_CORRECTED-2', 'H_CORRECTED-3', 'H_CORRECTED-4', 'H_CORRECTED-5', 'NETRAD', 'NETRAD-1', 'NETRAD-2', 'NETRAD-3', 'NETRAD-4', 'NETRAD-5', 'LE', 'LE_CORRECTED', 'LE_CORRECTED(mm)', 'LE_CORRECTED(mm)-1', 'LE_CORRECTED(mm)-2', 'LE_CORRECTED(mm)-3', 'LE_CORRECTED(mm)-4', 'LE_CORRECTED(mm)-5', 'C_BOWENS']\n",
      "columns: Index(['Date', 'Site Id', 'Year', 'Month', 'Day', 'WS', 'WS-1', 'WS-2', 'WS-3',\n",
      "       'WS-4', 'WS-5', 'RH', 'RH-1', 'RH-2', 'RH-3', 'RH-4', 'RH-5', 'TA',\n",
      "       'TA-1', 'TA-2', 'TA-3', 'TA-4', 'TA-5', 'G', 'G-1', 'G-2', 'G-3', 'G-4',\n",
      "       'G-5', 'H', 'H_CORRECTED', 'H_CORRECTED-1', 'H_CORRECTED-2',\n",
      "       'H_CORRECTED-3', 'H_CORRECTED-4', 'H_CORRECTED-5', 'NETRAD', 'NETRAD-1',\n",
      "       'NETRAD-2', 'NETRAD-3', 'NETRAD-4', 'NETRAD-5', 'LE', 'LE_CORRECTED',\n",
      "       'LE_CORRECTED(mm)', 'LE_CORRECTED(mm)-1', 'LE_CORRECTED(mm)-2',\n",
      "       'LE_CORRECTED(mm)-3', 'LE_CORRECTED(mm)-4', 'LE_CORRECTED(mm)-5',\n",
      "       'C_BOWENS'],\n",
      "      dtype='object')\n",
      "TA negative values count: 0\n",
      "Site: US-Var\n",
      "Before removing missing values:\n",
      "number of rows: 1903 \n",
      "number of columns: 14\n",
      "After removing missing values:\n",
      "number of rows: 1903 \n",
      "number of columns: 14\n",
      "ordered columns ['Date', 'Site Id', 'Year', 'Month', 'Day', 'WS', 'WS-1', 'WS-2', 'WS-3', 'WS-4', 'WS-5', 'RH', 'RH-1', 'RH-2', 'RH-3', 'RH-4', 'RH-5', 'TA', 'TA-1', 'TA-2', 'TA-3', 'TA-4', 'TA-5', 'G', 'G-1', 'G-2', 'G-3', 'G-4', 'G-5', 'H', 'H_CORRECTED', 'H_CORRECTED-1', 'H_CORRECTED-2', 'H_CORRECTED-3', 'H_CORRECTED-4', 'H_CORRECTED-5', 'NETRAD', 'NETRAD-1', 'NETRAD-2', 'NETRAD-3', 'NETRAD-4', 'NETRAD-5', 'LE', 'LE_CORRECTED', 'LE_CORRECTED(mm)', 'LE_CORRECTED(mm)-1', 'LE_CORRECTED(mm)-2', 'LE_CORRECTED(mm)-3', 'LE_CORRECTED(mm)-4', 'LE_CORRECTED(mm)-5', 'C_BOWENS']\n",
      "columns: Index(['Date', 'Site Id', 'Year', 'Month', 'Day', 'WS', 'WS-1', 'WS-2', 'WS-3',\n",
      "       'WS-4', 'WS-5', 'RH', 'RH-1', 'RH-2', 'RH-3', 'RH-4', 'RH-5', 'TA',\n",
      "       'TA-1', 'TA-2', 'TA-3', 'TA-4', 'TA-5', 'G', 'G-1', 'G-2', 'G-3', 'G-4',\n",
      "       'G-5', 'H', 'H_CORRECTED', 'H_CORRECTED-1', 'H_CORRECTED-2',\n",
      "       'H_CORRECTED-3', 'H_CORRECTED-4', 'H_CORRECTED-5', 'NETRAD', 'NETRAD-1',\n",
      "       'NETRAD-2', 'NETRAD-3', 'NETRAD-4', 'NETRAD-5', 'LE', 'LE_CORRECTED',\n",
      "       'LE_CORRECTED(mm)', 'LE_CORRECTED(mm)-1', 'LE_CORRECTED(mm)-2',\n",
      "       'LE_CORRECTED(mm)-3', 'LE_CORRECTED(mm)-4', 'LE_CORRECTED(mm)-5',\n",
      "       'C_BOWENS'],\n",
      "      dtype='object')\n",
      "TA negative values count: 0\n",
      "Site: US-Twt\n",
      "Before removing missing values:\n",
      "number of rows: 1861 \n",
      "number of columns: 14\n",
      "After removing missing values:\n",
      "number of rows: 1861 \n",
      "number of columns: 14\n",
      "ordered columns ['Date', 'Site Id', 'Year', 'Month', 'Day', 'WS', 'WS-1', 'WS-2', 'WS-3', 'WS-4', 'WS-5', 'RH', 'RH-1', 'RH-2', 'RH-3', 'RH-4', 'RH-5', 'TA', 'TA-1', 'TA-2', 'TA-3', 'TA-4', 'TA-5', 'G', 'G-1', 'G-2', 'G-3', 'G-4', 'G-5', 'H', 'H_CORRECTED', 'H_CORRECTED-1', 'H_CORRECTED-2', 'H_CORRECTED-3', 'H_CORRECTED-4', 'H_CORRECTED-5', 'NETRAD', 'NETRAD-1', 'NETRAD-2', 'NETRAD-3', 'NETRAD-4', 'NETRAD-5', 'LE', 'LE_CORRECTED', 'LE_CORRECTED(mm)', 'LE_CORRECTED(mm)-1', 'LE_CORRECTED(mm)-2', 'LE_CORRECTED(mm)-3', 'LE_CORRECTED(mm)-4', 'LE_CORRECTED(mm)-5', 'C_BOWENS']\n",
      "columns: Index(['Date', 'Site Id', 'Year', 'Month', 'Day', 'WS', 'WS-1', 'WS-2', 'WS-3',\n",
      "       'WS-4', 'WS-5', 'RH', 'RH-1', 'RH-2', 'RH-3', 'RH-4', 'RH-5', 'TA',\n",
      "       'TA-1', 'TA-2', 'TA-3', 'TA-4', 'TA-5', 'G', 'G-1', 'G-2', 'G-3', 'G-4',\n",
      "       'G-5', 'H', 'H_CORRECTED', 'H_CORRECTED-1', 'H_CORRECTED-2',\n",
      "       'H_CORRECTED-3', 'H_CORRECTED-4', 'H_CORRECTED-5', 'NETRAD', 'NETRAD-1',\n",
      "       'NETRAD-2', 'NETRAD-3', 'NETRAD-4', 'NETRAD-5', 'LE', 'LE_CORRECTED',\n",
      "       'LE_CORRECTED(mm)', 'LE_CORRECTED(mm)-1', 'LE_CORRECTED(mm)-2',\n",
      "       'LE_CORRECTED(mm)-3', 'LE_CORRECTED(mm)-4', 'LE_CORRECTED(mm)-5',\n",
      "       'C_BOWENS'],\n",
      "      dtype='object')\n",
      "TA negative values count: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid Sites are ['US-Ced', 'US-Shd', 'US-Bi2', 'US-A32', 'US-Tw2', 'US-Pon', 'US-Skr', 'US-Snd', 'US-AR2', 'US-Goo', 'US-Wlr', 'US-A74', 'US-AR1', 'US-Kon', 'US-SO2', 'US-SP2', 'US-Var', 'US-Twt']\n",
      "      Timestamp start  TIMESTAMP_END Site Id  Year  Month  Day        WS  \\\n",
      "9744     200907230000   200907230030  US-Twt  2009      7   23  2.578392   \n",
      "9748     200907230200   200907230230  US-Twt  2009      7   23  3.329627   \n",
      "9750     200907230300   200907230330  US-Twt  2009      7   23  3.770757   \n",
      "9751     200907230330   200907230400  US-Twt  2009      7   23  2.996385   \n",
      "9752     200907230400   200907230430  US-Twt  2009      7   23  1.757107   \n",
      "\n",
      "          WS-1      WS-2      WS-3  ...  NETRAD_SOIL         LE    LE(mm)  \\\n",
      "9744       NaN       NaN       NaN  ...          0.0  27.281298  0.942685   \n",
      "9748  2.578392       NaN       NaN  ...          0.0  25.882064  0.894335   \n",
      "9750  3.329627  2.578392       NaN  ...          0.0  23.188757  0.801270   \n",
      "9751  3.770757  3.329627  2.578392  ...          0.0  22.534713  0.778670   \n",
      "9752  2.996385  3.770757  3.329627  ...          0.0  13.626492  0.470853   \n",
      "\n",
      "      LE(mm)-1  LE(mm)-2  LE(mm)-3  LE(mm)-4  LE(mm)-5  LATENT_SENSIBLE  \\\n",
      "9744       NaN       NaN       NaN       NaN       NaN              0.0   \n",
      "9748  0.942685       NaN       NaN       NaN       NaN              0.0   \n",
      "9750  0.894335  0.942685       NaN       NaN       NaN              0.0   \n",
      "9751  0.801270  0.894335  0.942685       NaN       NaN              0.0   \n",
      "9752  0.778670  0.801270  0.894335  0.942685       NaN              0.0   \n",
      "\n",
      "      NETRAD_SOIL  \n",
      "9744          0.0  \n",
      "9748          0.0  \n",
      "9750          0.0  \n",
      "9751          0.0  \n",
      "9752          0.0  \n",
      "\n",
      "[5 rows x 52 columns]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    is_hourly = False\n",
    "    output_name = os.path.join(base_path + \"Ameriflux/\", \"Jan-11-2020_Daily/\")\n",
    "    am = Ameriflux(daily_classified_path, skipRowsNum, split_num, lags_count, is_hourly, False, output_name)\n",
    "    sites_df = Helpers.read_sites_data()\n",
    "    df_daily = am.generate_site_data(sites_df)\n",
    "    file_name = os.path.join(output_name, \"All_Daily\")\n",
    "    Helpers.export_data(df_daily, file_name) \n",
    "    print(all_sites_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Joint Data - EEflux </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class JointData:\n",
    "     def __init__(self, output_file, lags_count):\n",
    "        print(\"Merged Initializer\")\n",
    "        self.output_file = output_file\n",
    "        self.lags_count = lags_count\n",
    "     \n",
    "     def read_data(self):\n",
    "        '''This function reads the data from EEflux'''\n",
    "        file_name = os.path.join(base_path, \"EEflux/EEflux_sites.csv\")\n",
    "        eeflux_df = pd.read_csv(file_name, index_col=None, header=0)\n",
    "        eeflux_df[\"Date\"] = pd.to_datetime(eeflux_df[\"Date\"])\n",
    "        eeflux_df.head()\n",
    "        return eeflux_df\n",
    "    \n",
    "     def merge_datasets(self, df_first, df_second, col):\n",
    "        '''This function will merge two data frames according to the provided columns'''\n",
    "        merged_df = pd.merge(df_first, df_second, left_on=col, \n",
    "                         right_on=col, how=\"inner\")\n",
    "        columns = merged_df.columns\n",
    "        return merged_df\n",
    "    \n",
    "     def drop_invalid_lags(self, df):\n",
    "        '''This function will drop all the lags'''\n",
    "        ws_list = list(Helpers.get_all_matching_columns(df, \"WS-\"))\n",
    "        rh_list = list(Helpers.get_all_matching_columns(df, \"RH-\"))\n",
    "        ta_list = list(Helpers.get_all_matching_columns(df, \"TA-\"))\n",
    "        g_list = list(Helpers.get_all_matching_columns(df, \"G-\"))\n",
    "#         h_list = list(Helpers.get_all_matching_columns(df, \"H-\"))\n",
    "        h_corr_list = list(Helpers.get_all_matching_columns(df, \"H_CORRECTED-\"))\n",
    "        netrad_list = list(Helpers.get_all_matching_columns(df, \"NETRAD-\"))\n",
    "        le_list = list(Helpers.get_all_matching_columns(df, \"LE(mm)-\"))\n",
    "        le_corr_list = list(Helpers.get_all_matching_columns(df, \"LE_CORRECTED(mm)-\"))\n",
    "\n",
    "        columns_to_drop = []\n",
    "        columns_to_drop.extend(ws_list)\n",
    "        columns_to_drop.extend(rh_list)\n",
    "        columns_to_drop.extend(ta_list)\n",
    "        columns_to_drop.extend(g_list)\n",
    "#         columns_to_drop.extend(h_list)\n",
    "        columns_to_drop.extend(h_corr_list)\n",
    "        columns_to_drop.extend(netrad_list)\n",
    "        columns_to_drop.extend(le_list)\n",
    "        columns_to_drop.extend(le_corr_list)\n",
    "        df.drop(columns_to_drop, axis=1, inplace=True)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "     def order_common_columns(self, df):\n",
    "        '''This function will order the date and main columns'''\n",
    "        all_columns = [\"Date\", \"Site Id\", \"Year\", \"Month\", \"Day\"]\n",
    "        return all_columns\n",
    "            \n",
    "     def order_columns(self, df):\n",
    "        '''This function will specify the columns required and will order the columns'''\n",
    "        all_columns = self.order_common_columns(df)\n",
    "        if \"WS\" in df.columns:\n",
    "            all_columns.append(\"WS\")\n",
    "        ws_list = [col for col in df if col.startswith('WS-')]\n",
    "        all_columns.extend(ws_list)\n",
    "        if \"RH\" in df.columns:\n",
    "            all_columns.append(\"RH\")\n",
    "        rh_list = [col for col in df if col.startswith('RH-')]\n",
    "        all_columns.extend(rh_list)\n",
    "        if \"TA\" in df.columns:\n",
    "            all_columns.append(\"TA\")\n",
    "        ta_list = [col for col in df if col.startswith('TA-')]\n",
    "        all_columns.extend(ta_list)\n",
    "        if \"G\" in df.columns:\n",
    "            all_columns.append(\"G\")\n",
    "        g_list = [col for col in df if col.startswith('G-')]\n",
    "        all_columns.extend(g_list)\n",
    "        if \"H\" in df.columns:\n",
    "            all_columns.append(\"H\")\n",
    "        h_list = [col for col in df if col.startswith('H-')]\n",
    "        h_corr_list = [col for col in df if col.startswith('H_')]\n",
    "        all_columns.extend(h_list)\n",
    "        all_columns.extend(h_corr_list)\n",
    "        netrad_list = [col for col in df if col.startswith('NETRAD')]\n",
    "        le_list = [col for col in df if col.startswith('LE')]\n",
    "        all_columns.extend(netrad_list)\n",
    "        all_columns.extend(le_list)\n",
    "        all_columns.extend(['Cloud','Image Id', 'EEflux ET', 'Tier'])\n",
    "        print(\"ordered columns\", all_columns)\n",
    "        df = df[all_columns]\n",
    "        return df\n",
    "    \n",
    "     def generate_lags(self, df):\n",
    "        '''This function generates the lags for the list of columns'''\n",
    "        input_columns = [\"RH\", \"TA\", \"G\", \"H_CORRECTED\", \"WS\", \"NETRAD\", \"LE_CORRECTED(mm)\"]\n",
    "        for k in range(len(input_columns)):\n",
    "            col = input_columns[k]\n",
    "            if col in df.columns:\n",
    "                df = Helpers.generate_lags(df, col, self.lags_count)\n",
    "        return df\n",
    "    \n",
    "\n",
    "     def prepare_data(self, df_daily, col_first, col_second):\n",
    "        eeflux_df = self.read_data()\n",
    "        df_daily[\"Date\"] = pd.to_datetime(df_daily[\"Date\"])\n",
    "        print(\"daily df columns\", df_daily.columns)\n",
    "        group_sites_list = []\n",
    "        merged_df = self.merge_datasets(df_daily, eeflux_df, [\"Site Id\",\"Date\"])\n",
    "        unique_sites = df_daily[\"Site Id\"].unique()\n",
    "        for i in range(len(unique_sites)):\n",
    "            site_id = unique_sites[i]\n",
    "            df_joint = merged_df[merged_df[\"Site Id\"] == site_id]\n",
    "            df_joint[\"Site Id\"] = site_id\n",
    "            print(\"Site ID\", site_id)\n",
    "            if len(df_joint) > 1:\n",
    "                df_joint[\"EEflux ET\"] = np.where(df_joint[\"Modeled ET\"] == np.nan, df_joint[\"Mean Modeled ET\"], df_joint[\"Modeled ET\"])\n",
    "                df_joint = self.drop_invalid_lags(df_joint)\n",
    "                df_joint = self.generate_lags(df_joint)\n",
    "                df_joint = self.order_columns(df_joint)\n",
    "                df_joint = Helpers.drop_nan_columns(df_joint)\n",
    "                print(\"columns\", df_joint.columns)\n",
    "                file_name = os.path.join(self.output_file, site_id + \"_\" + \"Joint\")\n",
    "                Helpers.export_data(df_joint, file_name) \n",
    "                group_sites_list.append(df_joint)\n",
    "            \n",
    "        return Helpers.list_to_df(group_sites_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged Initializer\n",
      "daily df columns Index(['C_BOWENS', 'Date', 'Day', 'G', 'G-1', 'G-2', 'G-3', 'G-4', 'G-5', 'H',\n",
      "       'H_CORRECTED', 'H_CORRECTED-1', 'H_CORRECTED-2', 'H_CORRECTED-3',\n",
      "       'H_CORRECTED-4', 'H_CORRECTED-5', 'LE', 'LE_CORRECTED',\n",
      "       'LE_CORRECTED(mm)', 'LE_CORRECTED(mm)-1', 'LE_CORRECTED(mm)-2',\n",
      "       'LE_CORRECTED(mm)-3', 'LE_CORRECTED(mm)-4', 'LE_CORRECTED(mm)-5',\n",
      "       'Month', 'NETRAD', 'NETRAD-1', 'NETRAD-2', 'NETRAD-3', 'NETRAD-4',\n",
      "       'NETRAD-5', 'RH', 'RH-1', 'RH-2', 'RH-3', 'RH-4', 'RH-5', 'Site Id',\n",
      "       'TA', 'TA-1', 'TA-2', 'TA-3', 'TA-4', 'TA-5', 'WS', 'WS-1', 'WS-2',\n",
      "       'WS-3', 'WS-4', 'WS-5', 'Year'],\n",
      "      dtype='object')\n",
      "Site ID US-Ced\n",
      "ordered columns ['Date', 'Site Id', 'Year', 'Month', 'Day', 'WS', 'WS-1', 'WS-2', 'WS-3', 'WS-4', 'WS-5', 'RH', 'RH-1', 'RH-2', 'RH-3', 'RH-4', 'RH-5', 'TA', 'TA-1', 'TA-2', 'TA-3', 'TA-4', 'TA-5', 'G', 'G-1', 'G-2', 'G-3', 'G-4', 'G-5', 'H', 'H_CORRECTED', 'H_CORRECTED-1', 'H_CORRECTED-2', 'H_CORRECTED-3', 'H_CORRECTED-4', 'H_CORRECTED-5', 'NETRAD', 'NETRAD-1', 'NETRAD-2', 'NETRAD-3', 'NETRAD-4', 'NETRAD-5', 'LE', 'LE_CORRECTED', 'LE_CORRECTED(mm)', 'LE_CORRECTED(mm)-1', 'LE_CORRECTED(mm)-2', 'LE_CORRECTED(mm)-3', 'LE_CORRECTED(mm)-4', 'LE_CORRECTED(mm)-5', 'Cloud', 'Image Id', 'EEflux ET', 'Tier']\n",
      "columns Index(['Date', 'Site Id', 'Year', 'Month', 'Day', 'WS', 'WS-1', 'WS-2', 'WS-3',\n",
      "       'WS-4', 'WS-5', 'RH', 'RH-1', 'RH-2', 'RH-3', 'RH-4', 'RH-5', 'TA',\n",
      "       'TA-1', 'TA-2', 'TA-3', 'TA-4', 'TA-5', 'G', 'G-1', 'G-2', 'G-3', 'G-4',\n",
      "       'G-5', 'H', 'H_CORRECTED', 'H_CORRECTED-1', 'H_CORRECTED-2',\n",
      "       'H_CORRECTED-3', 'H_CORRECTED-4', 'H_CORRECTED-5', 'NETRAD', 'NETRAD-1',\n",
      "       'NETRAD-2', 'NETRAD-3', 'NETRAD-4', 'NETRAD-5', 'LE', 'LE_CORRECTED',\n",
      "       'LE_CORRECTED(mm)', 'LE_CORRECTED(mm)-1', 'LE_CORRECTED(mm)-2',\n",
      "       'LE_CORRECTED(mm)-3', 'LE_CORRECTED(mm)-4', 'LE_CORRECTED(mm)-5',\n",
      "       'Cloud', 'Image Id', 'EEflux ET', 'Tier'],\n",
      "      dtype='object')\n",
      "Site ID US-Shd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saraawad/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:107: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/saraawad/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:110: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/saraawad/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py:4117: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n",
      "/Users/saraawad/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ordered columns ['Date', 'Site Id', 'Year', 'Month', 'Day', 'WS', 'WS-1', 'WS-2', 'WS-3', 'WS-4', 'WS-5', 'RH', 'RH-1', 'RH-2', 'RH-3', 'RH-4', 'RH-5', 'TA', 'TA-1', 'TA-2', 'TA-3', 'TA-4', 'TA-5', 'G', 'G-1', 'G-2', 'G-3', 'G-4', 'G-5', 'H', 'H_CORRECTED', 'H_CORRECTED-1', 'H_CORRECTED-2', 'H_CORRECTED-3', 'H_CORRECTED-4', 'H_CORRECTED-5', 'NETRAD', 'NETRAD-1', 'NETRAD-2', 'NETRAD-3', 'NETRAD-4', 'NETRAD-5', 'LE', 'LE_CORRECTED', 'LE_CORRECTED(mm)', 'LE_CORRECTED(mm)-1', 'LE_CORRECTED(mm)-2', 'LE_CORRECTED(mm)-3', 'LE_CORRECTED(mm)-4', 'LE_CORRECTED(mm)-5', 'Cloud', 'Image Id', 'EEflux ET', 'Tier']\n",
      "columns Index(['Date', 'Site Id', 'Year', 'Month', 'Day', 'WS', 'WS-1', 'WS-2', 'WS-3',\n",
      "       'WS-4', 'WS-5', 'RH', 'RH-1', 'RH-2', 'RH-3', 'RH-4', 'RH-5', 'TA',\n",
      "       'TA-1', 'TA-2', 'TA-3', 'TA-4', 'TA-5', 'G', 'G-1', 'G-2', 'G-3', 'G-4',\n",
      "       'G-5', 'H', 'H_CORRECTED', 'H_CORRECTED-1', 'H_CORRECTED-2',\n",
      "       'H_CORRECTED-3', 'H_CORRECTED-4', 'H_CORRECTED-5', 'NETRAD', 'NETRAD-1',\n",
      "       'NETRAD-2', 'NETRAD-3', 'NETRAD-4', 'NETRAD-5', 'LE', 'LE_CORRECTED',\n",
      "       'LE_CORRECTED(mm)', 'LE_CORRECTED(mm)-1', 'LE_CORRECTED(mm)-2',\n",
      "       'LE_CORRECTED(mm)-3', 'LE_CORRECTED(mm)-4', 'LE_CORRECTED(mm)-5',\n",
      "       'Cloud', 'Image Id', 'EEflux ET', 'Tier'],\n",
      "      dtype='object')\n",
      "Site ID US-Bi2\n",
      "ordered columns ['Date', 'Site Id', 'Year', 'Month', 'Day', 'WS', 'WS-1', 'WS-2', 'WS-3', 'WS-4', 'WS-5', 'RH', 'RH-1', 'RH-2', 'RH-3', 'RH-4', 'RH-5', 'TA', 'TA-1', 'TA-2', 'TA-3', 'TA-4', 'TA-5', 'G', 'G-1', 'G-2', 'G-3', 'G-4', 'G-5', 'H', 'H_CORRECTED', 'H_CORRECTED-1', 'H_CORRECTED-2', 'H_CORRECTED-3', 'H_CORRECTED-4', 'H_CORRECTED-5', 'NETRAD', 'NETRAD-1', 'NETRAD-2', 'NETRAD-3', 'NETRAD-4', 'NETRAD-5', 'LE', 'LE_CORRECTED', 'LE_CORRECTED(mm)', 'LE_CORRECTED(mm)-1', 'LE_CORRECTED(mm)-2', 'LE_CORRECTED(mm)-3', 'LE_CORRECTED(mm)-4', 'LE_CORRECTED(mm)-5', 'Cloud', 'Image Id', 'EEflux ET', 'Tier']\n",
      "columns Index(['Date', 'Site Id', 'Year', 'Month', 'Day', 'WS', 'WS-1', 'WS-2', 'WS-3',\n",
      "       'WS-4', 'WS-5', 'RH', 'RH-1', 'RH-2', 'RH-3', 'RH-4', 'RH-5', 'TA',\n",
      "       'TA-1', 'TA-2', 'TA-3', 'TA-4', 'TA-5', 'G', 'G-1', 'G-2', 'G-3', 'G-4',\n",
      "       'G-5', 'H', 'H_CORRECTED', 'H_CORRECTED-1', 'H_CORRECTED-2',\n",
      "       'H_CORRECTED-3', 'H_CORRECTED-4', 'H_CORRECTED-5', 'NETRAD', 'NETRAD-1',\n",
      "       'NETRAD-2', 'NETRAD-3', 'NETRAD-4', 'NETRAD-5', 'LE', 'LE_CORRECTED',\n",
      "       'LE_CORRECTED(mm)', 'LE_CORRECTED(mm)-1', 'LE_CORRECTED(mm)-2',\n",
      "       'LE_CORRECTED(mm)-3', 'LE_CORRECTED(mm)-4', 'LE_CORRECTED(mm)-5',\n",
      "       'Cloud', 'Image Id', 'EEflux ET', 'Tier'],\n",
      "      dtype='object')\n",
      "Site ID US-A32\n",
      "ordered columns ['Date', 'Site Id', 'Year', 'Month', 'Day', 'WS', 'WS-1', 'WS-2', 'WS-3', 'WS-4', 'WS-5', 'RH', 'RH-1', 'RH-2', 'RH-3', 'RH-4', 'RH-5', 'TA', 'TA-1', 'TA-2', 'TA-3', 'TA-4', 'TA-5', 'G', 'G-1', 'G-2', 'G-3', 'G-4', 'G-5', 'H', 'H_CORRECTED', 'H_CORRECTED-1', 'H_CORRECTED-2', 'H_CORRECTED-3', 'H_CORRECTED-4', 'H_CORRECTED-5', 'NETRAD', 'NETRAD-1', 'NETRAD-2', 'NETRAD-3', 'NETRAD-4', 'NETRAD-5', 'LE', 'LE_CORRECTED', 'LE_CORRECTED(mm)', 'LE_CORRECTED(mm)-1', 'LE_CORRECTED(mm)-2', 'LE_CORRECTED(mm)-3', 'LE_CORRECTED(mm)-4', 'LE_CORRECTED(mm)-5', 'Cloud', 'Image Id', 'EEflux ET', 'Tier']\n",
      "columns Index(['Date', 'Site Id', 'Year', 'Month', 'Day', 'WS', 'WS-1', 'WS-2', 'WS-3',\n",
      "       'WS-4', 'WS-5', 'RH', 'RH-1', 'RH-2', 'RH-3', 'RH-4', 'RH-5', 'TA',\n",
      "       'TA-1', 'TA-2', 'TA-3', 'TA-4', 'TA-5', 'G', 'G-1', 'G-2', 'G-3', 'G-4',\n",
      "       'G-5', 'H', 'H_CORRECTED', 'H_CORRECTED-1', 'H_CORRECTED-2',\n",
      "       'H_CORRECTED-3', 'H_CORRECTED-4', 'H_CORRECTED-5', 'NETRAD', 'NETRAD-1',\n",
      "       'NETRAD-2', 'NETRAD-3', 'NETRAD-4', 'NETRAD-5', 'LE', 'LE_CORRECTED',\n",
      "       'LE_CORRECTED(mm)', 'LE_CORRECTED(mm)-1', 'LE_CORRECTED(mm)-2',\n",
      "       'LE_CORRECTED(mm)-3', 'LE_CORRECTED(mm)-4', 'LE_CORRECTED(mm)-5',\n",
      "       'Cloud', 'Image Id', 'EEflux ET', 'Tier'],\n",
      "      dtype='object')\n",
      "Site ID US-Tw2\n",
      "ordered columns ['Date', 'Site Id', 'Year', 'Month', 'Day', 'WS', 'WS-1', 'WS-2', 'WS-3', 'WS-4', 'WS-5', 'RH', 'RH-1', 'RH-2', 'RH-3', 'RH-4', 'RH-5', 'TA', 'TA-1', 'TA-2', 'TA-3', 'TA-4', 'TA-5', 'G', 'G-1', 'G-2', 'G-3', 'G-4', 'G-5', 'H', 'H_CORRECTED', 'H_CORRECTED-1', 'H_CORRECTED-2', 'H_CORRECTED-3', 'H_CORRECTED-4', 'H_CORRECTED-5', 'NETRAD', 'NETRAD-1', 'NETRAD-2', 'NETRAD-3', 'NETRAD-4', 'NETRAD-5', 'LE', 'LE_CORRECTED', 'LE_CORRECTED(mm)', 'LE_CORRECTED(mm)-1', 'LE_CORRECTED(mm)-2', 'LE_CORRECTED(mm)-3', 'LE_CORRECTED(mm)-4', 'LE_CORRECTED(mm)-5', 'Cloud', 'Image Id', 'EEflux ET', 'Tier']\n",
      "columns Index(['Date', 'Site Id', 'Year', 'Month', 'Day', 'WS', 'WS-1', 'WS-2', 'WS-3',\n",
      "       'WS-4', 'WS-5', 'RH', 'RH-1', 'RH-2', 'RH-3', 'RH-4', 'RH-5', 'TA',\n",
      "       'TA-1', 'TA-2', 'TA-3', 'TA-4', 'TA-5', 'G', 'G-1', 'G-2', 'G-3', 'G-4',\n",
      "       'G-5', 'H', 'H_CORRECTED', 'H_CORRECTED-1', 'H_CORRECTED-2',\n",
      "       'H_CORRECTED-3', 'H_CORRECTED-4', 'H_CORRECTED-5', 'NETRAD', 'NETRAD-1',\n",
      "       'NETRAD-2', 'NETRAD-3', 'NETRAD-4', 'NETRAD-5', 'LE', 'LE_CORRECTED',\n",
      "       'LE_CORRECTED(mm)', 'LE_CORRECTED(mm)-1', 'LE_CORRECTED(mm)-2',\n",
      "       'LE_CORRECTED(mm)-3', 'LE_CORRECTED(mm)-4', 'LE_CORRECTED(mm)-5',\n",
      "       'Cloud', 'Image Id', 'EEflux ET', 'Tier'],\n",
      "      dtype='object')\n",
      "Site ID US-Pon\n",
      "ordered columns ['Date', 'Site Id', 'Year', 'Month', 'Day', 'WS', 'WS-1', 'WS-2', 'WS-3', 'WS-4', 'WS-5', 'RH', 'RH-1', 'RH-2', 'RH-3', 'RH-4', 'RH-5', 'TA', 'TA-1', 'TA-2', 'TA-3', 'TA-4', 'TA-5', 'G', 'G-1', 'G-2', 'G-3', 'G-4', 'G-5', 'H', 'H_CORRECTED', 'H_CORRECTED-1', 'H_CORRECTED-2', 'H_CORRECTED-3', 'H_CORRECTED-4', 'H_CORRECTED-5', 'NETRAD', 'NETRAD-1', 'NETRAD-2', 'NETRAD-3', 'NETRAD-4', 'NETRAD-5', 'LE', 'LE_CORRECTED', 'LE_CORRECTED(mm)', 'LE_CORRECTED(mm)-1', 'LE_CORRECTED(mm)-2', 'LE_CORRECTED(mm)-3', 'LE_CORRECTED(mm)-4', 'LE_CORRECTED(mm)-5', 'Cloud', 'Image Id', 'EEflux ET', 'Tier']\n",
      "columns Index(['Date', 'Site Id', 'Year', 'Month', 'Day', 'WS', 'WS-1', 'WS-2', 'WS-3',\n",
      "       'WS-4', 'WS-5', 'RH', 'RH-1', 'RH-2', 'RH-3', 'RH-4', 'RH-5', 'TA',\n",
      "       'TA-1', 'TA-2', 'TA-3', 'TA-4', 'TA-5', 'G', 'G-1', 'G-2', 'G-3', 'G-4',\n",
      "       'G-5', 'H', 'H_CORRECTED', 'H_CORRECTED-1', 'H_CORRECTED-2',\n",
      "       'H_CORRECTED-3', 'H_CORRECTED-4', 'H_CORRECTED-5', 'NETRAD', 'NETRAD-1',\n",
      "       'NETRAD-2', 'NETRAD-3', 'NETRAD-4', 'NETRAD-5', 'LE', 'LE_CORRECTED',\n",
      "       'LE_CORRECTED(mm)', 'LE_CORRECTED(mm)-1', 'LE_CORRECTED(mm)-2',\n",
      "       'LE_CORRECTED(mm)-3', 'LE_CORRECTED(mm)-4', 'LE_CORRECTED(mm)-5',\n",
      "       'Cloud', 'Image Id', 'EEflux ET', 'Tier'],\n",
      "      dtype='object')\n",
      "Site ID US-Skr\n",
      "ordered columns ['Date', 'Site Id', 'Year', 'Month', 'Day', 'WS', 'WS-1', 'WS-2', 'WS-3', 'WS-4', 'WS-5', 'RH', 'RH-1', 'RH-2', 'RH-3', 'RH-4', 'RH-5', 'TA', 'TA-1', 'TA-2', 'TA-3', 'TA-4', 'TA-5', 'G', 'G-1', 'G-2', 'G-3', 'G-4', 'G-5', 'H', 'H_CORRECTED', 'H_CORRECTED-1', 'H_CORRECTED-2', 'H_CORRECTED-3', 'H_CORRECTED-4', 'H_CORRECTED-5', 'NETRAD', 'NETRAD-1', 'NETRAD-2', 'NETRAD-3', 'NETRAD-4', 'NETRAD-5', 'LE', 'LE_CORRECTED', 'LE_CORRECTED(mm)', 'LE_CORRECTED(mm)-1', 'LE_CORRECTED(mm)-2', 'LE_CORRECTED(mm)-3', 'LE_CORRECTED(mm)-4', 'LE_CORRECTED(mm)-5', 'Cloud', 'Image Id', 'EEflux ET', 'Tier']\n",
      "columns Index(['Date', 'Site Id', 'Year', 'Month', 'Day', 'WS', 'WS-1', 'WS-2', 'WS-3',\n",
      "       'WS-4', 'WS-5', 'RH', 'RH-1', 'RH-2', 'RH-3', 'RH-4', 'RH-5', 'TA',\n",
      "       'TA-1', 'TA-2', 'TA-3', 'TA-4', 'TA-5', 'G', 'G-1', 'G-2', 'G-3', 'G-4',\n",
      "       'G-5', 'H', 'H_CORRECTED', 'H_CORRECTED-1', 'H_CORRECTED-2',\n",
      "       'H_CORRECTED-3', 'H_CORRECTED-4', 'H_CORRECTED-5', 'NETRAD', 'NETRAD-1',\n",
      "       'NETRAD-2', 'NETRAD-3', 'NETRAD-4', 'NETRAD-5', 'LE', 'LE_CORRECTED',\n",
      "       'LE_CORRECTED(mm)', 'LE_CORRECTED(mm)-1', 'LE_CORRECTED(mm)-2',\n",
      "       'LE_CORRECTED(mm)-3', 'LE_CORRECTED(mm)-4', 'LE_CORRECTED(mm)-5',\n",
      "       'Cloud', 'Image Id', 'EEflux ET', 'Tier'],\n",
      "      dtype='object')\n",
      "Site ID US-Snd\n",
      "Site ID US-AR2\n",
      "ordered columns ['Date', 'Site Id', 'Year', 'Month', 'Day', 'WS', 'WS-1', 'WS-2', 'WS-3', 'WS-4', 'WS-5', 'RH', 'RH-1', 'RH-2', 'RH-3', 'RH-4', 'RH-5', 'TA', 'TA-1', 'TA-2', 'TA-3', 'TA-4', 'TA-5', 'G', 'G-1', 'G-2', 'G-3', 'G-4', 'G-5', 'H', 'H_CORRECTED', 'H_CORRECTED-1', 'H_CORRECTED-2', 'H_CORRECTED-3', 'H_CORRECTED-4', 'H_CORRECTED-5', 'NETRAD', 'NETRAD-1', 'NETRAD-2', 'NETRAD-3', 'NETRAD-4', 'NETRAD-5', 'LE', 'LE_CORRECTED', 'LE_CORRECTED(mm)', 'LE_CORRECTED(mm)-1', 'LE_CORRECTED(mm)-2', 'LE_CORRECTED(mm)-3', 'LE_CORRECTED(mm)-4', 'LE_CORRECTED(mm)-5', 'Cloud', 'Image Id', 'EEflux ET', 'Tier']\n",
      "columns Index(['Date', 'Site Id', 'Year', 'Month', 'Day', 'WS', 'WS-1', 'WS-2', 'WS-3',\n",
      "       'WS-4', 'WS-5', 'RH', 'RH-1', 'RH-2', 'RH-3', 'RH-4', 'RH-5', 'TA',\n",
      "       'TA-1', 'TA-2', 'TA-3', 'TA-4', 'TA-5', 'G', 'G-1', 'G-2', 'G-3', 'G-4',\n",
      "       'G-5', 'H', 'H_CORRECTED', 'H_CORRECTED-1', 'H_CORRECTED-2',\n",
      "       'H_CORRECTED-3', 'H_CORRECTED-4', 'H_CORRECTED-5', 'NETRAD', 'NETRAD-1',\n",
      "       'NETRAD-2', 'NETRAD-3', 'NETRAD-4', 'NETRAD-5', 'LE', 'LE_CORRECTED',\n",
      "       'LE_CORRECTED(mm)', 'LE_CORRECTED(mm)-1', 'LE_CORRECTED(mm)-2',\n",
      "       'LE_CORRECTED(mm)-3', 'LE_CORRECTED(mm)-4', 'LE_CORRECTED(mm)-5',\n",
      "       'Cloud', 'Image Id', 'EEflux ET', 'Tier'],\n",
      "      dtype='object')\n",
      "Site ID US-Goo\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ordered columns ['Date', 'Site Id', 'Year', 'Month', 'Day', 'WS', 'WS-1', 'WS-2', 'WS-3', 'WS-4', 'WS-5', 'RH', 'RH-1', 'RH-2', 'RH-3', 'RH-4', 'RH-5', 'TA', 'TA-1', 'TA-2', 'TA-3', 'TA-4', 'TA-5', 'G', 'G-1', 'G-2', 'G-3', 'G-4', 'G-5', 'H', 'H_CORRECTED', 'H_CORRECTED-1', 'H_CORRECTED-2', 'H_CORRECTED-3', 'H_CORRECTED-4', 'H_CORRECTED-5', 'NETRAD', 'NETRAD-1', 'NETRAD-2', 'NETRAD-3', 'NETRAD-4', 'NETRAD-5', 'LE', 'LE_CORRECTED', 'LE_CORRECTED(mm)', 'LE_CORRECTED(mm)-1', 'LE_CORRECTED(mm)-2', 'LE_CORRECTED(mm)-3', 'LE_CORRECTED(mm)-4', 'LE_CORRECTED(mm)-5', 'Cloud', 'Image Id', 'EEflux ET', 'Tier']\n",
      "columns Index(['Date', 'Site Id', 'Year', 'Month', 'Day', 'WS', 'WS-1', 'WS-2', 'WS-3',\n",
      "       'WS-4', 'WS-5', 'RH', 'RH-1', 'RH-2', 'RH-3', 'RH-4', 'RH-5', 'TA',\n",
      "       'TA-1', 'TA-2', 'TA-3', 'TA-4', 'TA-5', 'G', 'G-1', 'G-2', 'G-3', 'G-4',\n",
      "       'G-5', 'H', 'H_CORRECTED', 'H_CORRECTED-1', 'H_CORRECTED-2',\n",
      "       'H_CORRECTED-3', 'H_CORRECTED-4', 'H_CORRECTED-5', 'NETRAD', 'NETRAD-1',\n",
      "       'NETRAD-2', 'NETRAD-3', 'NETRAD-4', 'NETRAD-5', 'LE', 'LE_CORRECTED',\n",
      "       'LE_CORRECTED(mm)', 'LE_CORRECTED(mm)-1', 'LE_CORRECTED(mm)-2',\n",
      "       'LE_CORRECTED(mm)-3', 'LE_CORRECTED(mm)-4', 'LE_CORRECTED(mm)-5',\n",
      "       'Cloud', 'Image Id', 'EEflux ET', 'Tier'],\n",
      "      dtype='object')\n",
      "Site ID US-Wlr\n",
      "ordered columns ['Date', 'Site Id', 'Year', 'Month', 'Day', 'WS', 'WS-1', 'WS-2', 'WS-3', 'WS-4', 'WS-5', 'RH', 'RH-1', 'RH-2', 'RH-3', 'RH-4', 'RH-5', 'TA', 'TA-1', 'TA-2', 'TA-3', 'TA-4', 'TA-5', 'G', 'G-1', 'G-2', 'G-3', 'G-4', 'G-5', 'H', 'H_CORRECTED', 'H_CORRECTED-1', 'H_CORRECTED-2', 'H_CORRECTED-3', 'H_CORRECTED-4', 'H_CORRECTED-5', 'NETRAD', 'NETRAD-1', 'NETRAD-2', 'NETRAD-3', 'NETRAD-4', 'NETRAD-5', 'LE', 'LE_CORRECTED', 'LE_CORRECTED(mm)', 'LE_CORRECTED(mm)-1', 'LE_CORRECTED(mm)-2', 'LE_CORRECTED(mm)-3', 'LE_CORRECTED(mm)-4', 'LE_CORRECTED(mm)-5', 'Cloud', 'Image Id', 'EEflux ET', 'Tier']\n",
      "columns Index(['Date', 'Site Id', 'Year', 'Month', 'Day', 'WS', 'WS-1', 'WS-2', 'WS-3',\n",
      "       'WS-4', 'WS-5', 'RH', 'RH-1', 'RH-2', 'RH-3', 'RH-4', 'RH-5', 'TA',\n",
      "       'TA-1', 'TA-2', 'TA-3', 'TA-4', 'TA-5', 'G', 'G-1', 'G-2', 'G-3', 'G-4',\n",
      "       'G-5', 'H', 'H_CORRECTED', 'H_CORRECTED-1', 'H_CORRECTED-2',\n",
      "       'H_CORRECTED-3', 'H_CORRECTED-4', 'H_CORRECTED-5', 'NETRAD', 'NETRAD-1',\n",
      "       'NETRAD-2', 'NETRAD-3', 'NETRAD-4', 'NETRAD-5', 'LE', 'LE_CORRECTED',\n",
      "       'LE_CORRECTED(mm)', 'LE_CORRECTED(mm)-1', 'LE_CORRECTED(mm)-2',\n",
      "       'LE_CORRECTED(mm)-3', 'LE_CORRECTED(mm)-4', 'LE_CORRECTED(mm)-5',\n",
      "       'Cloud', 'Image Id', 'EEflux ET', 'Tier'],\n",
      "      dtype='object')\n",
      "Site ID US-A74\n",
      "ordered columns ['Date', 'Site Id', 'Year', 'Month', 'Day', 'WS', 'WS-1', 'WS-2', 'WS-3', 'WS-4', 'WS-5', 'RH', 'RH-1', 'RH-2', 'RH-3', 'RH-4', 'RH-5', 'TA', 'TA-1', 'TA-2', 'TA-3', 'TA-4', 'TA-5', 'G', 'G-1', 'G-2', 'G-3', 'G-4', 'G-5', 'H', 'H_CORRECTED', 'H_CORRECTED-1', 'H_CORRECTED-2', 'H_CORRECTED-3', 'H_CORRECTED-4', 'H_CORRECTED-5', 'NETRAD', 'NETRAD-1', 'NETRAD-2', 'NETRAD-3', 'NETRAD-4', 'NETRAD-5', 'LE', 'LE_CORRECTED', 'LE_CORRECTED(mm)', 'LE_CORRECTED(mm)-1', 'LE_CORRECTED(mm)-2', 'LE_CORRECTED(mm)-3', 'LE_CORRECTED(mm)-4', 'LE_CORRECTED(mm)-5', 'Cloud', 'Image Id', 'EEflux ET', 'Tier']\n",
      "columns Index(['Date', 'Site Id', 'Year', 'Month', 'Day', 'WS', 'WS-1', 'WS-2', 'WS-3',\n",
      "       'WS-4', 'WS-5', 'RH', 'RH-1', 'RH-2', 'RH-3', 'RH-4', 'RH-5', 'TA',\n",
      "       'TA-1', 'TA-2', 'TA-3', 'TA-4', 'TA-5', 'G', 'G-1', 'G-2', 'G-3', 'G-4',\n",
      "       'G-5', 'H', 'H_CORRECTED', 'H_CORRECTED-1', 'H_CORRECTED-2',\n",
      "       'H_CORRECTED-3', 'H_CORRECTED-4', 'H_CORRECTED-5', 'NETRAD', 'NETRAD-1',\n",
      "       'NETRAD-2', 'NETRAD-3', 'NETRAD-4', 'NETRAD-5', 'LE', 'LE_CORRECTED',\n",
      "       'LE_CORRECTED(mm)', 'LE_CORRECTED(mm)-1', 'LE_CORRECTED(mm)-2',\n",
      "       'LE_CORRECTED(mm)-3', 'LE_CORRECTED(mm)-4', 'LE_CORRECTED(mm)-5',\n",
      "       'Cloud', 'Image Id', 'EEflux ET', 'Tier'],\n",
      "      dtype='object')\n",
      "Site ID US-AR1\n",
      "ordered columns ['Date', 'Site Id', 'Year', 'Month', 'Day', 'WS', 'WS-1', 'WS-2', 'WS-3', 'WS-4', 'WS-5', 'RH', 'RH-1', 'RH-2', 'RH-3', 'RH-4', 'RH-5', 'TA', 'TA-1', 'TA-2', 'TA-3', 'TA-4', 'TA-5', 'G', 'G-1', 'G-2', 'G-3', 'G-4', 'G-5', 'H', 'H_CORRECTED', 'H_CORRECTED-1', 'H_CORRECTED-2', 'H_CORRECTED-3', 'H_CORRECTED-4', 'H_CORRECTED-5', 'NETRAD', 'NETRAD-1', 'NETRAD-2', 'NETRAD-3', 'NETRAD-4', 'NETRAD-5', 'LE', 'LE_CORRECTED', 'LE_CORRECTED(mm)', 'LE_CORRECTED(mm)-1', 'LE_CORRECTED(mm)-2', 'LE_CORRECTED(mm)-3', 'LE_CORRECTED(mm)-4', 'LE_CORRECTED(mm)-5', 'Cloud', 'Image Id', 'EEflux ET', 'Tier']\n",
      "columns Index(['Date', 'Site Id', 'Year', 'Month', 'Day', 'WS', 'WS-1', 'WS-2', 'WS-3',\n",
      "       'WS-4', 'WS-5', 'RH', 'RH-1', 'RH-2', 'RH-3', 'RH-4', 'RH-5', 'TA',\n",
      "       'TA-1', 'TA-2', 'TA-3', 'TA-4', 'TA-5', 'G', 'G-1', 'G-2', 'G-3', 'G-4',\n",
      "       'G-5', 'H', 'H_CORRECTED', 'H_CORRECTED-1', 'H_CORRECTED-2',\n",
      "       'H_CORRECTED-3', 'H_CORRECTED-4', 'H_CORRECTED-5', 'NETRAD', 'NETRAD-1',\n",
      "       'NETRAD-2', 'NETRAD-3', 'NETRAD-4', 'NETRAD-5', 'LE', 'LE_CORRECTED',\n",
      "       'LE_CORRECTED(mm)', 'LE_CORRECTED(mm)-1', 'LE_CORRECTED(mm)-2',\n",
      "       'LE_CORRECTED(mm)-3', 'LE_CORRECTED(mm)-4', 'LE_CORRECTED(mm)-5',\n",
      "       'Cloud', 'Image Id', 'EEflux ET', 'Tier'],\n",
      "      dtype='object')\n",
      "Site ID US-Kon\n",
      "ordered columns ['Date', 'Site Id', 'Year', 'Month', 'Day', 'WS', 'WS-1', 'WS-2', 'WS-3', 'WS-4', 'WS-5', 'RH', 'RH-1', 'RH-2', 'RH-3', 'RH-4', 'RH-5', 'TA', 'TA-1', 'TA-2', 'TA-3', 'TA-4', 'TA-5', 'G', 'G-1', 'G-2', 'G-3', 'G-4', 'G-5', 'H', 'H_CORRECTED', 'H_CORRECTED-1', 'H_CORRECTED-2', 'H_CORRECTED-3', 'H_CORRECTED-4', 'H_CORRECTED-5', 'NETRAD', 'NETRAD-1', 'NETRAD-2', 'NETRAD-3', 'NETRAD-4', 'NETRAD-5', 'LE', 'LE_CORRECTED', 'LE_CORRECTED(mm)', 'LE_CORRECTED(mm)-1', 'LE_CORRECTED(mm)-2', 'LE_CORRECTED(mm)-3', 'LE_CORRECTED(mm)-4', 'LE_CORRECTED(mm)-5', 'Cloud', 'Image Id', 'EEflux ET', 'Tier']\n",
      "columns Index(['Date', 'Site Id', 'Year', 'Month', 'Day', 'WS', 'WS-1', 'WS-2', 'WS-3',\n",
      "       'WS-4', 'WS-5', 'RH', 'RH-1', 'RH-2', 'RH-3', 'RH-4', 'RH-5', 'TA',\n",
      "       'TA-1', 'TA-2', 'TA-3', 'TA-4', 'TA-5', 'G', 'G-1', 'G-2', 'G-3', 'G-4',\n",
      "       'G-5', 'H', 'H_CORRECTED', 'H_CORRECTED-1', 'H_CORRECTED-2',\n",
      "       'H_CORRECTED-3', 'H_CORRECTED-4', 'H_CORRECTED-5', 'NETRAD', 'NETRAD-1',\n",
      "       'NETRAD-2', 'NETRAD-3', 'NETRAD-4', 'NETRAD-5', 'LE', 'LE_CORRECTED',\n",
      "       'LE_CORRECTED(mm)', 'LE_CORRECTED(mm)-1', 'LE_CORRECTED(mm)-2',\n",
      "       'LE_CORRECTED(mm)-3', 'LE_CORRECTED(mm)-4', 'LE_CORRECTED(mm)-5',\n",
      "       'Cloud', 'Image Id', 'EEflux ET', 'Tier'],\n",
      "      dtype='object')\n",
      "Site ID US-SO2\n",
      "ordered columns ['Date', 'Site Id', 'Year', 'Month', 'Day', 'WS', 'WS-1', 'WS-2', 'WS-3', 'WS-4', 'WS-5', 'RH', 'RH-1', 'RH-2', 'RH-3', 'RH-4', 'RH-5', 'TA', 'TA-1', 'TA-2', 'TA-3', 'TA-4', 'TA-5', 'G', 'G-1', 'G-2', 'G-3', 'G-4', 'G-5', 'H', 'H_CORRECTED', 'H_CORRECTED-1', 'H_CORRECTED-2', 'H_CORRECTED-3', 'H_CORRECTED-4', 'H_CORRECTED-5', 'NETRAD', 'NETRAD-1', 'NETRAD-2', 'NETRAD-3', 'NETRAD-4', 'NETRAD-5', 'LE', 'LE_CORRECTED', 'LE_CORRECTED(mm)', 'LE_CORRECTED(mm)-1', 'LE_CORRECTED(mm)-2', 'LE_CORRECTED(mm)-3', 'LE_CORRECTED(mm)-4', 'LE_CORRECTED(mm)-5', 'Cloud', 'Image Id', 'EEflux ET', 'Tier']\n",
      "columns Index(['Date', 'Site Id', 'Year', 'Month', 'Day', 'WS', 'WS-1', 'WS-2', 'WS-3',\n",
      "       'WS-4', 'WS-5', 'RH', 'RH-1', 'RH-2', 'RH-3', 'RH-4', 'RH-5', 'TA',\n",
      "       'TA-1', 'TA-2', 'TA-3', 'TA-4', 'TA-5', 'G', 'G-1', 'G-2', 'G-3', 'G-4',\n",
      "       'G-5', 'H', 'H_CORRECTED', 'H_CORRECTED-1', 'H_CORRECTED-2',\n",
      "       'H_CORRECTED-3', 'H_CORRECTED-4', 'H_CORRECTED-5', 'NETRAD', 'NETRAD-1',\n",
      "       'NETRAD-2', 'NETRAD-3', 'NETRAD-4', 'NETRAD-5', 'LE', 'LE_CORRECTED',\n",
      "       'LE_CORRECTED(mm)', 'LE_CORRECTED(mm)-1', 'LE_CORRECTED(mm)-2',\n",
      "       'LE_CORRECTED(mm)-3', 'LE_CORRECTED(mm)-4', 'LE_CORRECTED(mm)-5',\n",
      "       'Cloud', 'Image Id', 'EEflux ET', 'Tier'],\n",
      "      dtype='object')\n",
      "Site ID US-SP2\n",
      "ordered columns ['Date', 'Site Id', 'Year', 'Month', 'Day', 'WS', 'WS-1', 'WS-2', 'WS-3', 'WS-4', 'WS-5', 'RH', 'RH-1', 'RH-2', 'RH-3', 'RH-4', 'RH-5', 'TA', 'TA-1', 'TA-2', 'TA-3', 'TA-4', 'TA-5', 'G', 'G-1', 'G-2', 'G-3', 'G-4', 'G-5', 'H', 'H_CORRECTED', 'H_CORRECTED-1', 'H_CORRECTED-2', 'H_CORRECTED-3', 'H_CORRECTED-4', 'H_CORRECTED-5', 'NETRAD', 'NETRAD-1', 'NETRAD-2', 'NETRAD-3', 'NETRAD-4', 'NETRAD-5', 'LE', 'LE_CORRECTED', 'LE_CORRECTED(mm)', 'LE_CORRECTED(mm)-1', 'LE_CORRECTED(mm)-2', 'LE_CORRECTED(mm)-3', 'LE_CORRECTED(mm)-4', 'LE_CORRECTED(mm)-5', 'Cloud', 'Image Id', 'EEflux ET', 'Tier']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "columns Index(['Date', 'Site Id', 'Year', 'Month', 'Day', 'WS', 'WS-1', 'WS-2', 'WS-3',\n",
      "       'WS-4', 'WS-5', 'RH', 'RH-1', 'RH-2', 'RH-3', 'RH-4', 'RH-5', 'TA',\n",
      "       'TA-1', 'TA-2', 'TA-3', 'TA-4', 'TA-5', 'G', 'G-1', 'G-2', 'G-3', 'G-4',\n",
      "       'G-5', 'H', 'H_CORRECTED', 'H_CORRECTED-1', 'H_CORRECTED-2',\n",
      "       'H_CORRECTED-3', 'H_CORRECTED-4', 'H_CORRECTED-5', 'NETRAD', 'NETRAD-1',\n",
      "       'NETRAD-2', 'NETRAD-3', 'NETRAD-4', 'NETRAD-5', 'LE', 'LE_CORRECTED',\n",
      "       'LE_CORRECTED(mm)', 'LE_CORRECTED(mm)-1', 'LE_CORRECTED(mm)-2',\n",
      "       'LE_CORRECTED(mm)-3', 'LE_CORRECTED(mm)-4', 'LE_CORRECTED(mm)-5',\n",
      "       'Cloud', 'Image Id', 'EEflux ET', 'Tier'],\n",
      "      dtype='object')\n",
      "Site ID US-Var\n",
      "ordered columns ['Date', 'Site Id', 'Year', 'Month', 'Day', 'WS', 'WS-1', 'WS-2', 'WS-3', 'WS-4', 'WS-5', 'RH', 'RH-1', 'RH-2', 'RH-3', 'RH-4', 'RH-5', 'TA', 'TA-1', 'TA-2', 'TA-3', 'TA-4', 'TA-5', 'G', 'G-1', 'G-2', 'G-3', 'G-4', 'G-5', 'H', 'H_CORRECTED', 'H_CORRECTED-1', 'H_CORRECTED-2', 'H_CORRECTED-3', 'H_CORRECTED-4', 'H_CORRECTED-5', 'NETRAD', 'NETRAD-1', 'NETRAD-2', 'NETRAD-3', 'NETRAD-4', 'NETRAD-5', 'LE', 'LE_CORRECTED', 'LE_CORRECTED(mm)', 'LE_CORRECTED(mm)-1', 'LE_CORRECTED(mm)-2', 'LE_CORRECTED(mm)-3', 'LE_CORRECTED(mm)-4', 'LE_CORRECTED(mm)-5', 'Cloud', 'Image Id', 'EEflux ET', 'Tier']\n",
      "columns Index(['Date', 'Site Id', 'Year', 'Month', 'Day', 'WS', 'WS-1', 'WS-2', 'WS-3',\n",
      "       'WS-4', 'WS-5', 'RH', 'RH-1', 'RH-2', 'RH-3', 'RH-4', 'RH-5', 'TA',\n",
      "       'TA-1', 'TA-2', 'TA-3', 'TA-4', 'TA-5', 'G', 'G-1', 'G-2', 'G-3', 'G-4',\n",
      "       'G-5', 'H', 'H_CORRECTED', 'H_CORRECTED-1', 'H_CORRECTED-2',\n",
      "       'H_CORRECTED-3', 'H_CORRECTED-4', 'H_CORRECTED-5', 'NETRAD', 'NETRAD-1',\n",
      "       'NETRAD-2', 'NETRAD-3', 'NETRAD-4', 'NETRAD-5', 'LE', 'LE_CORRECTED',\n",
      "       'LE_CORRECTED(mm)', 'LE_CORRECTED(mm)-1', 'LE_CORRECTED(mm)-2',\n",
      "       'LE_CORRECTED(mm)-3', 'LE_CORRECTED(mm)-4', 'LE_CORRECTED(mm)-5',\n",
      "       'Cloud', 'Image Id', 'EEflux ET', 'Tier'],\n",
      "      dtype='object')\n",
      "Site ID US-Twt\n",
      "ordered columns ['Date', 'Site Id', 'Year', 'Month', 'Day', 'WS', 'WS-1', 'WS-2', 'WS-3', 'WS-4', 'WS-5', 'RH', 'RH-1', 'RH-2', 'RH-3', 'RH-4', 'RH-5', 'TA', 'TA-1', 'TA-2', 'TA-3', 'TA-4', 'TA-5', 'G', 'G-1', 'G-2', 'G-3', 'G-4', 'G-5', 'H', 'H_CORRECTED', 'H_CORRECTED-1', 'H_CORRECTED-2', 'H_CORRECTED-3', 'H_CORRECTED-4', 'H_CORRECTED-5', 'NETRAD', 'NETRAD-1', 'NETRAD-2', 'NETRAD-3', 'NETRAD-4', 'NETRAD-5', 'LE', 'LE_CORRECTED', 'LE_CORRECTED(mm)', 'LE_CORRECTED(mm)-1', 'LE_CORRECTED(mm)-2', 'LE_CORRECTED(mm)-3', 'LE_CORRECTED(mm)-4', 'LE_CORRECTED(mm)-5', 'Cloud', 'Image Id', 'EEflux ET', 'Tier']\n",
      "columns Index(['Date', 'Site Id', 'Year', 'Month', 'Day', 'WS', 'WS-1', 'WS-2', 'WS-3',\n",
      "       'WS-4', 'WS-5', 'RH', 'RH-1', 'RH-2', 'RH-3', 'RH-4', 'RH-5', 'TA',\n",
      "       'TA-1', 'TA-2', 'TA-3', 'TA-4', 'TA-5', 'G', 'G-1', 'G-2', 'G-3', 'G-4',\n",
      "       'G-5', 'H', 'H_CORRECTED', 'H_CORRECTED-1', 'H_CORRECTED-2',\n",
      "       'H_CORRECTED-3', 'H_CORRECTED-4', 'H_CORRECTED-5', 'NETRAD', 'NETRAD-1',\n",
      "       'NETRAD-2', 'NETRAD-3', 'NETRAD-4', 'NETRAD-5', 'LE', 'LE_CORRECTED',\n",
      "       'LE_CORRECTED(mm)', 'LE_CORRECTED(mm)-1', 'LE_CORRECTED(mm)-2',\n",
      "       'LE_CORRECTED(mm)-3', 'LE_CORRECTED(mm)-4', 'LE_CORRECTED(mm)-5',\n",
      "       'Cloud', 'Image Id', 'EEflux ET', 'Tier'],\n",
      "      dtype='object')\n",
      "ordered columns ['Date', 'Site Id', 'Year', 'Month', 'Day', 'WS', 'WS-1', 'WS-2', 'WS-3', 'WS-4', 'WS-5', 'RH', 'RH-1', 'RH-2', 'RH-3', 'RH-4', 'RH-5', 'TA', 'TA-1', 'TA-2', 'TA-3', 'TA-4', 'TA-5', 'G', 'G-1', 'G-2', 'G-3', 'G-4', 'G-5', 'H', 'H_CORRECTED', 'H_CORRECTED-1', 'H_CORRECTED-2', 'H_CORRECTED-3', 'H_CORRECTED-4', 'H_CORRECTED-5', 'NETRAD', 'NETRAD-1', 'NETRAD-2', 'NETRAD-3', 'NETRAD-4', 'NETRAD-5', 'LE', 'LE_CORRECTED', 'LE_CORRECTED(mm)', 'LE_CORRECTED(mm)-1', 'LE_CORRECTED(mm)-2', 'LE_CORRECTED(mm)-3', 'LE_CORRECTED(mm)-4', 'LE_CORRECTED(mm)-5', 'Cloud', 'Image Id', 'EEflux ET', 'Tier']\n"
     ]
    }
   ],
   "source": [
    "#Generate excel with all the sites Ameriflux joint with EEflux\n",
    "output_name = os.path.join(base_path + \"Ameriflux/\", \"Jan-11-2020_Joint/\")\n",
    "joint = JointData(output_name, lags_count)\n",
    "merged_df = joint.prepare_data(df_daily, [\"Site Id\",\"Date\"], [\"Site Id\", \"Date\"])\n",
    "merged_df = joint.order_columns(merged_df)\n",
    "file_name = os.path.join(output_name, \"All_Joint\")\n",
    "Helpers.export_data(merged_df, file_name) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AmerifluxErrorGraph Initializer\n"
     ]
    }
   ],
   "source": [
    "class AmerifluxErrorGraph:\n",
    "    def __init__(self, path):\n",
    "        print(\"AmerifluxErrorGraph Initializer\")\n",
    "        self.path = path\n",
    "          \n",
    "    def read_data(self):\n",
    "        file_name = os.path.join(base_path, self.path)\n",
    "        df = pd.read_csv(file_name, index_col=None, header=0)\n",
    "        df = Helpers.add_LE_conversion_rate(df, \"LE\")\n",
    "        return df\n",
    "    \n",
    "\n",
    "    def get_error_metrics(self, y_true, y_predicted):\n",
    "        r2_Score = r2_score(y_true, y_predicted)\n",
    "        rmse_score = np.sqrt(mean_squared_error(y_true, y_predicted))\n",
    "        mse_score = mean_squared_error(y_true, y_predicted)\n",
    "        mae_score = mean_absolute_error(y_true, y_predicted)\n",
    "\n",
    "        def mean_absolute_percentage_error(y_true, y_pred):\n",
    "            y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "            return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "        mape_score = mean_absolute_percentage_error(y_true, y_predicted)\n",
    "        num = 2\n",
    "        return (round(r2_Score, num), round(rmse_score, num), round(mse_score, num), \n",
    "                round(mae_score, num), round(mape_score, num))\n",
    "\n",
    "\n",
    "    def generate_errors(self, df, first_col, second_col):\n",
    "        df = df.replace(to_replace = np.nan, value =0) \n",
    "        errors = self.get_error_metrics(df[first_col], df[second_col])\n",
    "        return errors\n",
    "    \n",
    "    def plot_et(self, df, site_id, first_column, first_b_column, second_column, path_to_save):\n",
    "        fig, ax = plt.subplots(figsize=(40, 17))\n",
    "        fig.subplots_adjust(bottom=0.15, left=0.2)\n",
    "        plt.subplot(121)\n",
    "        title1 = site_id + \": Comparison before correction between \" + first_column + \" and \" + second_column\n",
    "        self.plot_sub(df, first_column, second_column, title1)\n",
    "        \n",
    "        plt.subplot(122)\n",
    "        title2 = site_id + \": Comparison after correction between \" + first_b_column + \" and \" + second_column\n",
    "        self.plot_sub(df, first_b_column, second_column, title2)\n",
    "\n",
    "        plt.xticks(rotation=90)\n",
    "#         ax.legend()\n",
    "#         plt.show()\n",
    "        full_path = os.path.join(base_path, path_to_save)\n",
    "        plt.savefig(full_path + site_id + \"_et.png\")\n",
    "        plt.close(fig)\n",
    "\n",
    "    def plot_sub(self, df, first_column, second_column, title):\n",
    "        ax = sns.regplot(x=first_column, y=second_column, data=df, fit_reg=False)\n",
    "        lims = [\n",
    "            np.min([ax.get_xlim(), ax.get_ylim()]),  # min of both axes\n",
    "            np.max([ax.get_xlim(), ax.get_ylim()]),  # max of both axes\n",
    "            ]\n",
    "\n",
    "        # now plot both limits against eachother\n",
    "        ax.plot(lims, lims, 'k-', alpha=0.75, zorder=0)\n",
    "        ax.set_aspect('equal')\n",
    "        ax.set_xlim(lims)\n",
    "        ax.set_ylim(lims)\n",
    "       \n",
    "        plt.title(title)\n",
    "        \n",
    "        \n",
    "    def prepare_data(self, df):\n",
    "        unique_sites = df[\"Site Id\"].unique()\n",
    "        unique_sites\n",
    "\n",
    "        r2_list, rmse_list, mse_list, mae_list, mape_list = [], [], [], [], []\n",
    "        first_column = \"LE(mm)\"\n",
    "        first_b_column = \"LE_CORRECTED(mm)\"\n",
    "\n",
    "        second_column = \"EEflux ET\"\n",
    "        for i in range(len(unique_sites)):\n",
    "            site_id = unique_sites[i]\n",
    "            df_site = df[df[\"Site Id\"] == site_id]\n",
    "            (r2, rmse, mse, mae, mape) = self.generate_errors(df_site, first_column, second_column)\n",
    "            r2_list.append(r2)\n",
    "            rmse_list.append(rmse)\n",
    "            mse_list.append(mse)\n",
    "            mae_list.append(mae)\n",
    "            mape_list.append(mape)\n",
    "            df_site['Date'] = pd.to_datetime(df_site[\"Date\"])\n",
    "            df_site.sort_values(by=\"Date\", inplace=True, ascending=True)\n",
    "            #Plot the output feature\n",
    "            if len(df_site) > 0:\n",
    "                self.plot_et(df_site, site_id, first_column, first_b_column, second_column, \"Ameriflux/Generated/v1/Graphs/\")\n",
    "\n",
    "        df_errors = pd.DataFrame({\"Site Id\": unique_sites,\n",
    "                                  \"True Value\": first_column,\n",
    "                                  \"Predicted Value\": second_column,\n",
    "                                  \"R2\": r2_list,\n",
    "                                  \"RMSE\": rmse_list, \n",
    "                                  \"MSE\": rmse_list,\n",
    "                                  \"MAE\": mae_list, \n",
    "                                  \"MAPE\": mape_list})\n",
    "        print(df_errors)\n",
    "        errors_path = \"Ameriflux/Generated/v1/Errors_ET\"\n",
    "        Helpers.export_data(df_errors, errors_path)\n",
    "\n",
    "\n",
    "\n",
    "full_path = os.path.join(\"/Users/saraawad/Desktop/All_Joint.csv\")\n",
    "am_eg = AmerifluxErrorGraph(full_path)\n",
    "df = am_eg.read_data()\n",
    "df.head()\n",
    "am_eg.prepare_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
